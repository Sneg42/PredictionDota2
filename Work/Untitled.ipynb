{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузить данные из файлов\n",
    "matches706_team_picks = pd.read_csv('table with carry or support in 7.06.csv').drop(['Unnamed: 0'], axis=1)\n",
    "matches707_team_picks = pd.read_csv('table with carry or support in 7.07 to 29.12.17.csv', index_col=0)\n",
    "\n",
    "# Соединить даныне\n",
    "matches_team_picks = matches706_team_picks.append(matches707_team_picks).reset_index().drop(['index'], axis=1)\n",
    "\n",
    "#Разделение данных без перемешивания на traning & test для каждого патча и для соединенных данных\n",
    "X_706, y_706 = np.split(matches706_team_picks, [len(matches706_team_picks) - int(len(matches706_team_picks)*0.3)]) \n",
    "X_707, y_707 = np.split(matches707_team_picks, [len(matches707_team_picks) - int(len(matches707_team_picks)*0.3)]) \n",
    "X, y = np.split(matches_team_picks, [len(matches_team_picks) - 400]) \n",
    "\n",
    "X_train = X.drop(['radiant_win'], axis=1)\n",
    "y_train = X['radiant_win']\n",
    "\n",
    "X_test = y.drop(['radiant_win'], axis=1)\n",
    "y_test = y['radiant_win']\n",
    "\n",
    "X_train_706 = X_706.drop(['radiant_win'], axis=1)\n",
    "y_train_706 = X_706['radiant_win']\n",
    "\n",
    "X_test_706 = y_706.drop(['radiant_win'], axis=1)\n",
    "y_test_706 = y_706['radiant_win']\n",
    "\n",
    "X_train_707 = X_707.drop(['radiant_win'], axis=1)\n",
    "y_train_707 = X_707['radiant_win']\n",
    "\n",
    "X_test_707 = y_707.drop(['radiant_win'], axis=1)\n",
    "y_test_707 = y_707['radiant_win']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "105\n",
      "110\n",
      "115\n",
      "120\n",
      "125\n",
      "130\n",
      "135\n",
      "140\n",
      "145\n",
      "150\n",
      "155\n",
      "160\n",
      "165\n",
      "170\n",
      "175\n",
      "180\n",
      "185\n",
      "190\n",
      "195\n"
     ]
    }
   ],
   "source": [
    "# создание большого кол-ва лесов с разными параметрами и запись Score в массив\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "all_parametrs=[]\n",
    "for n in range(100, 200, 5):\n",
    "    for depth in range(15, 100, 5):\n",
    "        for features in range(1, 103, 5):\n",
    "            parametrs=[]\n",
    "            forest_optim_param = RandomForestClassifier(n_estimators=n, random_state=42, \n",
    "                                                        max_depth=depth, max_features=features)\n",
    "            forest_optim_param.fit(X_train_707, y_train_707)\n",
    "            if (forest_optim_param.score(X_test_707, y_test_707) > 0.62):\n",
    "                parametrs.append(n)\n",
    "                parametrs.append(depth)\n",
    "                parametrs.append(features)\n",
    "                parametrs.append(forest_optim_param.score(X_train_707, y_train_707))\n",
    "                parametrs.append(forest_optim_param.score(X_test_707, y_test_707))\n",
    "                all_parametrs.append(parametrs)\n",
    "    print (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[105, 15, 96, 1.0, 0.63675213675213671],\n",
       " [105, 20, 96, 1.0, 0.63675213675213671],\n",
       " [105, 25, 96, 1.0, 0.63675213675213671],\n",
       " [105, 30, 96, 1.0, 0.63675213675213671],\n",
       " [105, 35, 96, 1.0, 0.63675213675213671],\n",
       " [105, 40, 96, 1.0, 0.63675213675213671],\n",
       " [105, 45, 96, 1.0, 0.63675213675213671],\n",
       " [105, 50, 96, 1.0, 0.63675213675213671],\n",
       " [105, 55, 96, 1.0, 0.63675213675213671],\n",
       " [105, 60, 96, 1.0, 0.63675213675213671],\n",
       " [105, 65, 96, 1.0, 0.63675213675213671],\n",
       " [105, 70, 96, 1.0, 0.63675213675213671],\n",
       " [105, 75, 96, 1.0, 0.63675213675213671],\n",
       " [105, 80, 96, 1.0, 0.63675213675213671],\n",
       " [105, 85, 96, 1.0, 0.63675213675213671],\n",
       " [105, 90, 96, 1.0, 0.63675213675213671],\n",
       " [105, 95, 96, 1.0, 0.63675213675213671],\n",
       " [115, 15, 41, 1.0, 0.63675213675213671],\n",
       " [125, 15, 51, 1.0, 0.64102564102564108],\n",
       " [125, 20, 51, 1.0, 0.63675213675213671],\n",
       " [125, 25, 51, 1.0, 0.63675213675213671],\n",
       " [125, 30, 51, 1.0, 0.63675213675213671],\n",
       " [125, 35, 51, 1.0, 0.63675213675213671],\n",
       " [125, 40, 51, 1.0, 0.63675213675213671],\n",
       " [125, 45, 51, 1.0, 0.63675213675213671],\n",
       " [125, 50, 51, 1.0, 0.63675213675213671],\n",
       " [125, 55, 51, 1.0, 0.63675213675213671],\n",
       " [125, 60, 51, 1.0, 0.63675213675213671],\n",
       " [125, 65, 51, 1.0, 0.63675213675213671],\n",
       " [125, 70, 51, 1.0, 0.63675213675213671],\n",
       " [125, 75, 51, 1.0, 0.63675213675213671],\n",
       " [125, 80, 51, 1.0, 0.63675213675213671],\n",
       " [125, 85, 51, 1.0, 0.63675213675213671],\n",
       " [125, 90, 51, 1.0, 0.63675213675213671],\n",
       " [125, 95, 51, 1.0, 0.63675213675213671],\n",
       " [130, 15, 81, 1.0, 0.63675213675213671],\n",
       " [130, 20, 81, 1.0, 0.63675213675213671],\n",
       " [130, 25, 81, 1.0, 0.63675213675213671],\n",
       " [130, 30, 81, 1.0, 0.63675213675213671],\n",
       " [130, 35, 81, 1.0, 0.63675213675213671],\n",
       " [130, 40, 81, 1.0, 0.63675213675213671],\n",
       " [130, 45, 81, 1.0, 0.63675213675213671],\n",
       " [130, 50, 81, 1.0, 0.63675213675213671],\n",
       " [130, 55, 81, 1.0, 0.63675213675213671],\n",
       " [130, 60, 81, 1.0, 0.63675213675213671],\n",
       " [130, 65, 81, 1.0, 0.63675213675213671],\n",
       " [130, 70, 81, 1.0, 0.63675213675213671],\n",
       " [130, 75, 81, 1.0, 0.63675213675213671],\n",
       " [130, 80, 81, 1.0, 0.63675213675213671],\n",
       " [130, 85, 81, 1.0, 0.63675213675213671],\n",
       " [130, 90, 81, 1.0, 0.63675213675213671],\n",
       " [130, 95, 81, 1.0, 0.63675213675213671]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test=[]\n",
    "\n",
    "for par in all_parametrs:\n",
    "    if par[4] > 0.633:\n",
    "        all_test.append(par)\n",
    "all_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
