{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Sneg\\Add.Program\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "import urllib\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import requests\n",
    "\n",
    "# ДЛЯ ДОСТУПА НА РАБОТЕ и не только\n",
    "def get_json_from_url(url):\n",
    "#     # Для работы\n",
    "#         http_proxy  = \"http://pavlov.ds:qwerty@172.16.0.10:3128\"\n",
    "#         https_proxy = \"https://pavlov.ds:qwerty@172.16.0.10:3128\"\n",
    "#         ftp_proxy   = \"ftp://pavlov.ds:qwerty@172.16.0.10:3128\"\n",
    "\n",
    "#         proxyDict = { \n",
    "#                       \"http\"  : http_proxy, \n",
    "#                       \"https\" : https_proxy, \n",
    "#                       \"ftp\"   : ftp_proxy\n",
    "#                     }\n",
    "#         r = requests.get(url, headers={'User-agent': 'Mozilla/5.0'}, proxies=proxyDict)\n",
    "        \n",
    "    # Дома\n",
    "    r = requests.get(url, headers={'User-agent': 'Mozilla/5.0'})\n",
    "        \n",
    "    return json.loads(r.text)\n",
    "\n",
    "# Для рейтинга команд\n",
    "# создать мапу с старыми и новыми именами колонок для рейтинга команд\n",
    "def name_columns(z1, elo):\n",
    "    mapa = {}\n",
    "    for index, key in enumerate(z1.keys()):\n",
    "        mapa[key] = key + elo\n",
    "    return mapa\n",
    "# вытащить все данные по рейтингу (elo32, elo64, glicko, glicko2) одной команды\n",
    "def get_data_team(data):\n",
    "    ratings = ['elo32', 'elo64', 'glicko', 'glicko2']\n",
    "\n",
    "    #Создать колонку с именем команды\n",
    "    team = pd.DataFrame(columns=['team_Name'])\n",
    "    team['team_Name'] = [data.get('teamName')]\n",
    "\n",
    "    for rat in ratings:\n",
    "        current_rating = data.get(rat)\n",
    "        columns = name_columns(current_rating, '_' + rat)\n",
    "        df = pd.DataFrame(data.get(rat), index=range(0,1))     \n",
    "        df.rename(columns=columns, inplace=True)\n",
    "        team = pd.DataFrame.merge(team, df, left_index=True, right_index=True)\n",
    "    return team\n",
    "\n",
    "#Для KDA Героевg\n",
    "# Вытащить КДА по всем героям одной команды (нужна ссылка на сайт и массив из 5 героев одной команды)\n",
    "def get_KDA(url, array_heroes):\n",
    "    columns = ['hero', 'kills', 'deaths', 'assists', 'kda', 'avgKal', 'gpm', 'xpm', 'lastHits', 'denies', 'level',\n",
    "           'heroDamage', 'towerDamage', 'heroHealing', 'goldSpent']\n",
    "    # ДФ для соединения всех герове матча в один ДФ \n",
    "    df_heroe_match_teams = pd.DataFrame()\n",
    "\n",
    "    # выгрзить json с предыдущей ссылки\n",
    "    dat = get_json_from_url(url)\n",
    "    df_data_tabel_for_heroes_radiant = pd.DataFrame(dat, columns=columns)\n",
    "    df_kda_heroes = []\n",
    "    for her in array_heroes:\n",
    "        # достать KDA по каждому герою и убрать стобец с индексом героя\n",
    "        kda_heroe = df_data_tabel_for_heroes_radiant[df_data_tabel_for_heroes_radiant['hero'] == her]\n",
    "        kda_heroe = kda_heroe.drop('hero', axis=1)\n",
    "        if len(kda_heroe) == 0:\n",
    "            kda_heroe = [0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "        df_kda_heroes = np.append(df_kda_heroes, kda_heroe)\n",
    "    return df_kda_heroes\n",
    "\n",
    "# Head_to_head\n",
    "# добавить в массив суммарный показатель elo для героя vs всх врагов\n",
    "def elo_heroes_vs_enemies(array_heroes, array_enemies, df_elo_herVsEne):\n",
    "    df_elo = []\n",
    "    # две переменные для записи суммарного elo каждой команды\n",
    "    for her in array_heroes:\n",
    "        hero_elo = 0\n",
    "        # суммировать elo героя против героев противника\n",
    "        for her_enemy in array_enemies:\n",
    "            try:\n",
    "                elo =  df_elo_herVsEne['shift'][df_elo_herVsEne['hero'] == \n",
    "                                              her][df_elo_herVsEne['againstHero'] == her_enemy].item()\n",
    "                if math.isnan(elo):\n",
    "                    elo=0\n",
    "            except:\n",
    "                elo=0\n",
    "            hero_elo += elo\n",
    "        # записать в основной массив elo по каждому герою\n",
    "        df_elo = np.append(df_elo, hero_elo)\n",
    "    return df_elo\n",
    "# создать массив elo по героям имея только ссылку на сайт\n",
    "def get_elo_head_to_head(url):\n",
    "    # выгрзить json с предыдущей ссылки и создать ДФ\n",
    "    dat = get_json_from_url(url)\n",
    "    df_elo_herVsEne = pd.DataFrame(dat)\n",
    "    \n",
    "    radiant_eloVsEnemy = elo_heroes_vs_enemies(radiant, dire, df_elo_herVsEne)\n",
    "    dire_eloVsEnemy = elo_heroes_vs_enemies(dire, radiant, df_elo_herVsEne)\n",
    "    return np.append(radiant_eloVsEnemy, dire_eloVsEnemy)\n",
    "\n",
    "#AvgElo\n",
    "# вытащить ДФы для одного, пары, тройки героев из сайта по дате\n",
    "def get_df_avgElo_heroes(df):\n",
    "    # создать ДФ для одного героя, пары и тройки\n",
    "    df_one = df.loc[(index for index, x in enumerate(df['heroes']) if len(x) == 1), :]  \n",
    "    df_one = df_one.reset_index().drop('index', axis=1)\n",
    "#     df_double = df.loc[(index for index, x in enumerate(df['heroes']) if len(x) == 2), :]  \n",
    "#     df_triple = df.loc[(index for index, x in enumerate(df['heroes']) if len(x) == 3), :]  \n",
    "\n",
    "    return df_one#, df_double, df_triple\n",
    "\n",
    "# вытащить таблицу с elo героев для команды \n",
    "def get_df_AvgElo_heroes_teams(id_radiant_or_dire):\n",
    "    # создать ссылку с данными по Avg.Elo для двух предыдущих месяцев игры\n",
    "    url = ('http://www.datdota.com/api/heroes/elo?teams={}&tier=1&valve-event=does-not-matter&threshold=5'.format(id_radiant_or_dire) +\n",
    "        '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03&patch=7.02' + \n",
    "        '&patch=7.01&patch=7.00&patch=6.88&patch=6.87&patch=6.86&winner=either'+\n",
    "        '&after=01%2F01%2F2011'+ \n",
    "        '&before={}%2F{}%2F{}'.format(date.today().day, date.today().month, date.today().year) + \n",
    "        '&duration=0%3B200&duration-value-from=0&duration-value-to=200')\n",
    "    # выгрузить все с сайта и создать ДФ\n",
    "    dat = get_json_from_url(url)\n",
    "    df_url = pd.DataFrame(dat.get('data'))\n",
    "\n",
    "    \n",
    "    # создать ДФ для соло героев за все время игр команды (сигнатурки)\n",
    "    return get_df_avgElo_heroes(df_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&patch=7.10&patch=7.11\n"
     ]
    }
   ],
   "source": [
    "def last_patch(last):\n",
    "    file =''\n",
    "    for i in range(10,last+1):\n",
    "        file += '&patch=7.'+str(i)\n",
    "    return file   \n",
    "print (last_patch(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Основная функция для предикта\n",
    "def PREDICT(radiant_team_name, radiant_team_id, radiant, dire_team_name, dire_team_id, dire):\n",
    "    # ВЫТАЩИТЬ из таблицы рейтинга пару героев\n",
    "    # создать правильную ссылку для посика героев по команде radiant\n",
    "    url = ('https://www.datdota.com/api/ratings')\n",
    "\n",
    "    # выгрзить json с предыдущей ссылки и создать ДФ\n",
    "    dat = get_json_from_url(url)\n",
    "    data = dat.get('data')\n",
    "    # создать DF для сохранения\n",
    "    all_teams = pd.DataFrame()\n",
    "    for i in data:   \n",
    "        # убрать повторяющиеся команды (DC и Infamous и Effect(FlipSide))\n",
    "        if (i.get('valveId') != 2512249) and (i.get('valveId') != 2672298) and (i.get('valveId') != 2790766):\n",
    "            team = get_data_team(i) \n",
    "            all_teams = pd.concat([all_teams, team], ignore_index=True)\n",
    "    all_teams = all_teams.drop(['phi_glicko', 'sigma_glicko2'],  axis=1)\n",
    "    \n",
    "    # Создание парметров для всех данных\n",
    "    # вытащить рейтинги двух команд и убрать имя\n",
    "    radiant_rating_df_allData = all_teams[all_teams['team_Name'] == radiant_team_name]\n",
    "    radiant_rating_df_allData = radiant_rating_df_allData.drop(['team_Name'],  axis=1)\n",
    "\n",
    "    dire_rating_df_allData = all_teams[all_teams['team_Name'] == dire_team_name]\n",
    "    dire_rating_df_allData = dire_rating_df_allData.drop(['team_Name'],  axis=1)\n",
    "    # соединить в один массив\n",
    "    df_rating_teams_allData = np.append(radiant_rating_df_allData, dire_rating_df_allData ) \n",
    "    \n",
    "    \n",
    "    # Создание парметров для алгоритмов без ело32 и ело64\n",
    "    # Оставляю только важные фичи, убираю из рейтинга команд ело32 и ело64\n",
    "    all_teams_without_Elo = all_teams.drop(all_teams.loc[:, 'current_elo32':'thirtyDayAvg_elo64'], axis=1)\n",
    "\n",
    "    # вытащить рейтинги двух команд и убрать имя\n",
    "    radiant_rating_df_without_Elo = all_teams_without_Elo[all_teams_without_Elo['team_Name'] == radiant_team_name]\n",
    "    radiant_rating_df_without_Elo = radiant_rating_df_without_Elo.drop(['team_Name'],  axis=1)\n",
    "    print (len(radiant_rating_df_without_Elo))\n",
    "    dire_rating_df_without_Elo = all_teams_without_Elo[all_teams_without_Elo['team_Name'] == dire_team_name]\n",
    "    dire_rating_df_without_Elo = dire_rating_df_without_Elo.drop(['team_Name'],  axis=1)\n",
    "    print (len(dire_rating_df_without_Elo))\n",
    "    # соединить в один массив\n",
    "    df_rating_teams_without_Elo = np.append(radiant_rating_df_without_Elo, dire_rating_df_without_Elo )\n",
    "    print (len(df_rating_teams_without_Elo))\n",
    "    \n",
    "    \n",
    "    #KDA Heroes\n",
    "    url_kda_Heroes = ('http://www.datdota.com/api/heroes/performances?patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07'+\n",
    "                    '&patch=7.06&patch=7.05&patch=7.04&patch=7.03&patch=7.02&patch=7.01&patch=7.00'+\n",
    "                  '&winner=either&after=01%2F01%2F2011&'+\n",
    "                      'before={}%2F{}%2F{}&duration=0%3B200'.format(date.today().day, date.today().month, date.today().year)+\n",
    "                  '&duration-value-from=0&duration-value-to=200&tier=1&valve-event=does-not-matter&threshold=10')\n",
    "    radiant_kdaHeroes = get_KDA(url_kda_Heroes, radiant)\n",
    "    dire_kdaHeroes = get_KDA(url_kda_Heroes, dire)\n",
    "    # соединить всех героев в один массив\n",
    "    df_kda_heroes = np.append(radiant_kdaHeroes, dire_kdaHeroes)\n",
    "    print (len(df_kda_heroes))\n",
    "    \n",
    "    #KDA Teams\n",
    "    # Radiant\n",
    "    url_heroes_radiant =('http://www.datdota.com/api/heroes/performances?teams={}'.format(radiant_team_id) + \n",
    "                         '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03'+\n",
    "                         '&patch=7.02&patch=7.01&patch=7.00&winner=either&after=01%2F01%2F2011&'+\n",
    "                         'before={}%2F{}%2F{}'.format(date.today().day, date.today().month, date.today().year)+\n",
    "                         '&duration=0%3B200&duration-value-from=0&duration-value-to=200&tier=1&valve-event='+\n",
    "                         'does-not-matter&threshold=1') \n",
    "    radiant_kdaHeroes = get_KDA(url_heroes_radiant, radiant)\n",
    "    #Dire\n",
    "    url_heroes_dire =('http://www.datdota.com/api/heroes/performances?teams={}'.format(dire_team_id) + \n",
    "                      '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03'+\n",
    "                      '&patch=7.02&patch=7.01&patch=7.00&winner=either&after=01%2F01%2F2011&'+\n",
    "                      'before={}%2F{}%2F{}&'.format(date.today().day, date.today().month, date.today().year)+\n",
    "                      'duration=0%3B200&duration-value-from=0&duration-value-to=200&tier=1&valve-event=does-not-matter'+\n",
    "                      '&threshold=1') \n",
    "    dire_kdaHeroes = get_KDA(url_heroes_dire, dire)\n",
    "    print (len(radiant_kdaHeroes))\n",
    "    print (len(dire_kdaHeroes))\n",
    "    df_kda_heroes_teams = np.append(radiant_kdaHeroes, dire_kdaHeroes)\n",
    "    df_kda_heroes_teams = np.nan_to_num(df_kda_heroes_teams)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Elo героя относительно его врагов (Head-to_head)\n",
    "    url_Head_to_head_allPatch = ('http://www.datdota.com/api/heroes/head-to-head-elo?tier=1&valve-event='+\n",
    "                                 'does-not-matter&threshold=1&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06'+\n",
    "                                 '&patch=7.05&patch=7.04&patch=7.03&patch=7.02&patch=7.01&patch=7.00&patch=6.88&patch=6.87&'+\n",
    "                                 'patch=6.86&patch=6.85&patch=6.84&patch=6.83&patch=6.82&patch=6.81&patch=6.80&patch=6.79&'+\n",
    "                                 'patch=6.78&patch=6.77&patch=6.76&patch=6.75&patch=6.74&winner=either&after=01%2F01%2F2011&'+\n",
    "                                 'before={}%2F{}%2F{}'.format(date.today().day, date.today().month, date.today().year)+\n",
    "                                 '&duration=0%3B200&duration-value-from=0&duration-value-to=200')\n",
    "    head_to_head_allPatch = get_elo_head_to_head(url_Head_to_head_allPatch)\n",
    "    print (len(head_to_head_allPatch))\n",
    "\n",
    "\n",
    "    # Метовые герои AvgElo\n",
    "    # ДФ для соединения всех герове матча в один ДФ \n",
    "    df_heroes_match_AvgElo = []\n",
    "    # создать дату два месяца назад от даты матча\n",
    "    two_month_ago = date.today() - timedelta(60)\n",
    "    # создать ссылку с данными по Avg.Elo для двух предыдущих месяцев игры\n",
    "    url = ('http://www.datdota.com/api/heroes/elo?tier=1&valve-event=does-not-matter&threshold=10' +\n",
    "        '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03&patch=7.02' + \n",
    "        '&patch=7.01&patch=7.00&patch=6.88&patch=6.87&patch=6.86&winner=either'+\n",
    "        '&after={}%2F{}%2F{}'.format(two_month_ago.day, two_month_ago.month, two_month_ago.year) + \n",
    "        '&before={}%2F{}%2F{}'.format(date.today().day, date.today().month, date.today().year) + \n",
    "        '&duration=0%3B200&duration-value-from=0&duration-value-to=200')\n",
    "    # выгрузить все с сайта и создать ДФ\n",
    "    dat = get_json_from_url(url)\n",
    "    df_url = pd.DataFrame(dat.get('data'))\n",
    "    # создать ДФ для одного героя за 2 предыдущих месяца\n",
    "    df_data_tabel_for_heroes = get_df_avgElo_heroes(df_url)\n",
    "\n",
    "    for her in (radiant + dire):\n",
    "        # вытащить avg elo для данного героя\n",
    "        avgElo_hero = df_data_tabel_for_heroes.loc[(index for index, x in enumerate(\n",
    "                                            df_data_tabel_for_heroes['heroes']) if x == [her]),'eloShift']\n",
    "\n",
    "        # проверить есть ли герой\n",
    "        try:\n",
    "            avgElo_hero = float(avgElo_hero)\n",
    "        except:\n",
    "            avgElo_hero = 0\n",
    "        df_heroes_match_AvgElo.append(avgElo_hero)\n",
    "    print(len(df_heroes_match_AvgElo))\n",
    "\n",
    "    # ДФ для соединения всех герове матча в один ДФ \n",
    "    df_heroes_match_radiant = []\n",
    "    df_heroes_match_dire = []\n",
    "    # создать дату два месяца назад от даты матча\n",
    "    two_month_ago = date.today() - timedelta(60)\n",
    "\n",
    "    # RADIANT\n",
    "    # создать ДФ для одного героя за 2 предыдущих месяца\n",
    "    df_data_tabel_radiant = get_df_AvgElo_heroes_teams(radiant_team_id)\n",
    "\n",
    "    for her in (radiant):\n",
    "        # вытащить avg elo для данного героя\n",
    "        avgElo_hero = df_data_tabel_radiant.loc[(index for index, x in enumerate(\n",
    "                                            df_data_tabel_radiant['heroes']) if x == [her]),'eloShift']\n",
    "        # проверить есть ли герой\n",
    "        try:\n",
    "            avgElo_hero = float(avgElo_hero)\n",
    "        except:\n",
    "            avgElo_hero = 0\n",
    "        df_heroes_match_radiant.append(avgElo_hero)\n",
    "\n",
    "    #DIRE\n",
    "    # создать ДФ для одного героя за 2 предыдущих месяца\n",
    "    df_data_tabel_dire = get_df_AvgElo_heroes_teams(dire_team_id)\n",
    "\n",
    "    for her in (dire):\n",
    "        # вытащить avg elo для данного героя\n",
    "        avgElo_hero = df_data_tabel_dire.loc[(index for index, x in enumerate(\n",
    "                                            df_data_tabel_dire['heroes']) if x == [her]),'eloShift']\n",
    "        # проверить есть ли герой\n",
    "        try:\n",
    "            avgElo_hero = float(avgElo_hero)\n",
    "        except:\n",
    "            avgElo_hero = 0\n",
    "        df_heroes_match_dire.append(avgElo_hero)\n",
    "    df_heroes_teams_AvgElo = np.append(df_heroes_match_radiant, df_heroes_match_dire)\n",
    "    print (len(df_heroes_teams_AvgElo))\n",
    "\n",
    "    # Соединить все в один массив для предсказания без учета КДА, Ело32 и Ело64\n",
    "    # Для данныз из head_to_head по всем патчам\n",
    "    main_array_allPatch = np.append(df_rating_teams_without_Elo, head_to_head_allPatch)\n",
    "    main_array_allPatch = np.append(main_array_allPatch, df_heroes_match_AvgElo)\n",
    "    main_array_allPatch = np.append(main_array_allPatch, df_heroes_teams_AvgElo)\n",
    "    Dmatrix_without_Elo = pd.DataFrame(main_array_allPatch, index=['radiant_mu_glicko', 'radiant_rating_glicko',\n",
    "           'radiant_ratingSevenDaysAgo_glicko', 'radiant_sigma_glicko',\n",
    "           'radiant_mu_glicko2', 'radiant_phi_glicko2', 'radiant_rating_glicko2',\n",
    "           'radiant_ratingSevenDaysAgo_glicko2', 'dire_mu_glicko',\n",
    "           'dire_rating_glicko', 'dire_ratingSevenDaysAgo_glicko',\n",
    "           'dire_sigma_glicko', 'dire_mu_glicko2', 'dire_phi_glicko2',\n",
    "           'dire_rating_glicko2', 'dire_ratingSevenDaysAgo_glicko2',\n",
    "           'radiant_H1elo_vs_enemies', 'radiant_H2elo_vs_enemies',\n",
    "           'radiant_H3elo_vs_enemies', 'radiant_H4elo_vs_enemies',\n",
    "           'radiant_H5elo_vs_enemies', 'dire_H1elo_vs_enemies',\n",
    "           'dire_H2elo_vs_enemies', 'dire_H3elo_vs_enemies',\n",
    "           'dire_H4elo_vs_enemies', 'dire_H5elo_vs_enemies', 'radiant_H1_AvgElo_x',\n",
    "           'radiant_H2_AvgElo_x', 'radiant_H3_AvgElo_x', 'radiant_H4_AvgElo_x',\n",
    "           'radiant_H5_AvgElo_x', 'dire_H1_AvgElo_x', 'dire_H2_AvgElo_x',\n",
    "           'dire_H3_AvgElo_x', 'dire_H4_AvgElo_x', 'dire_H5_AvgElo_x',\n",
    "           'radiant_H1_AvgElo_y', 'radiant_H2_AvgElo_y', 'radiant_H3_AvgElo_y',\n",
    "           'radiant_H4_AvgElo_y', 'radiant_H5_AvgElo_y', 'dire_H1_AvgElo_y',\n",
    "           'dire_H2_AvgElo_y', 'dire_H3_AvgElo_y', 'dire_H4_AvgElo_y',\n",
    "           'dire_H5_AvgElo_y']).T\n",
    "    len(main_array_allPatch)\n",
    "           \n",
    "    # Соединить все в один массив для предсказания co всеми данными\n",
    "    main_array_allPatch_allData = np.append(df_rating_teams_allData, df_kda_heroes)\n",
    "    main_array_allPatch_allData = np.append(main_array_allPatch_allData, df_kda_heroes_teams)\n",
    "    main_array_allPatch_allData = np.append(main_array_allPatch_allData, head_to_head_allPatch)\n",
    "    main_array_allPatch_allData = np.append(main_array_allPatch_allData, df_heroes_match_AvgElo)\n",
    "    main_array_allPatch_allData = np.append(main_array_allPatch_allData, df_heroes_teams_AvgElo)\n",
    "\n",
    "    # Соединить все в один массив для предсказания без рейтинга команд\n",
    "    main_array_allPatch_without_rating = np.append(head_to_head_allPatch, df_heroes_match_AvgElo)\n",
    "    main_array_allPatch_without_rating = np.append(main_array_allPatch_without_rating, df_heroes_teams_AvgElo)\n",
    "    Dmatrix_without_rating = pd.DataFrame(main_array_allPatch_without_rating, index=[\n",
    "           'radiant_H1elo_vs_enemies', 'radiant_H2elo_vs_enemies',\n",
    "           'radiant_H3elo_vs_enemies', 'radiant_H4elo_vs_enemies',\n",
    "           'radiant_H5elo_vs_enemies', 'dire_H1elo_vs_enemies',\n",
    "           'dire_H2elo_vs_enemies', 'dire_H3elo_vs_enemies',\n",
    "           'dire_H4elo_vs_enemies', 'dire_H5elo_vs_enemies', 'radiant_H1_AvgElo_x',\n",
    "           'radiant_H2_AvgElo_x', 'radiant_H3_AvgElo_x', 'radiant_H4_AvgElo_x',\n",
    "           'radiant_H5_AvgElo_x', 'dire_H1_AvgElo_x', 'dire_H2_AvgElo_x',\n",
    "           'dire_H3_AvgElo_x', 'dire_H4_AvgElo_x', 'dire_H5_AvgElo_x',\n",
    "           'radiant_H1_AvgElo_y', 'radiant_H2_AvgElo_y', 'radiant_H3_AvgElo_y',\n",
    "           'radiant_H4_AvgElo_y', 'radiant_H5_AvgElo_y', 'dire_H1_AvgElo_y',\n",
    "           'dire_H2_AvgElo_y', 'dire_H3_AvgElo_y', 'dire_H4_AvgElo_y',\n",
    "           'dire_H5_AvgElo_y']).T\n",
    "    return (Dmatrix_without_Elo, Dmatrix_without_rating, main_array_allPatch, main_array_allPatch_allData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Anti-Mage', 'Axe', 'Bane', 'Bloodseeker', 'Crystal Maiden',\n",
       "       'Drow Ranger', 'Earthshaker', 'Juggernaut', 'Mirana', 'Morphling',\n",
       "       'Shadow Fiend', 'Phantom Lancer', 'Puck', 'Pudge', 'Razor',\n",
       "       'Sand King', 'Storm Spirit', 'Sven', 'Tiny', 'Vengeful Spirit',\n",
       "       'Windranger', 'Zeus', 'Kunkka', 'Lina', 'Lion', 'Shadow Shaman',\n",
       "       'Slardar', 'Tidehunter', 'Witch Doctor', 'Lich', 'Riki', 'Enigma',\n",
       "       'Tinker', 'Sniper', 'Necrophos', 'Warlock', 'Beastmaster',\n",
       "       'Queen of Pain', 'Venomancer', 'Faceless Void', 'Wraith King',\n",
       "       'Death Prophet', 'Phantom Assassin', 'Pugna', 'Templar Assassin',\n",
       "       'Viper', 'Luna', 'Dragon Knight', 'Dazzle', 'Clockwerk', 'Leshrac',\n",
       "       \"Nature's Prophet\", 'Lifestealer', 'Dark Seer', 'Clinkz',\n",
       "       'Omniknight', 'Enchantress', 'Huskar', 'Night Stalker',\n",
       "       'Broodmother', 'Bounty Hunter', 'Weaver', 'Jakiro', 'Batrider',\n",
       "       'Chen', 'Spectre', 'Ancient Apparition', 'Doom', 'Ursa',\n",
       "       'Spirit Breaker', 'Gyrocopter', 'Alchemist', 'Invoker', 'Silencer',\n",
       "       'Outworld Devourer', 'Lycan', 'Brewmaster', 'Shadow Demon',\n",
       "       'Lone Druid', 'Chaos Knight', 'Meepo', 'Treant Protector',\n",
       "       'Ogre Magi', 'Undying', 'Rubick', 'Disruptor', 'Nyx Assassin',\n",
       "       'Naga Siren', 'Keeper of the Light', 'Io', 'Visage', 'Slark',\n",
       "       'Medusa', 'Troll Warlord', 'Centaur Warrunner', 'Magnus',\n",
       "       'Timbersaw', 'Bristleback', 'Tusk', 'Skywrath Mage', 'Abaddon',\n",
       "       'Elder Titan', 'Legion Commander', 'Techies', 'Ember Spirit',\n",
       "       'Earth Spirit', 'Underlord', 'Terrorblade', 'Phoenix', 'Oracle',\n",
       "       'Winter Wyvern', 'Arc Warden', 'Monkey King', 'Dark Willow',\n",
       "       'Pangolier'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teams_name_id = pd.read_csv('../Teams name and ID.csv', index_col=0)\n",
    "\n",
    "list_heroes = pd.read_csv('../All_Heroes.csv')\n",
    "np.array(list_heroes['localized_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiant_team_name =   \"Vega Squadron\" \n",
    "dire_team_name = 'Team. Spirit'\n",
    "\n",
    "radiant_team_id =   2006913\n",
    "dire_team_id =     2621843\n",
    "\n",
    "radiant_H1 = list_heroes['id'][list_heroes['localized_name'] == \"Earth Spirit\"].item()\n",
    "radiant_H2 = list_heroes['id'][list_heroes['localized_name'] == \"Rubick\"].item()\n",
    "radiant_H3 = list_heroes['id'][list_heroes['localized_name'] == \"Viper\"].item()\n",
    "radiant_H4 = list_heroes['id'][list_heroes['localized_name'] == \"Underlord\"].item()\n",
    "radiant_H5 = list_heroes['id'][list_heroes['localized_name'] == \"Lifestealer\"].item()\n",
    "dire_H1 = list_heroes['id'][list_heroes['localized_name'] == \"Gyrocopter\"].item()\n",
    "dire_H2 = list_heroes['id'][list_heroes['localized_name'] == \"Night Stalker\"].item()\n",
    "dire_H3 = list_heroes['id'][list_heroes['localized_name'] == \"Bane\"].item()\n",
    "dire_H4 = list_heroes['id'][list_heroes['localized_name'] == \"Lycan\"].item()\n",
    "dire_H5 = list_heroes['id'][list_heroes['localized_name'] == \"Elder Titan\"].item()\n",
    "\n",
    "radiant = [radiant_H1, radiant_H2, radiant_H3, radiant_H4, radiant_H5]\n",
    "dire = [dire_H1, dire_H2, dire_H3, dire_H4, dire_H5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сбор всех таблиц\n",
    "# Рейтинг команд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "16\n",
      "140\n",
      "70\n",
      "70\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "Dmatrix_without_Elo, Dmatrix_without_rating, main_array_allPatch, main_array_allPatch_allData = PREDICT(\n",
    "    radiant_team_name, radiant_team_id, radiant, dire_team_name, dire_team_id, dire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель обученая На всех патчах до дня матча\n",
      "[1]\n",
      "[[ 0.32518451  0.67481549]]\n",
      "------------------------------------------------------------------------------------------------\n",
      "Модель обученая На всех патчах до 2018.05.06\n",
      "[0]\n",
      "[[ 0.51691507  0.48308493]]\n",
      "------------------------------------------------------------------------------------------------\n",
      "Модель xgb обученая На всех патчах до 2018.05.06\n",
      "[0]\n",
      "[[ 0.69262183  0.30737814]]\n",
      "------------------------------------------------------------------------------------------------\n",
      "Модель обученая На всех патчах до дня матча без повторяющихся команд в таблице рейтинга\n",
      "[0]\n",
      "[[ 0.83527889  0.16472111]]\n",
      "------------------------------------------------------------------------------------------------\n",
      "Модель обученая На всех патчах до 2018.05.06 без повторяющихся команд в таблице рейтинга\n",
      "[0]\n",
      "[[ 0.87981985  0.12018015]]\n",
      "Модель обученая На всех патчах до 2018.05.06 без повтор команд в таблице рейтинга без рейтинга команд (по пикам)\n",
      "[0]\n",
      "[[ 0.58561766  0.41438231]]\n"
     ]
    }
   ],
   "source": [
    "filename = 'grid_search_GB_model_allData_dayMatch.sav'\n",
    "test_gb = pickle.load(open(filename, 'rb'))\n",
    "print('Модель обученая На всех патчах до дня матча')\n",
    "print (test_gb.predict([main_array_allPatch_allData]))\n",
    "print (test_gb.predict_proba([main_array_allPatch_allData]))\n",
    "print ('------------------------------------------------------------------------------------------------')\n",
    "\n",
    "filename = 'grid_search_GB_model_allData_2018.05.06.sav'\n",
    "test_gb = pickle.load(open(filename, 'rb'))\n",
    "print('Модель обученая На всех патчах до 2018.05.06')\n",
    "print (test_gb.predict([main_array_allPatch_allData]))\n",
    "print (test_gb.predict_proba([main_array_allPatch_allData]))\n",
    "print ('------------------------------------------------------------------------------------------------')\n",
    "\n",
    "filename = 'xgb_all_data v.1.1 .sav'\n",
    "test_gb = pickle.load(open(filename, 'rb'))\n",
    "print('Модель xgb обученая На всех патчах до 2018.05.06')\n",
    "print (test_gb.predict(Dmatrix_without_Elo))\n",
    "print (test_gb.predict_proba(Dmatrix_without_Elo))\n",
    "print ('------------------------------------------------------------------------------------------------')\n",
    "\n",
    "filename = 'grid_search_GB_model v.1.1.b (day match without repeated rating teams) .sav'\n",
    "test_gb = pickle.load(open(filename, 'rb'))\n",
    "print('Модель обученая На всех патчах до дня матча без повторяющихся команд в таблице рейтинга')\n",
    "print (test_gb.predict([main_array_allPatch]))\n",
    "print (test_gb.predict_proba([main_array_allPatch]))\n",
    "print ('------------------------------------------------------------------------------------------------')\n",
    "\n",
    "filename = 'grid_search_GB_model v.1.1.a (day 12.02.18 without repeated rating teams) .sav'\n",
    "test_gb = pickle.load(open(filename, 'rb'))\n",
    "print('Модель обученая На всех патчах до 2018.05.06 без повторяющихся команд в таблице рейтинга')\n",
    "print (test_gb.predict([main_array_allPatch]))\n",
    "print (test_gb.predict_proba([main_array_allPatch]))\n",
    "\n",
    "filename = 'xgb_all_data v.2.1.a (day 12.02.18 without repeated rating teams) .sav'\n",
    "test_gb = pickle.load(open(filename, 'rb'))\n",
    "print('Модель обученая На всех патчах до 2018.05.06 без повтор команд в таблице рейтинга без рейтинга команд (по пикам)')\n",
    "print (test_gb.predict(Dmatrix_without_rating))\n",
    "print (test_gb.predict_proba(Dmatrix_without_rating))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
