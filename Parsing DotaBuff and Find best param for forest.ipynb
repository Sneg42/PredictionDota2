{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import urllib.request\n",
    "import bs4 as bs\n",
    "import requests\n",
    "\n",
    "def soup_from_url(url):\n",
    "    sauce = urllib.request.Request(url, headers={'User-agent': 'Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11'} )\n",
    "    sauce = urllib.request.urlopen(sauce).read()\n",
    "\n",
    "    soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "    return soup\n",
    "\n",
    "#List teams Dota 2 from site gamepedia (CORRECT VARIANT)\n",
    "def pick_up_nameTeam(url):\n",
    "    soup = soup_from_url(url)\n",
    "    body = soup.body  \n",
    "    list_team = []\n",
    "    i=0\n",
    "    for par in body.find_all('caption'):\n",
    "        for name in par.find_all('a'):\n",
    "            s = name.text\n",
    "            if s == 'The Dire' or len(s) == 0:\n",
    "                break\n",
    "            else:\n",
    "                list_team.append(s)\n",
    "    return list_team\n",
    "\n",
    "list_teamName = pick_up_nameTeam('https://dota2.gamepedia.com/Professional_teams')  \n",
    "\n",
    "#List of all Heroes in Dota2\n",
    "def pick_up_Heroes(url):\n",
    "    soup = soup_from_url(url)\n",
    "    body = soup.body    \n",
    "    list_Heroes=[]\n",
    "    for par in body.find_all('div', class_='name'):\n",
    "        list_Heroes.append(par.text)\n",
    "    return list_Heroes\n",
    "\n",
    "Heroes = pick_up_Heroes('https://ru.dotabuff.com/heroes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List teams Dota 2 from site game-tournament\n",
    "# def pick_up_nameTeam(url, list_team):\n",
    "#     soup = soup_from_url(url)\n",
    "#     body = soup.body    \n",
    "#     i=0\n",
    "#     for par in body.find_all('a', class_='teamname1'):\n",
    "#         if i < 20:\n",
    "#             list_team.append(par.get('title'))\n",
    "#         i+=1\n",
    "\n",
    "# list_teamName=[]\n",
    "\n",
    "# pick_up_nameTeam('http://game-tournaments.com/dota-2/team', list_teamName)\n",
    "# pick_up_nameTeam('http://game-tournaments.com/dota-2/team?s=2', list_teamName)\n",
    "# pick_up_nameTeam('http://game-tournaments.com/dota-2/team?s=3', list_teamName)\n",
    "\n",
    "# remove wrong team\n",
    "# list_teamName.remove('Gorillaz-Pride')\n",
    "\n",
    "\n",
    "#change name team\n",
    "#list_teamName.remove('OG')\n",
    "#list_teamName.insert(1, 'OG Dota2')\n",
    "# list_teamName.remove('Virtus.Pro')\n",
    "# list_teamName.insert(1, 'Virtus.pro')\n",
    "# list_teamName.remove('NewBee')\n",
    "# list_teamName.insert(1, 'Newbee')\n",
    "# list_teamName.remove('Team Effect')\n",
    "# list_teamName.insert(39, 'Effect')\n",
    "# list_teamName.remove('LGD Gaming')\n",
    "# list_teamName.insert(4, 'LGD-GAMING')\n",
    "\n",
    "#add team\n",
    "# list_teamName.append('Faceless')\n",
    "# list_teamName.append('Mineski')\n",
    "# list_teamName.append('compLexity Gaming')\n",
    "# list_teamName.append('Alliance')\n",
    "\n",
    "\n",
    "#list_teamName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pick up all matches from site DOTABUFF\n",
    "def pick_up_matches(url, list_with_matches):\n",
    "    sauce = urllib.request.Request(url, \n",
    "                                   headers={'User-agent': 'Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11'})\n",
    "    sauce = urllib.request.urlopen(sauce).read()\n",
    "\n",
    "    soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "    body = soup.body\n",
    "    #matches_all_data = []\n",
    "\n",
    "    for paragraph in body.find_all('a', class_='match-score'):\n",
    "        #counters for radiant or dire, if j=0 then all data filling for radiant, else dire\n",
    "        j=0\n",
    "        match = []\n",
    "\n",
    "        # choose name team in the match, 1st team - radiant, 2nd - dire\n",
    "        for span in paragraph.find_all('span', class_=('team-text')):\n",
    "            \n",
    "#             #add name team\n",
    "#             try:\n",
    "#                 number_team = list_teamName.index(span.text)\n",
    "#             except ValueError:\n",
    "#                 print (span.text)\n",
    "#                 break;\n",
    "                \n",
    "#             #match.append(number_team)\n",
    "            \n",
    "            for team_winner in paragraph.find_all('div', class_= ('match-score-teams')):\n",
    "\n",
    "                #count for 1st & 2nd team. if j=0 then 1st team else 2nd team in the match\n",
    "                if j == 1:    \n",
    "                    for team in team_winner.find_all('div', class_= ( 'radiant team-winner')):\n",
    "                        winner = 0\n",
    "                else:\n",
    "                    for team in team_winner.find_all('div', class_= ( 'dire team-winner')):\n",
    "                        winner = 1\n",
    "\n",
    "            #choose all heroes the correct team\n",
    "            for team_heroes in paragraph.find_all('div', class_= ('match-score-heroes')):\n",
    "                if j == 0:\n",
    "                    for team in team_heroes.find_all('div', class_= ('radiant')):\n",
    "                        for heroes in team.find_all('img', class_='image-hero') :\n",
    "                            match.append(int(Heroes.index(heroes.get('title'))))\n",
    "                else:\n",
    "                    for team in team_heroes.find_all('div', class_= ('dire')):\n",
    "                        for heroes in team.find_all('img', class_='image-hero') :\n",
    "                            match.append(int(Heroes.index(heroes.get('title'))))\n",
    "                    #add last elements if 0 then win radiant, 1 - dire\n",
    "                        match.append(winner)\n",
    "\n",
    "            #add all data for match in list with all matches\n",
    "            \n",
    "            j+=1\n",
    "        #if len(match) == 11:\n",
    "        list_with_matches.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Epicenter 2017\n",
    "list_matches_Epicenter = []\n",
    "url_Epicenter = 'https://ru.dotabuff.com/esports/leagues/5353-epicenter-moscow-season-2/scores?original_slug=5353-epicenter-moscow-season-2&series_status=live_or_completed'\n",
    "pick_up_matches(url_Epicenter, list_matches_Epicenter)\n",
    "\n",
    "#Dream league 2017\n",
    "list_matches_Dream2017 = []\n",
    "url_Dream2017 = 'https://ru.dotabuff.com/esports/leagues/5336-dreamleague-season-7/scores?original_slug=5336-dreamleague-season-7'\n",
    "pick_up_matches(url_Dream2017, list_matches_Dream2017)\n",
    "\n",
    "#MDL 2017\n",
    "list_matches_MDL2017 = []\n",
    "url_MDL2017 = 'https://ru.dotabuff.com/esports/leagues/5504-2017-mars-dota-2-league/scores'\n",
    "pick_up_matches(url_MDL2017, list_matches_MDL2017)\n",
    "\n",
    "#The Summit\n",
    "list_matches_Summit = []\n",
    "url_Summit = 'https://ru.dotabuff.com/esports/leagues/4442-the-summit-5/scores'\n",
    "pick_up_matches(url_Summit, list_matches_Summit)\n",
    "\n",
    "#Galaxy Battle\n",
    "list_matches_Galaxy = []\n",
    "url_Galaxy = 'https://ru.dotabuff.com/esports/leagues/5399-neso-4th-national-e-sports-shenzhen-open-tournament-galaxy-battles/scores'\n",
    "pick_up_matches(url_Galaxy, list_matches_Galaxy)\n",
    "\n",
    "#The Kiev Major\n",
    "list_matches_KievMajor = []\n",
    "url_KievMajor = 'https://ru.dotabuff.com/esports/leagues/5157-kiev-major/scores'\n",
    "pick_up_matches(url_KievMajor, list_matches_KievMajor)\n",
    "\n",
    "url_KievMajor = 'https://ru.dotabuff.com/esports/leagues/5157-kiev-major/scores?original_slug=5157-kiev-major&page=2'\n",
    "pick_up_matches(url_KievMajor, list_matches_KievMajor)\n",
    "\n",
    "url_KievMajor = 'https://ru.dotabuff.com/esports/leagues/5157-kiev-major/scores?original_slug=5157-kiev-major&page=3'\n",
    "pick_up_matches(url_KievMajor, list_matches_KievMajor)\n",
    "\n",
    "#The International 2017\n",
    "list_matches_International2017 = []\n",
    "url_International2017 = 'https://ru.dotabuff.com/esports/leagues/5401-the-international-2017/scores'\n",
    "pick_up_matches(url_International2017, list_matches_International2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create testing data from data The International\n",
    "df_International = pd.DataFrame(list_matches_International2017, columns= ['H1_t1', 'H2_t1','H3_t1','H4_t1','H5_t1','H1_t2', 'H2_t2', 'H3_t2', 'H4_t2','H5_t2', 'winner'])\n",
    "\n",
    "test_matches = df_International.drop(['winner'], axis='columns')\n",
    "test_winner =  (df_International.winner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def dataFrame_\n",
    "#df = pd.DataFrame(list_matches_Epicenter, columns= ['team_name', 'H1_t1', 'H2_t1','H3_t1','H4_t1','H5_t1','team_name','H1_t2', 'H2_t2', 'H3_t2', 'H4_t2','H5_t2', 'winner'])\n",
    "list_all_matches =  (list_matches_Epicenter + list_matches_MDL2017 + list_matches_Dream2017 + list_matches_Summit +\n",
    "                    list_matches_Galaxy + list_matches_KievMajor)\n",
    "\n",
    "df = pd.DataFrame(list_all_matches, columns= ['H1_t1', 'H2_t1','H3_t1','H4_t1','H5_t1','H1_t2', 'H2_t2', 'H3_t2', 'H4_t2','H5_t2', 'winner'])\n",
    "\n",
    "training_matchs = df.drop(['winner'], axis='columns').dropna()\n",
    "\n",
    "training_winner =  (df.winner.dropna())\n",
    "\n",
    "#print (training_winner.append(test_winner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Sneg\\Add.Program\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree:\n",
      "Training data: 0.70\n",
      "Test data (International 2017): 0.59\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=8)\n",
    "#clf = svm.SVR()\n",
    "clf.fit(training_matchs, training_winner)\n",
    "\n",
    "#testing on International \n",
    "predict_df = pd.DataFrame(clf.predict(test_matches), columns=['Predict'])\n",
    "predict_df['correct'] = test_winner\n",
    "\n",
    "accuarcy = clf.score(test_matches, test_winner)\n",
    "\n",
    "print ('Tree:')\n",
    "print ('Training data: {:.2f}'.format(clf.score(training_matchs, training_winner)))\n",
    "print ('Test data (International 2017): {:.2f}'.format(clf.score(test_matches, test_winner)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest:\n",
      "Training data: 0.88\n",
      "Test data (International 2017): 0.60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=15, random_state=42, max_depth=7, max_features=5)\n",
    "\n",
    "forest.fit(training_matchs, training_winner)\n",
    "\n",
    "print ('Forest:')\n",
    "print ('Training data: {:.2f}'.format(forest.score(training_matchs, training_winner)))\n",
    "print ('Test data (International 2017): {:.2f}'.format(forest.score(test_matches, test_winner)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#importances features (Heroes)\n",
    "def plot_feature_importances_cancer(model):\n",
    "    plt.barh(training_matchs.columns, model.feature_importances_)\n",
    "    plt.xlabel('Важность признаков')\n",
    "    plt.ylabel('Признак')\n",
    "plot_feature_importances_cancer(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with split data:\n",
      "Training data: 0.99\n",
      "Test data: 0.42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    training_matchs.append(test_matches), training_winner.append(test_winner), random_state=0)\n",
    "\n",
    "forest_split_data = RandomForestClassifier(n_estimators=22, random_state=42, max_depth=14, max_features=8)\n",
    "\n",
    "forest_split_data.fit(X_train, y_train)\n",
    "print ('Forest with split data:')\n",
    "\n",
    "print ('Training data: {:.2f}'.format(forest_split_data.score(X_train, y_train)))\n",
    "print ('Test data: {:.2f}'.format(forest_split_data.score(X_test, y_test,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', 'X', 'X', '1', 'X', '0', '1', 'X', '1', 'X', 'X', 'X', '1',\n",
       "       '0', 'X', '1', 'X', 'X', 'X', 'X', 'X', '1', 'X', 'X', '1', 'X',\n",
       "       '1', 'X', 'X', '0', 'X', 'X', 'X', 'X', '0', '1', '0', '0', 'X',\n",
       "       '0', 'X', 'X', 'X', '0', 'X', 'X', '0', 'X', 'X', 'X', 'X', 'X',\n",
       "       '0', 'X', 'X', 'X', 'X', '0', 'X', '1', 'X', '1', '1', 'X', 'X',\n",
       "       'X', 'X', 'X', '0', '0', 'X', 'X', 'X', '1', 'X', '1', 'X', 'X',\n",
       "       '0', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X',\n",
       "       '0', 'X', 'X', '0', 'X', 'X', 'X', '0', 'X', 'X', 'X', '1', '1',\n",
       "       'X', '0', '1', 'X', 'X', '0', '0', '1', 'X', 'X', 'X', '1', 'X',\n",
       "       '0', 'X', '0', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', '0', 'X',\n",
       "       'X', '1', 'X', 'X', '1', '0', '1', 'X', '0', 'X', 'X', 'X', '1',\n",
       "       '0', 'X', '0', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', '0',\n",
       "       'X', '0', 'X', '0', 'X', '1', '0', '0', 'X', 'X', 'X', '1', 'X',\n",
       "       'X', 'X', 'X', 'X', 'X', 'X', '0', '1', '1', 'X', 'X', 'X', '1',\n",
       "       'X', '1', 'X', 'X', 'X', '0', 'X', 'X', '1', 'X', 'X', '0', 'X',\n",
       "       'X', '1', 'X', '1', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X',\n",
       "       '0', 'X'],\n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создать список предсказаний с минималным значением предик проба равным perc\n",
    "perc = 0.65\n",
    "arr = []\n",
    "for x in forest_split_data.predict_proba(X_test):\n",
    "    if (x[0]>=perc):\n",
    "        arr.append(0)\n",
    "        continue\n",
    "    if(x[1]>=perc):\n",
    "        arr.append(1)\n",
    "        continue\n",
    "    else:\n",
    "        arr.append('X')\n",
    "        continue\n",
    "arr = np.array(arr)\n",
    "#массив правильных ответов\n",
    "arr_correct = np.array(y_test)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "69\n"
     ]
    }
   ],
   "source": [
    "# Предсказания с предик проба с убиранеим \"Х\" и вывод конечного массива предсказаний и его длины\n",
    "predict = []\n",
    "for index,a in enumerate(arr):\n",
    "    if a =='X':\n",
    "        pass\n",
    "    else:\n",
    "        #print ('Предсказание {}'.format(float(arr[index])))\n",
    "        #print ('Правильно {}',format(arr_correct[index]))\n",
    "        if (float(arr[index]) == arr_correct[index]):\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "predict = np.array(predict)\n",
    "predict.sort()\n",
    "print (predict)\n",
    "print(len(predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нахождение лучших параметров для Леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Тестовая выборка это интернешнл 2017\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "all_parametrs=[]\n",
    "for n in range(50, 101):\n",
    "    for depth in range(1, 25):\n",
    "        for features in range(1, 10):\n",
    "            parametrs=[]\n",
    "            forest_optim_param = RandomForestClassifier(n_estimators=n, random_state=42, \n",
    "                                                        max_depth=depth, max_features=features)\n",
    "            forest_optim_param.fit(training_matchs, training_winner)\n",
    "            parametrs.append(n)\n",
    "            parametrs.append(depth)\n",
    "            parametrs.append(features)\n",
    "            parametrs.append(forest_optim_param.score(training_matchs, training_winner))\n",
    "            parametrs.append(forest_optim_param.score(test_matches, test_winner))\n",
    "            all_parametrs.append(parametrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_test=[]\n",
    "\n",
    "for par in all_parametrs:\n",
    "    if par[4] > 0.6299:\n",
    "        all_test.append(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[51, 7, 4, 0.95669824086603517, 0.63],\n",
       " [51, 14, 9, 0.99594046008119075, 0.64000000000000001],\n",
       " [52, 14, 9, 0.99594046008119075, 0.63],\n",
       " [53, 7, 4, 0.95805142083897155, 0.63],\n",
       " [53, 23, 7, 0.99594046008119075, 0.63],\n",
       " [53, 24, 7, 0.99594046008119075, 0.63],\n",
       " [54, 7, 4, 0.95805142083897155, 0.63],\n",
       " [55, 24, 7, 0.99594046008119075, 0.63],\n",
       " [73, 11, 9, 0.99594046008119075, 0.64000000000000001],\n",
       " [75, 14, 9, 0.99594046008119075, 0.63],\n",
       " [76, 12, 7, 0.99594046008119075, 0.63],\n",
       " [78, 13, 1, 0.99594046008119075, 0.63],\n",
       " [85, 11, 9, 0.99594046008119075, 0.63],\n",
       " [87, 11, 9, 0.99594046008119075, 0.63],\n",
       " [90, 11, 9, 0.99594046008119075, 0.63],\n",
       " [91, 12, 6, 0.99594046008119075, 0.63],\n",
       " [92, 11, 9, 0.99594046008119075, 0.64000000000000001],\n",
       " [93, 12, 6, 0.99594046008119075, 0.64000000000000001],\n",
       " [96, 12, 6, 0.99594046008119075, 0.63],\n",
       " [97, 12, 6, 0.99594046008119075, 0.64000000000000001]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test # для кол-ва деревьев от 50 до 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нахождение лучших параметров леса для смещанных данных (train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Тестовая выборка это интернешнл 2017\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "all_parametrs=[]\n",
    "for n in range(1, 101):\n",
    "    for depth in range(1, 25):\n",
    "        for features in range(1, 10):\n",
    "            parametrs=[]\n",
    "            forest_optim_param = RandomForestClassifier(n_estimators=n, random_state=42, \n",
    "                                                        max_depth=depth, max_features=features)\n",
    "            forest_optim_param.fit(X_train, y_train)\n",
    "            parametrs.append(n)\n",
    "            parametrs.append(depth)\n",
    "            parametrs.append(features)\n",
    "            parametrs.append(forest_optim_param.score(X_train, y_train))\n",
    "            parametrs.append(forest_optim_param.score(X_test, y_test))\n",
    "            all_parametrs.append(parametrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 8, 1, 0.69157392686804453, 0.60476190476190472],\n",
       " [3, 8, 1, 0.72655007949125594, 0.60476190476190472],\n",
       " [4, 8, 1, 0.7678855325914149, 0.60476190476190472]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test=[]\n",
    "\n",
    "for par in all_parametrs:\n",
    "    if par[4] > 0.60:\n",
    "        all_test.append(par)\n",
    "all_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лучшие параметры для леса при обучении на не перемещенных данных и тестовой выборкой интернешнл 2017.\n",
    "# Признаки только герои без команд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n"
     ]
    }
   ],
   "source": [
    "forest_last = RandomForestClassifier(n_estimators=36, random_state=42, \n",
    "                                                        max_depth=14, max_features=8)\n",
    "forest_last.fit(training_matchs, training_winner)\n",
    "print (forest_last.score(test_matches,test_winner))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_matchs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a3ede3e4fc2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Нейронные сети\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_matchs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_winner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_matchs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_winner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_matchs' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
