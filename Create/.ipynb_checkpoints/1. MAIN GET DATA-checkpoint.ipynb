{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Номер последнего патча, Эта переменная подставляется во все ссылки в данном файле\n",
    "PATCH = '&patch=7.19&patch=7.18&patch=7.17&patch=7.16&patch=7.15&patch=7.14&patch=7.13&patch=7.12'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib, json\n",
    "from datetime import date, timedelta, datetime\n",
    "import re, requests, pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ДЛЯ ДОСТУПА НА РАБОТЕ или дома\n",
    "def get_url_from_proxy(url, *args):\n",
    "    if len(args) == 1:\n",
    "        params = args[0]\n",
    "    else:\n",
    "        params = ''\n",
    "        \n",
    "    http_proxy  = \"http://pavlov.ds:qwerty@172.16.0.10:3128\"\n",
    "    https_proxy = \"https://pavlov.ds:qwerty@172.16.0.10:3128\"\n",
    "    ftp_proxy   = \"ftp://pavlov.ds:qwerty@172.16.0.10:3128\"\n",
    "\n",
    "    proxyDict = { \"http\"  : http_proxy, \n",
    "                  \"https\" : https_proxy, \n",
    "                  \"ftp\"   : ftp_proxy}\n",
    "    return requests.get(url, params = params , headers={'User-agent': 'Mozilla/5.0'}, proxies=proxyDict)\n",
    "\n",
    "#     # Дома\n",
    "#     return requests.get(url, params = params , headers={'User-agent': 'Mozilla/5.0'})\n",
    "\n",
    "def get_json_from_url(url):\n",
    "    r = get_url_from_proxy(url)\n",
    "    return json.loads(r.text)\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Для рейтингов команд\n",
    "# создать мапу с старыми и новыми именами колонок для рейтинга команд\n",
    "def name_columns(z1, elo):\n",
    "    mapa = {}\n",
    "    for index, key in enumerate(z1.keys()):\n",
    "        mapa[key] = key + elo\n",
    "    return mapa\n",
    "# вытащить все данные по рейтингу (elo32, elo64, glicko, glicko2) одной команды\n",
    "def get_data_team(data):\n",
    "    ratings = ['elo32', 'elo64', 'glicko', 'glicko2']\n",
    "    #Создать колонку с именем команды\n",
    "    team = pd.DataFrame(columns=['team_Name'])\n",
    "    team['team_Name'] = [data.get('teamName')]\n",
    "\n",
    "    for rat in ratings:\n",
    "        current_rating = data.get(rat)\n",
    "        columns = name_columns(current_rating, '_' + rat)\n",
    "        df = pd.DataFrame(data.get(rat), index=range(0,1))     \n",
    "        df.rename(columns=columns, inplace=True)\n",
    "        team = pd.DataFrame.merge(team, df, left_index=True, right_index=True)\n",
    "    return team\n",
    "\n",
    "# Для SQL запроса к Opendota\n",
    "def query_opendota(sql):\n",
    "    resp = get_url_from_proxy('https://api.opendota.com/api/explorer',({'sql': sql}))\n",
    "    data = resp.json()\n",
    "    return pd.DataFrame.from_records(data['rows'])\n",
    "\n",
    "# для преобразования имен команд (убрать лишние символы)\n",
    "def reg(x): \n",
    "    reg = re.compile('[^-a-zA-Z0-9_. 、]')\n",
    "    return reg.sub('', x)\n",
    "\n",
    "# вытащить таблицу рейтинга на предыдущий день матча\n",
    "def get_rating_table(time_match):\n",
    "    # работа с датами\n",
    "    a = time_match - timedelta(1)\n",
    "    # Открыть json с сайта и выгрузить данные\n",
    "    url = \"https://www.datdota.com/api/ratings?date={}-{}-{}\".format(a.day, a.month, a.year)\n",
    "    dat = get_json_from_url(url)\n",
    "    data = dat.get('data')\n",
    "    # создать DF для сохранения\n",
    "    rating_team_date = pd.DataFrame() \n",
    "    # вытащить все команды и сохранить их данные в all_teams\n",
    "    for i in data:   \n",
    "        team = get_data_team(i) \n",
    "        rating_team_date = pd.concat([rating_team_date, team], ignore_index=True)    \n",
    "    # очистить имена команд\n",
    "    rating_team_date['team_Name'] = rating_team_date['team_Name'].apply(reg)\n",
    "    return rating_team_date\n",
    "# создать данные рейтинга команды по мнимальному рейтингу на день соревнований\n",
    "def get_min_team_rating(team_name, dire_or_radiant, rating_team_date):\n",
    "    #взять минимальную команду в рейтинге\n",
    "    test_min_team_rating = rating_team_date[rating_team_date['current_elo32'] == min(rating_team_date['current_elo32'])]\n",
    "    test_min_team_rating = test_min_team_rating.drop(['phi_glicko', 'sigma_glicko2'],  axis=1)\n",
    "    # сменить имя в минимальном рейтиенге\n",
    "    test_min_team_rating['team_Name'] = team_name\n",
    "    test_min_team_rating.columns = [dire_or_radiant + '_' + str(col) for col in test_min_team_rating.columns]\n",
    "    return test_min_team_rating\n",
    "\n",
    "#KDA\n",
    "#Вытащить данные из json по герою\n",
    "# Kills \tDeaths \tAssists \tKDA \tAvg. KAL \tGPM \tXPM \tLast Hits \tDenies \tLVL \tHD \tTD \tHH \tGS\n",
    "def get_data_for_Heroe(i):    \n",
    "    data = [i.get('hero'), i.get('kills'), i.get('deaths'), i.get('assists'), i.get('kda'), i.get('avgKal'), i.get('gpm'), i.get('xpm'),\n",
    "            i.get('lastHits'), i.get('denies'), i.get('level'), i.get('heroDamage'), i.get('towerDamage'),\n",
    "            i.get('heroHealing'), i.get('goldSpent'),]\n",
    "    return data\n",
    "# выгрузить json с сайта по kda героев для конкретной команды и добавить в основной ДФ\n",
    "def get_kda_heroes_team(url, radiant_or_dire, main_df):\n",
    "    # выгрзить json с предыдущей ссылки\n",
    "    dat = get_json_from_url(url)\n",
    "    df_team_hero_kda = pd.DataFrame(dat, columns=columns)\n",
    "    \n",
    "    # создать список названий колонок  героев radiant\n",
    "    all_her = main.loc[:,radiant_or_dire+'_H1': radiant_or_dire+'_H5'].columns\n",
    "    # ДФ для соединения всех герове матча в один ДФ \n",
    "    df_heroe_match = pd.DataFrame()\n",
    "    # пройтись по всем героям и добавить их kda в главный ДФ\n",
    "    for her in all_her:\n",
    "        # вытащить id героя\n",
    "        id_heroe = main[her][index]\n",
    "\n",
    "        # создать массив с данными \n",
    "        array = df_team_hero_kda[df_team_hero_kda['hero'] == id_heroe].values\n",
    "        # создать название колонок для определнного героя\n",
    "        col = [her + '_' + c for c  in df_team_hero_kda.columns]\n",
    "        # ДФ для героя по матчу, если нету данных по герою для команды то создается ДФ с нулями\n",
    "        df_heroe = pd.DataFrame(array, columns=col)\n",
    "        if len(df_heroe) == 0:\n",
    "            df_heroe = pd.DataFrame(np.zeros((1, 15)), columns=col)\n",
    "            \n",
    "        df_heroe_match = pd.merge(df_heroe_match, df_heroe, \n",
    "                                               left_index=True, right_index=True, how='outer')\n",
    "    return df_heroe_match\n",
    "\n",
    "# Head-to-Head\n",
    "# добавить в main_df суммарный показатель elo для героя vs всх врагов\n",
    "def elo_heroes_vs_enemies(index, columns_heroes, columns_enemies, df_elo_herVsEne, main_df):\n",
    "    # две переменные для записи суммарного elo каждой команды\n",
    "    for her in columns_heroes:\n",
    "        hero_elo = 0\n",
    "        # вытащить id героя\n",
    "        id_heroe = main[her][index]\n",
    "        # суммировать elo героя против героев противника\n",
    "        for her_enemy in columns_enemies:\n",
    "            id_heroe_enemy = main[her_enemy][index]\n",
    "            try:\n",
    "                elo =  df_elo_herVsEne['shift'][df_elo_herVsEne['hero'] == \n",
    "                                              id_heroe][df_elo_herVsEne['againstHero'] == id_heroe_enemy].item()\n",
    "            except:\n",
    "                elo=0\n",
    "            hero_elo += elo\n",
    "        # записать в основной ДФ elo по каждому герою\n",
    "        main_df.loc[index, her + '_elo_vs_enemies'] =  hero_elo \n",
    "\n",
    "# AvgElo Сигнатурки и Метовые герои \n",
    "# вытащить ДФы для одного, пары, тройки героев из сайта по дате\n",
    "def get_df_avgElo_heroes(day_match, df):\n",
    "    # создать ДФ для одного героя, пары и тройки\n",
    "    df_one = df.loc[(index for index, x in enumerate(df['heroes']) if len(x) == 1), :]  \n",
    "    df_one = df_one.reset_index().drop('index', axis=1)\n",
    "    df_double = df.loc[(index for index, x in enumerate(df['heroes']) if len(x) == 2), :]  \n",
    "    df_double = df_double.reset_index().drop('index', axis=1)\n",
    "#     df_triple = df.loc[(index for index, x in enumerate(df['heroes']) if len(x) == 3), :]  \n",
    "    return df_one, df_double#, df_triple\n",
    "\n",
    "# вытащить avgElo для двух героев, по их номеру\n",
    "def AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_Twoheroes, what_team, one_H, two_H):\n",
    "    a = what_team + one_H\n",
    "    b = what_team + two_H\n",
    "    # Если нету связки то поставить 0\n",
    "    try:\n",
    "        avgElo = df_data_tabel_for_Twoheroes.loc[(ind for ind, x in enumerate(df_data_tabel_for_Twoheroes['heroes'])\n",
    "                if (arr_heroes[a] in x and arr_heroes[b] in x)),'eloShift'].values[0]\n",
    "    except:\n",
    "        avgElo = 0\n",
    "    return (avgElo)\n",
    "\n",
    "# создать ДФ с avgElo по парам героев\n",
    "def get_df_AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_Twoheroes, dire_or_radiant):\n",
    "    if dire_or_radiant == 'dire':\n",
    "        what_team = 5\n",
    "    else:\n",
    "        what_team = 0\n",
    "     # вытащить avgElo для связки героя с другими по команде\n",
    "    avgElo_hero1_2 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_Twoheroes, what_team, 0, 1)\n",
    "    avgElo_hero1_3 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_Twoheroes, what_team, 0, 2)\n",
    "    avgElo_hero1_4 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_Twoheroes, what_team, 0, 3)\n",
    "    avgElo_hero1_5 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_Twoheroes, what_team, 0, 4)\n",
    "    avgElo_hero2_3 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_Twoheroes, what_team, 1, 2)\n",
    "    avgElo_hero2_4 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_Twoheroes, what_team, 1, 3)\n",
    "    avgElo_hero2_5 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_Twoheroes, what_team, 1, 4)\n",
    "    avgElo_hero3_4 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_Twoheroes, what_team, 2, 3)\n",
    "    avgElo_hero3_5 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_Twoheroes, what_team, 2, 4)\n",
    "    avgElo_hero4_5 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_Twoheroes, what_team, 3, 4)\n",
    "    arr = []\n",
    "    arr.append(avgElo_hero1_2); arr.append(avgElo_hero1_3); arr.append(avgElo_hero1_4); arr.append(avgElo_hero1_5);\n",
    "    arr.append(avgElo_hero2_3); arr.append(avgElo_hero2_4); arr.append(avgElo_hero2_5);\n",
    "    arr.append(avgElo_hero3_4); arr.append(avgElo_hero3_5);\n",
    "    arr.append(avgElo_hero4_5);\n",
    "    # Создать ДФ с данными для пар героев в команде\n",
    "    df_avgElo_for_two_heroes = pd.DataFrame([arr], columns=[dire_or_radiant + '_' + c for c in ['1_2','1_3','1_4','1_5',\n",
    "                                                                                                '2_3','2_4','2_5',\n",
    "                                                                                                '3_4','3_5',\n",
    "                                                                                                '4_5']])\n",
    "    return df_avgElo_for_two_heroes\n",
    "\n",
    "# вытащить таблицу с elo героев  по каждому игроку\n",
    "def get_df_AvgElo_heroes_player(player, index):\n",
    "    # дата матча\n",
    "    date_match = date.fromtimestamp(main['start_time'][index])\n",
    "    \n",
    "    date_match = date_match - timedelta(1)\n",
    "    \n",
    "    # создать ДФ для соло героев за все время игр игрока (сигнатурки)\n",
    "    url = ('http://www.datdota.com/api/players/hero-combos?players={}'.format(player) +\n",
    "    PATCH +\n",
    "    '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03&patch=7.02'+\n",
    "    '&patch=7.01&patch=7.00&patch=6.88&patch=6.87&patch=6.86&patch=6.85&patch=6.84&patch=6.83&patch=6.82&patch=6.81'+\n",
    "    '&patch=6.80&patch=6.79&patch=6.78&patch=6.77&patch=6.76&patch=6.75&patch=6.74&winner=either'+\n",
    "    '&after=01%2F01%2F2011&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year)+\n",
    "    '&duration=0%3B200&duration-value-from=0&duration-value-to=200&tier=1&tier=2&tier=3'+\n",
    "    '&valve-event=does-not-matter&threshold=5')\n",
    "\n",
    "    # выгрузить все с сайта и создать ДФ\n",
    "    try:\n",
    "        dat = get_json_from_url(url)\n",
    "    except:\n",
    "        dat = {'data':[]}\n",
    "    df_url = pd.DataFrame(dat.get('data'))\n",
    "    \n",
    "    return df_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_data_matches(date_one, date_end):\n",
    "    sql = '''SELECT\n",
    "    matches.match_id ,\n",
    "    matches.start_time,\n",
    "    matches.radiant_team_id,\n",
    "    matches.radiant_score,\n",
    "    matches.dire_team_id,\n",
    "    matches.dire_score,\n",
    "    matches.radiant_win\n",
    "    FROM matches\n",
    "    JOIN match_patch using(match_id)\n",
    "    JOIN leagues using(leagueid)\n",
    "    JOIN player_matches using(match_id)\n",
    "    JOIN heroes on heroes.id = player_matches.hero_id\n",
    "    LEFT JOIN notable_players ON notable_players.account_id = player_matches.account_id AND notable_players.locked_until = (SELECT MAX(locked_until) FROM notable_players)\n",
    "    LEFT JOIN teams using(team_id)\n",
    "    WHERE TRUE\n",
    "    AND matches.start_time >= extract(epoch from timestamp '{}')\n",
    "    AND matches.start_time <= extract(epoch from timestamp '{}')\n",
    "    AND leagues.tier = 'premium'\n",
    "    AND match_patch.patch >= '7.01'\n",
    "    GROUP BY matches.match_id\n",
    "    HAVING count(distinct matches.match_id) >= 1\n",
    "    LIMIT 2000000'''.format(date_one.isoformat() , date_end.isoformat()) \n",
    "    return  query_opendota(sql)\n",
    "\n",
    "def query_teams_heroes_mathes(date_one, date_end):\n",
    "    sql = '''SELECT\n",
    "    matches.match_id,\n",
    "    matches.start_time,\n",
    "    ((player_matches.player_slot < 128) = matches.radiant_win) win,\n",
    "    player_matches.hero_id,\n",
    "    player_matches.account_id,\n",
    "    leagues.name leaguename\n",
    "    FROM matches\n",
    "    JOIN match_patch using(match_id)\n",
    "    JOIN leagues using(leagueid)\n",
    "    JOIN player_matches using(match_id)\n",
    "    JOIN heroes on heroes.id = player_matches.hero_id\n",
    "    LEFT JOIN notable_players ON notable_players.account_id = player_matches.account_id AND notable_players.locked_until = (SELECT MAX(locked_until) FROM notable_players)\n",
    "    LEFT JOIN teams using(team_id)\n",
    "    WHERE TRUE\n",
    "    AND matches.start_time >= extract(epoch from timestamp '{}')\n",
    "    AND matches.start_time <= extract(epoch from timestamp '{}')\n",
    "    AND leagues.tier = 'premium'\n",
    "    AND match_patch.patch >= '7.01'\n",
    "    ORDER BY matches.match_id DESC NULLS LAST\n",
    "    LIMIT 2000000'''.format(date_one.isoformat() , date_end.isoformat()) \n",
    "    return query_opendota(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Задать даты для которых нужны матчи \n",
    "# date_one = datetime(2012, 2, 28)\n",
    "# date_end = datetime(2018, 3, 1)\n",
    "\n",
    "# date_one = datetime(2018, 3, 1)\n",
    "# date_end = datetime(2018, 4, 8)\n",
    "\n",
    "# date_one = datetime(2018, 4, 8)\n",
    "# date_end = datetime(2018, 4, 25)\n",
    "\n",
    "# date_one = datetime(2018, 4, 25)\n",
    "# date_end = datetime(2018, 5, 7)\n",
    "\n",
    "# date_one = datetime(2018, 5, 7)\n",
    "# date_end = datetime(2018, 5, 14)\n",
    "\n",
    "# date_one = datetime(2018, 5, 14)\n",
    "# date_end = datetime(2018, 6, 1)\n",
    "\n",
    "date_one = datetime(2018, 6, 1)\n",
    "date_end = datetime(2018, 7, 1)\n",
    "\n",
    "day_one = date_one.date()\n",
    "day_end = date_end.date()\n",
    "\n",
    "# main = pd.DataFrame(query_data_matches(date_one, date_end))\n",
    "# df_teams_hereoes = pd.DataFrame(query_teams_heroes_mathes(date_one, date_end))\n",
    "\n",
    "# print (len(main))\n",
    "# print (len(df_teams_hereoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# присвоить ДФ для обработки из нужного файла с героями и игроками\n",
    "df_her_play = df_teams_hereoes\n",
    "# собрать все матчи из ДФ с героями и игроками\n",
    "matches = np.unique(df_her_play['match_id'])\n",
    "for id_match in matches:\n",
    "    # номер индекса в галвном ДФ\n",
    "    main_index = main[main['match_id'] == id_match].index[0]\n",
    "    # создать два датафрейма по героям и игрокам (разделенных на выйгрывших и проигравших)\n",
    "    her_false = pd.DataFrame(df_her_play['hero_id'][df_her_play['match_id'] == id_match][df_her_play['win'] == False])\n",
    "    her_true = pd.DataFrame(df_her_play['hero_id'][df_her_play['match_id'] == id_match][df_her_play['win'] == True])\n",
    "    heroes = pd.concat([her_false, her_true]).reset_index().T.drop('index')\n",
    "    play_false = pd.DataFrame(df_her_play['account_id'][df_her_play['match_id'] == id_match][df_her_play['win'] == False])\n",
    "    play_true = pd.DataFrame(df_her_play['account_id'][df_her_play['match_id'] == id_match][df_her_play['win'] == True])\n",
    "    players = pd.concat([play_false, play_true]).reset_index().T.drop('index')\n",
    "\n",
    "    # соединение и присваивание нормальных имен столбцам в дф с героями и игроками\n",
    "    col_her = {0: 'lose_H1', 1: 'lose_H2', 2: 'lose_H3', 3: 'lose_H4', 4: 'lose_H5', \n",
    "                 5: 'win_H1', 6: 'win_H2', 7: 'win_H3', 8: 'win_H4', 9: 'win_H5'}\n",
    "    col_play = {0: 'lose_P1', 1: 'lose_P2', 2: 'lose_P3', 3: 'lose_P4', 4: 'lose_P5', \n",
    "                 5: 'win_P1', 6: 'win_P2', 7: 'win_P3', 8: 'win_P4', 9: 'win_P5'}\n",
    "    heroes = heroes.rename(columns=col_her,).rename( {'hero_id': 0})\n",
    "    players = players.rename(columns=col_play).rename( {'account_id': 0})\n",
    "\n",
    "    match = pd.merge(heroes, players,  left_index=True, right_index=True)\n",
    "    match['match_id'] = id_match\n",
    "    \n",
    "    #ЗАменить название столбцов win or lose на радиант и даер\n",
    "    if main[main['match_id'] == id_match]['radiant_win'].bool() == False:\n",
    "        for i in range(1,6):\n",
    "            main.loc[main_index, 'radiant_H' + str(i)] = match['lose_H' + str(i)][0]\n",
    "        for i in range(1,6):\n",
    "            main.loc[main_index, 'dire_H' + str(i)] = match['win_H' + str(i)][0]\n",
    "        for i in range(1,6):\n",
    "            main.loc[main_index, 'radiant_P' + str(i)] = match['lose_P' + str(i)][0]\n",
    "        for i in range(1,6):\n",
    "            main.loc[main_index, 'dire_P' + str(i)] = match['win_P' + str(i)][0]\n",
    "\n",
    "    elif main[main['match_id'] == id_match]['radiant_win'].bool() == True:\n",
    "        for i in range(1,6):\n",
    "            main.loc[main_index, 'radiant_H' + str(i)] = match['win_H' + str(i)][0]\n",
    "        for i in range(1,6):\n",
    "            main.loc[main_index, 'dire_H' + str(i)] = match['lose_H' + str(i)][0]\n",
    "        for i in range(1,6):\n",
    "            main.loc[main_index, 'radiant_P' + str(i)] = match['win_P' + str(i)][0]\n",
    "        for i in range(1,6):\n",
    "            main.loc[main_index, 'dire_P' + str(i)] = match['lose_P' + str(i)][0]\n",
    "# добавить лигу\n",
    "for id_match in matches:\n",
    "    # номер индекса в галвном ДФ\n",
    "    main_index = main[main['match_id'] == id_match].index[0]\n",
    "    df_her_play_index = df_her_play[df_her_play['match_id'] == id_match].index[0]\n",
    "    \n",
    "    main.loc[main_index, 'league_name'] = df_her_play.loc[df_her_play_index,'leaguename']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n"
     ]
    }
   ],
   "source": [
    "# main.to_csv('../tabel/MAIN TABEL PREMIUM on {} to {}.csv'.format(day_one, day_end))\n",
    "main = pd.read_csv('../tabel/MAIN TABEL PREMIUM on {} to {}.csv'.format(day_one, day_end), index_col=0)\n",
    "print(len(main))\n",
    "# main = main.dropna()\n",
    "# print(len(main))\n",
    "# main = main.reset_index().drop('index', axis=1)\n",
    "# print(len(main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# создать дф из json по всем командам с OPENDOTA https://api.opendota.com/api/teams\n",
    "url = \"https://api.opendota.com/api/teams\"\n",
    "dat = get_json_from_url(url)\n",
    "\n",
    "# дф с именем команды и ее id\n",
    "df_team_id = pd.DataFrame(dat).loc[:,['name', 'team_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dire_score', 'dire_team_id', 'match_id', 'radiant_score',\n",
      "       'radiant_team_id', 'radiant_win', 'start_time', 'radiant_H1',\n",
      "       'radiant_H2', 'radiant_H3', 'radiant_H4', 'radiant_H5', 'dire_H1',\n",
      "       'dire_H2', 'dire_H3', 'dire_H4', 'dire_H5', 'radiant_P1', 'radiant_P2',\n",
      "       'radiant_P3', 'radiant_P4', 'radiant_P5', 'dire_P1', 'dire_P2',\n",
      "       'dire_P3', 'dire_P4', 'dire_P5', 'league_name', 'radiant_name',\n",
      "       'dire_name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# создать столбцы с именами команд с opendota\n",
    "for index in main.index:\n",
    "    try:\n",
    "        main.loc[index, 'radiant_name'] = (\n",
    "            df_team_id.loc[df_team_id['team_id'] == main.loc[index, 'radiant_team_id'], 'name'].get_values()[0])\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        main.loc[index, 'dire_name'] = (\n",
    "            df_team_id.loc[df_team_id['team_id'] == main.loc[index, 'dire_team_id'], 'name'].get_values()[0])\n",
    "    except:\n",
    "        continue\n",
    "print(main.columns)\n",
    "main = main.dropna()\n",
    "main['radiant_name'] = main['radiant_name'].apply(reg)\n",
    "main['dire_name'] = main['dire_name'].apply(reg)\n",
    "main = main.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['dire_score', 'dire_team_id', 'match_id', 'radiant_score',\n",
       "       'radiant_team_id', 'radiant_win', 'start_time', 'radiant_H1',\n",
       "       'radiant_H2', 'radiant_H3', 'radiant_H4', 'radiant_H5', 'dire_H1',\n",
       "       'dire_H2', 'dire_H3', 'dire_H4', 'dire_H5', 'radiant_P1', 'radiant_P2',\n",
       "       'radiant_P3', 'radiant_P4', 'radiant_P5', 'dire_P1', 'dire_P2',\n",
       "       'dire_P3', 'dire_P4', 'dire_P5', 'league_name', 'radiant_name',\n",
       "       'dire_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (len (main))\n",
    "main.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Убрать все повторющиеся команды из основного списка (Effect, Infamous, Digital Chaos)\n",
    "main = main[main['dire_team_id'] != 5065748]\n",
    "main = main[main['radiant_team_id'] != 5065748]\n",
    "main = main[main['dire_team_id'] != 2672298]\n",
    "main = main[main['radiant_team_id'] != 2672298]\n",
    "main = main[main['dire_team_id'] != 5196328]dire_team_id\n",
    "main = main[main['radiant_team_id'] != 5196328]\n",
    "main = main[main['dire_team_id'] != 2512249]\n",
    "main = main[main['radiant_team_id'] != 2512249]\n",
    "main = main[main['dire_team_id'] != 2790766]\n",
    "main = main[main['radiant_team_id'] != 2790766]\n",
    "main = main[main['dire_team_id'] != 5197722]\n",
    "main = main[main['radiant_team_id'] != 5197722]\n",
    "len (main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рейтинг команд по таблице рейтинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 10min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "match_rating_teams = pd.DataFrame()\n",
    "\n",
    "for index in  main.index:\n",
    "    if index%100 == 0:\n",
    "        print (index) \n",
    "    # вытащить одну строчку (для того чтобы потом добавить в основную таблицу. Пока оставить так, но в принципе можно \n",
    "    # уброть переменную one_match)\n",
    "    one_match = main.loc[[index]]\n",
    "    # достать дату матча\n",
    "    date_match =  date.fromtimestamp(one_match['start_time'][index])\n",
    "    # вытащить таблицу с рейтингами на предыдущий день матча\n",
    "    rating_team_date = get_rating_table(date_match)\n",
    "    \n",
    "    # имена команд в матче\n",
    "    radiant_name = one_match['radiant_name'][index]\n",
    "    dire_name = one_match['dire_name'][index]\n",
    "    \n",
    "    # вытащить команду radiant из рейтинга команд на предыдущий день соревнований\n",
    "    rating_radiant = rating_team_date[rating_team_date['team_Name'] == radiant_name]\n",
    "    if rating_radiant.empty == True:\n",
    "        # если команды нету в списке рейтинга взять данные по команде с минимальным рейтинго elo32\n",
    "        rating_radiant = get_min_team_rating(radiant_name, 'radiant', rating_team_date)\n",
    "    else:\n",
    "        rating_radiant = rating_radiant.drop(['phi_glicko', 'sigma_glicko2'],  axis=1)\n",
    "        # добавить к названиям столбцов 'radiant'\n",
    "        rating_radiant.columns = ['radiant_' + str(col) for col in rating_radiant.columns]\n",
    "\n",
    "    # вытащить команду dire из рейтинга команд на предыдущий денб соревнований\n",
    "    rating_dire = rating_team_date[rating_team_date['team_Name'] == dire_name]\n",
    "    if rating_dire.empty == True:\n",
    "        # если команды нету в списке рейтинга взять данные по команде с минимальным рейтинго elo32\n",
    "        rating_dire = get_min_team_rating(dire_name, 'dire', rating_team_date)\n",
    "    else:\n",
    "        rating_dire = rating_dire.drop(['phi_glicko', 'sigma_glicko2'],  axis=1)\n",
    "        # добавить к названиям столбцов 'dire'\n",
    "        rating_dire.columns = ['dire_' + str(col) for col in rating_dire.columns]\n",
    "        \n",
    "    #соединить в одну строчку данные матча и данные с рейтинга каждой команды если присутсвуют данные по команде\n",
    "    rating_teams = pd.merge(one_match, rating_radiant,  left_on='radiant_name', right_on='radiant_team_Name')\n",
    "    rating_teams = pd.merge(rating_teams, rating_dire, left_on='dire_name', right_on='dire_team_Name')\n",
    "    rating_teams = rating_teams.drop(['dire_team_Name', 'radiant_team_Name'], axis=1)\n",
    "    # Если повторяющиеся команды  то длина будет два. НЕ ДОБАВЛЯТЬ ПОВТОРЯЮЩИЕСЯ КОМАНДЫ\n",
    "    if len(rating_teams) == 1:\n",
    "        match_rating_teams = pd.concat([match_rating_teams, rating_teams])\n",
    "# match_rating_teams = match_rating_teams.reset_index().drop('index', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match_rating_teams.to_csv('../tabel/table from Datdota/Rating teams/'+\n",
    "                          'PREMIUM on {} to {} (PreDay).csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main = main.loc[3495:]\n",
    "# main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рейтинг команд по ссылке на данные команды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_current_rating_teams(date_match, team_id, radiant_or_dire):\n",
    "    date_rating = date_match\n",
    "    date_rating_7day_ago = date_rating - timedelta(7)\n",
    "    # Достать данные по рейтингу для редиант на текущий день и семь дней назад\n",
    "    url = 'http://www.datdota.com/api/teams/{}/ratings?date={}-{}-{}'.format(\n",
    "                                team_id, date_rating.year, date_rating.month, date_rating.day )\n",
    "    # выгрзить json с предыдущей ссылки и создать ДФ\n",
    "    dat = get_json_from_url(url)\n",
    "    data = pd.DataFrame(dat.get('data'))\n",
    "        \n",
    "    url_7day_ago = 'http://www.datdota.com/api/teams/{}/ratings?date={}-{}-{}'.format(\n",
    "            team_id, date_rating_7day_ago.year, date_rating_7day_ago.month, date_rating_7day_ago.day )\n",
    "    # выгрзить json с предыдущей ссылки и создать ДФ\n",
    "    dat_7day_ago = get_json_from_url(url_7day_ago)\n",
    "    data_7day_ago = pd.DataFrame(dat_7day_ago.get('data'))\n",
    "    # если нету данных 7 дней назад\n",
    "    try:\n",
    "        \n",
    "        # бывает что не посчитан рейтинг для текущей недели и тогда взять 14 дней назад\n",
    "        if data_7day_ago.loc['startPeriod', 'GLICKO_1'] == data.loc['startPeriod', 'GLICKO_1']:\n",
    "            date_rating_7day_ago = date_rating - timedelta(14)\n",
    "            url_7day_ago = 'http://www.datdota.com/api/teams/{}/ratings?date={}-{}-{}'.format(\n",
    "                    team_id, date_rating_7day_ago.year, date_rating_7day_ago.month, date_rating_7day_ago.day )\n",
    "            # выгрзить json с предыдущей ссылки и создать ДФ\n",
    "            dat_7day_ago = get_json_from_url(url_7day_ago)\n",
    "            data_7day_ago = pd.DataFrame(dat_7day_ago.get('data'))\n",
    "    except:\n",
    "        data_7day_ago = pd.DataFrame([[0,0]], columns=['GLICKO_1', 'GLICKO_2'], index=['rating'])\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        \n",
    "        team_ratin_df_allData = pd.DataFrame()\n",
    "        team_ratin_df_allData.loc[0, radiant_or_dire + '_mu_glicko'] = data.loc['mu', 'GLICKO_1']\n",
    "        team_ratin_df_allData.loc[0, radiant_or_dire + '_rating_glicko'] = data.loc['rating', 'GLICKO_1']\n",
    "        team_ratin_df_allData.loc[0, radiant_or_dire + '_ratingSevenDaysAgo_glicko'] = data_7day_ago.loc['rating', 'GLICKO_1']\n",
    "        team_ratin_df_allData.loc[0, radiant_or_dire + '_sigma_glicko'] = data.loc['sigma', 'GLICKO_1']\n",
    "\n",
    "        team_ratin_df_allData.loc[0, radiant_or_dire + '_mu_glicko2'] = data.loc['mu', 'GLICKO_2']\n",
    "        team_ratin_df_allData.loc[0, radiant_or_dire + '_phi_glicko2'] = data.loc['phi', 'GLICKO_2']\n",
    "        team_ratin_df_allData.loc[0, radiant_or_dire + '_rating_glicko2'] = data.loc['rating', 'GLICKO_2']\n",
    "        team_ratin_df_allData.loc[0, radiant_or_dire + '_ratingSevenDaysAgo_glicko2'] = data_7day_ago.loc['rating', 'GLICKO_2']    \n",
    "    except:\n",
    "        team_ratin_df_allData = pd.DataFrame([[0,0,0,0,0,0,0,0]], \n",
    "                columns=[radiant_or_dire + x for x in ['_mu_glicko', '_rating_glicko', \n",
    "                                        '_ratingSevenDaysAgo_glicko', '_sigma_glicko', \n",
    "                            '_mu_glicko2', '_phi_glicko2', '_rating_glicko2', '_ratingSevenDaysAgo_glicko2', ]])\n",
    "    return(team_ratin_df_allData)\n",
    "    \n",
    "# get_current_rating_teams(radiant_team_id, dire_team_id, 'radiant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 6min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "match_rating_teams = pd.DataFrame()\n",
    "\n",
    "for index in  main.index:\n",
    "    if index%100 == 0:\n",
    "        print (index) \n",
    "    # вытащить одну строчку (для того чтобы потом добавить в основную таблицу. Пока оставить так, но в принципе можно \n",
    "    # уброть переменную one_match)\n",
    "    one_match = main.loc[[index]]\n",
    "    # достать дату матча\n",
    "    date_match =  date.fromtimestamp(one_match['start_time'][index]) - timedelta(1)\n",
    "#     # вытащить таблицу с рейтингами на предыдущий день матча\n",
    "#     rating_team_date = get_rating_table(date_match)\n",
    "    \n",
    "    # id команд в матче, иногда бывает что нет id \n",
    "    try:\n",
    "        radiant_id = int(one_match['radiant_team_id'][index])\n",
    "    except:\n",
    "        radiant_id = 0\n",
    "    try:\n",
    "        dire_id = int(one_match['dire_team_id'][index])\n",
    "    except:\n",
    "        dire_id = 0\n",
    "    \n",
    "    # вытащить команду radiant из рейтинга команд на предыдущий день соревнований\n",
    "    rating_radiant = get_current_rating_teams(date_match, radiant_id, 'radiant')\n",
    "#     if rating_radiant.empty == True:\n",
    "#         # если команды нету в списке рейтинга взять данные по команде с минимальным рейтинго elo32\n",
    "#         rating_radiant = get_min_team_rating(radiant_name, 'radiant', rating_team_date)\n",
    "#     else:\n",
    "#         rating_radiant = rating_radiant.drop(['phi_glicko', 'sigma_glicko2'],  axis=1)\n",
    "#         # добавить к названиям столбцов 'radiant'\n",
    "#         rating_radiant.columns = ['radiant_' + str(col) for col in rating_radiant.columns]\n",
    "\n",
    "    # вытащить команду dire из рейтинга команд на предыдущий денб соревнований\n",
    "    rating_dire = get_current_rating_teams(date_match, dire_id, 'dire')\n",
    "#     if rating_dire.empty == True:\n",
    "#         # если команды нету в списке рейтинга взять данные по команде с минимальным рейтинго elo32\n",
    "#         rating_dire = get_min_team_rating(dire_name, 'dire', rating_team_date)\n",
    "#     else:\n",
    "#         rating_dire = rating_dire.drop(['phi_glicko', 'sigma_glicko2'],  axis=1)\n",
    "#         # добавить к названиям столбцов 'dire'\n",
    "#         rating_dire.columns = ['dire_' + str(col) for col in rating_dire.columns]\n",
    "        \n",
    "    #соединить в одну строчку данные матча и данные с рейтинга каждой команды если присутсвуют данные по команде\n",
    "#     rating_teams = pd.merge(one_match['match_id'], rating_radiant)\n",
    "    rating_teams = pd.merge(rating_radiant, rating_dire, left_index=True, right_index=True)\n",
    "    rating_teams['match_id'] = one_match['match_id'].values[0]\n",
    "#     rating_teams = rating_teams.drop(['dire_team_Name', 'radiant_team_Name'], axis=1)\n",
    "    # Если повторяющиеся команды  то длина будет два. НЕ ДОБАВЛЯТЬ ПОВТОРЯЮЩИЕСЯ КОМАНДЫ\n",
    "    if len(rating_teams) == 1:\n",
    "        match_rating_teams = pd.concat([match_rating_teams, rating_teams])\n",
    "match_rating_teams = match_rating_teams.reset_index().drop('index', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "match_rating_teams.to_csv('../tabel/table from Datdota/Rating teams/'+\n",
    "                          'Rating Glicko on {} to {} (PreDay).csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDA для героев в матче за все время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 4min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "columns = ['hero', 'kills', 'deaths', 'assists', 'kda', 'avgKal', 'gpm', 'xpm', 'lastHits', 'denies', 'level',\n",
    "           'heroDamage', 'towerDamage', 'heroHealing', 'goldSpent']\n",
    "# создать основной массив, где будут записаны все матчи (id матча и rda героя)\n",
    "df_basick_peromances_heroes = pd.DataFrame()\n",
    "\n",
    "# создать список названий колонок всех героев\n",
    "all_her = main.loc[:,'radiant_H1':'dire_H5'].columns\n",
    "for index in main.index:\n",
    "    if index%100 == 0:\n",
    "        print (index)\n",
    "    # ДФ для соединения всех герове матча в один ДФ \n",
    "    df_heroe_match = pd.DataFrame()\n",
    "    # дата матча\n",
    "    date_match = date.fromtimestamp(main['start_time'][index])\n",
    "    # предыдущий день\n",
    "    date_match =  date_match - timedelta(1)\n",
    "    \n",
    "    url_heroes =('http://www.datdota.com/api/heroes/performances?' + PATCH +\n",
    "        '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03' +\n",
    "        '&patch=7.02&patch=7.01&patch=7.00&patch=6.88' +\n",
    "        '&winner=either&after=01%2F01%2F2011' + \n",
    "        '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year) + \n",
    "        '&duration=0%3B200&duration-value-from=0&duration-value-to=200&tier=1' + \n",
    "        '&valve-event=does-not-matter&threshold=20') \n",
    "#     print(url_heroes)\n",
    "    # выгрзить json с предыдущей ссылки\n",
    "    dat = get_json_from_url(url_heroes).get('data')\n",
    "    df_data_tabel_for_heroes = pd.DataFrame(dat)#, columns=columns)\n",
    "#     print(dat)\n",
    "    for her in all_her:\n",
    "        # вытащить id героя\n",
    "        id_heroe = main[her][index]\n",
    "\n",
    "        # создать массив с данными \n",
    "        array = df_data_tabel_for_heroes[df_data_tabel_for_heroes['hero'] == id_heroe].values\n",
    "        # создать название колонок для определнного героя\n",
    "        col = [her + '_' + c for c  in df_data_tabel_for_heroes.columns]\n",
    "        # ДФ для героя по матчу\n",
    "        df_heroe = pd.DataFrame(array, columns=col)\n",
    "        df_heroe_match = pd.merge(df_heroe_match, df_heroe, \n",
    "                                               left_index=True, right_index=True, how='outer')\n",
    "        df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "    df_basick_peromances_heroes = pd.concat([df_basick_peromances_heroes, df_heroe_match])\n",
    "df_basick_peromances_heroes = df_basick_peromances_heroes.reset_index().drop('index', axis=1)\n",
    "# df_basick_peromances_heroes['match_id'] = main['match_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_basick_peromances_heroes.to_csv('../tabel/table from Datdota/KDA/Heroes/'+\n",
    "                          'KDA heroes on {} to {} (6.88+, Pro, more 20).csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDA Для героев за последние 7 дней  (Мета)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "columns = ['hero', 'kills', 'deaths', 'assists', 'kda', 'avgKal', 'gpm', 'xpm', 'lastHits', 'denies', 'level',\n",
    "           'heroDamage', 'towerDamage', 'heroHealing', 'goldSpent']\n",
    "# создать основной массив, где будут записаны все матчи (id матча и rda героя)\n",
    "df_basick_peromances_heroes = pd.DataFrame()\n",
    "\n",
    "# создать список названий колонок всех героев\n",
    "all_her = main.loc[:,'radiant_H1':'dire_H5'].columns\n",
    "for index in main.index:\n",
    "    if index%100 == 0:\n",
    "        print (index)\n",
    "    # ДФ для соединения всех герове матча в один ДФ \n",
    "    df_heroe_match = pd.DataFrame()\n",
    "    # дата матча\n",
    "    date_match = date.fromtimestamp(main['start_time'][index])\n",
    "    # предыдущий день\n",
    "    date_match =  date_match - timedelta(1)\n",
    "    seven_day_ago = date_match - timedelta(7)\n",
    "    url_heroes =('http://www.datdota.com/api/heroes/performances?' + PATCH +\n",
    "        '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03' +\n",
    "        '&patch=7.02&patch=7.01&patch=7.00&patch=6.88' +\n",
    "        '&winner=either&after={}%2F{}%2F{}'.format(seven_day_ago.day, seven_day_ago.month, seven_day_ago.year) + \n",
    "        '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year) + \n",
    "        '&duration=0%3B200&duration-value-from=0&duration-value-to=200&tier=1&tier=2&tier=3' + \n",
    "        '&valve-event=does-not-matter&threshold=10') \n",
    "#     print(url_heroes)\n",
    "    # выгрзить json с предыдущей ссылки\n",
    "    dat = get_json_from_url(url_heroes).get('data')\n",
    "    df_data_tabel_for_heroes = pd.DataFrame(dat)#, columns=columns)\n",
    "#     print(dat)\n",
    "    for her in all_her:\n",
    "        # вытащить id героя\n",
    "        id_heroe = main[her][index]\n",
    "\n",
    "        # создать массив с данными \n",
    "        array = df_data_tabel_for_heroes[df_data_tabel_for_heroes['hero'] == id_heroe].values\n",
    "        # создать название колонок для определнного героя\n",
    "        col = [her + '_' + c for c  in df_data_tabel_for_heroes.columns]\n",
    "        # ДФ для героя по матчу\n",
    "        df_heroe = pd.DataFrame(array, columns=col)\n",
    "        df_heroe_match = pd.merge(df_heroe_match, df_heroe, \n",
    "                                               left_index=True, right_index=True, how='outer')\n",
    "        df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "    df_basick_peromances_heroes = pd.concat([df_basick_peromances_heroes, df_heroe_match])\n",
    "df_basick_peromances_heroes = df_basick_peromances_heroes.reset_index().drop('index', axis=1)\n",
    "# df_basick_peromances_heroes['match_id'] = main['match_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_basick_peromances_heroes = df_basick_peromances_heroes.fillna(0)\n",
    "df_basick_peromances_heroes.to_csv('../tabel/table from Datdota/KDA/Heroes/7day_ago/'+\n",
    "                          'KDA heroes on {} to {} (7day_ago, All, more 10).csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head-to-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 10min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# создать основной массив, где будут записаны суммарное elo каждого егроя относительно всех героев противника\n",
    "df_head_to_head_elo_heroes = pd.DataFrame()#main['match_id']\n",
    "\n",
    "# создать список названий колонок  героев radiant\n",
    "all_her_rad = main.loc[:,'radiant_H1':'radiant_H5'].columns\n",
    "# создать список названий колонок  героев radiant\n",
    "all_her_dir = main.loc[:,'dire_H1':'dire_H5'].columns\n",
    "\n",
    "# # ВЫТАЩИТЬ ЕЛО ГЕРОЕВ ЗА ВСЕ ПАТЧИ И С ПОСЛЕДНЕЙ ДАТОЙ 01 ОКТЯБРЯ 2018,\n",
    "# # создать правильную ссылку для посика героев по команде radiant\n",
    "# url_heroes_team = ('http://www.datdota.com/api/heroes/head-to-head-elo?tier=1&valve-event=does-not-matter&threshold=20'+\n",
    "#                    PATCH +\n",
    "#                    '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03'+\n",
    "#                    '&patch=7.02&patch=7.01&patch=7.00&patch=6.88&patch=6.87&patch=6.86&patch=6.85&patch=6.84'+\n",
    "#                    '&patch=6.83&patch=6.82&patch=6.81&patch=6.80&patch=6.79&patch=6.78&patch=6.77&patch=6.76&'+\n",
    "#                    'patch=6.75&patch=6.74&winner=either&after=01%2F01%2F2011&before=01%2F10%2F2018&'+\n",
    "#                    'duration=0%3B200&duration-value-from=0&duration-value-to=200')\n",
    "\n",
    "# # выгрзить json с предыдущей ссылки и создать ДФ\n",
    "# dat = get_json_from_url(url_heroes_team)\n",
    "# df_elo_herVsEne = pd.DataFrame(dat.get('data'))\n",
    "\n",
    "for index in main.index:\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "    \n",
    "    # достать дату матча и отнять один день\n",
    "    date_match = date.fromtimestamp(main['start_time'][index])\n",
    "    date_match = date_match - timedelta(1)\n",
    "#     # создать дату два месяца назад от даты матча\n",
    "#     two_month_ago = date_match - timedelta(60)\n",
    "    \n",
    "    # создать cылку для предыдущего дня по контрпикам  за все время существования DatDota\n",
    "    url_heroes_team = ('http://www.datdota.com/api/heroes/head-to-head-elo?tier=1&tier=2&tier=3'+\n",
    "                       '&valve-event=does-not-matter&threshold=20' + PATCH +\n",
    "                       '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04'+\n",
    "                       '&patch=7.03&patch=7.02&patch=7.01&patch=7.00&patch=6.88&patch=6.87&patch=6.86&patch=6.85'+\n",
    "                       '&patch=6.84&patch=6.83&patch=6.82&patch=6.81&patch=6.80&patch=6.79&patch=6.78&patch=6.77'+\n",
    "                       '&patch=6.76&patch=6.75&patch=6.74'+\n",
    "                       '&winner=either&after=01%2F01%2F2011' +\n",
    "                '&before={}%2F{}%2F{}&duration=0%3B200&'.format(date_match.day, date_match.month, date_match.year) +\n",
    "                'duration-value-from=0&duration-value-to=200') \n",
    "    # выгрзить json с предыдущей ссылки и создать ДФ\n",
    "    dat = get_json_from_url(url_heroes_team)\n",
    "    df_elo_herVsEne = pd.DataFrame(dat.get('data'))\n",
    "      \n",
    "    # добавить в мейн таблицу данные сначала по ело героям рединт против дире, а затем наоборот\n",
    "    elo_heroes_vs_enemies(index, all_her_rad, all_her_dir, df_elo_herVsEne, df_head_to_head_elo_heroes )\n",
    "    elo_heroes_vs_enemies(index, all_her_dir, all_her_rad, df_elo_herVsEne, df_head_to_head_elo_heroes )\n",
    "    \n",
    "df_head_to_head_elo_heroes['match_id'] = main['match_id']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_head_to_head_elo_heroes.to_csv('../tabel/table from Datdota/Heah-to-head Contrpicks/'+\n",
    "                           'data from 6.74-last. on {} to {} (PreDay, All, more 20).csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метовые герои AvgELo (TwoMonthAgo, All, more 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# создать основной ДФ, где будут записаны все матчи (id матча и rda героя)\n",
    "df_AvgElo_heroes = pd.DataFrame()\n",
    "df_AvgElo_for_two_heroes_in_two_teams = pd.DataFrame()\n",
    "\n",
    "# создать список названий колонок всех героев\n",
    "all_her = main.loc[:,'radiant_H1':'dire_H5'].columns\n",
    "for index in main.index:\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "    # ДФ для соединения всех герове матча в один ДФ \n",
    "    df_heroe_match = pd.DataFrame()\n",
    "    # дата матча\n",
    "    date_match = date.fromtimestamp(main['start_time'][index])\n",
    "    # предыдущий день\n",
    "    date_match =  date_match - timedelta(1)\n",
    "    # создать дату два месяца назад от даты матча\n",
    "    two_month_ago = date_match - timedelta(60)\n",
    "    # создать ссылку с данными по Avg.Elo для двух предыдущих месяцев игры\n",
    "    url = ('http://www.datdota.com/api/heroes/elo?tier=1&tier=2&tier=3&valve-event=does-not-matter&threshold=20' +\n",
    "        PATCH + \n",
    "        '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03&patch=7.02' + \n",
    "        '&patch=7.01&patch=7.00&patch=6.88&patch=6.87&patch=6.86&patch=6.85'+\n",
    "        '&patch=6.84&patch=6.83&patch=6.82&patch=6.81&patch=6.80&patch=6.79&patch=6.78&patch=6.77'+\n",
    "        '&patch=6.76&patch=6.75&patch=6.74'+\n",
    "        '&winner=either'+\n",
    "        '&after={}%2F{}%2F{}'.format(two_month_ago.day, two_month_ago.month, two_month_ago.year) + \n",
    "        '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year) + \n",
    "        '&duration=0%3B200&duration-value-from=0&duration-value-to=200')\n",
    "    # выгрузить все с сайта и создать ДФ\n",
    "    dat = get_json_from_url(url)\n",
    "    df_url = pd.DataFrame(dat.get('data'))\n",
    "    # создать ДФ для одного и пары героев за 2 предыдущих месяца\n",
    "    df_data_tabel_for_heroes, df_data_tabel_for_TwoHeroes = get_df_avgElo_heroes(date_match, df_url)\n",
    "\n",
    "    for her in all_her:\n",
    "        # вытащить id героя\n",
    "        id_hero = main[her][index]\n",
    "\n",
    "        # вытащить avg elo для данного героя\n",
    "        avgElo_hero = df_data_tabel_for_heroes.loc[(index for index, x in enumerate(\n",
    "                                            df_data_tabel_for_heroes['heroes']) if x == [id_hero]),'eloShift']\n",
    "        \n",
    "        # проверить есть ли герой\n",
    "        try:\n",
    "            avgElo_hero = float(avgElo_hero)\n",
    "        except:\n",
    "            avgElo_hero = 0\n",
    "        # ДФ для avgELo героя по матчу\n",
    "        df_heroe = pd.DataFrame([avgElo_hero], columns=[her + '_AvgElo'])\n",
    "        df_heroe_match = pd.merge(df_heroe_match, df_heroe, left_index=True, right_index=True, how='outer')\n",
    "        df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "    df_AvgElo_heroes = pd.concat([df_AvgElo_heroes, df_heroe_match])\n",
    "    \n",
    "# df_AvgElo_heroes['mathc_id'] = main['match_id']\n",
    "df_AvgElo_heroes = df_AvgElo_heroes.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_AvgElo_heroes.to_csv('../tabel/table from Datdota/AvgElo Meta and Signatures Heroes/'+\n",
    "                        'Meta on {} to {} (TwoMonthAgo, All, more 20).csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метовые Пары героев AvgELo (TwoMonthAgo, Pro, more 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# создать основной ДФ, где будут записаны все матчи (id матча и rda героя)\n",
    "df_AvgElo_heroes = pd.DataFrame()\n",
    "df_AvgElo_for_two_heroes_in_two_teams = pd.DataFrame()\n",
    "# создать список названий колонок всех героев\n",
    "all_her = main.loc[:,'radiant_H1':'dire_H5'].columns\n",
    "for index in main.index:\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "    # ДФ для соединения всех герове матча в один ДФ \n",
    "    df_heroe_match = pd.DataFrame()\n",
    "    # дата матча\n",
    "    date_match = date.fromtimestamp(main['start_time'][index])\n",
    "    # предыдущий день\n",
    "    date_match =  date_match - timedelta(1)\n",
    "    # создать дату два месяца назад от даты матча\n",
    "    two_month_ago = date_match - timedelta(60)\n",
    "    # создать ссылку с данными по Avg.Elo для двух предыдущих месяцев игры\n",
    "    url = ('http://www.datdota.com/api/heroes/elo?tier=1&valve-event=does-not-matter&threshold=8' +\n",
    "        PATCH + \n",
    "        '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03&patch=7.02' + \n",
    "        '&patch=7.01&patch=7.00&patch=6.88&patch=6.87&patch=6.86&patch=6.85'+\n",
    "        '&patch=6.84&patch=6.83&patch=6.82&patch=6.81&patch=6.80&patch=6.79&patch=6.78&patch=6.77'+\n",
    "        '&patch=6.76&patch=6.75&patch=6.74'+\n",
    "        '&winner=either'+\n",
    "        '&after={}%2F{}%2F{}'.format(two_month_ago.day, two_month_ago.month, two_month_ago.year) + \n",
    "        '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year) + \n",
    "        '&duration=0%3B200&duration-value-from=0&duration-value-to=200')\n",
    "    # выгрузить все с сайта и создать ДФ\n",
    "    dat = get_json_from_url(url)\n",
    "    df_url = pd.DataFrame(dat.get('data'))\n",
    "    # создать ДФ для одного героя за 2 предыдущих месяца\n",
    "    df_data_tabel_for_heroes, df_data_tabel_for_Twoheroes = get_df_avgElo_heroes(date_match, df_url)\n",
    "    \n",
    "    # Массив героев в матче \n",
    "    arr_heroes_in_match = main.loc[index,'radiant_H1':'dire_H5'].values\n",
    "    \n",
    "    # Создать два ДФ для редиант и даер по парным связкам AvgElo\n",
    "    rad = get_df_AvgElo_for_two_heroes_in_teams(arr_heroes_in_match, df_data_tabel_for_Twoheroes, 'radiant')\n",
    "    di =  get_df_AvgElo_for_two_heroes_in_teams(arr_heroes_in_match, df_data_tabel_for_Twoheroes, 'dire')\n",
    "    df_AvgElo_for_two_heroes_in_match = pd.merge(rad, di, \n",
    "                                                   left_index=True, right_index=True, how='outer')\n",
    "    df_AvgElo_for_two_heroes_in_match['match_id'] = main.loc[index, 'match_id'] \n",
    "    df_AvgElo_for_two_heroes_in_two_teams = pd.concat([\n",
    "                                df_AvgElo_for_two_heroes_in_two_teams, df_AvgElo_for_two_heroes_in_match ])\n",
    "\n",
    "df_AvgElo_for_two_heroes_in_two_teams = df_AvgElo_for_two_heroes_in_two_teams.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_AvgElo_for_two_heroes_in_two_teams.to_csv('../tabel/table from Datdota/'+\n",
    "                        'AvgElo Meta and Signatures Heroes/Meta AvgElo Couples/'+\n",
    "                        'Meta couples heroes on {} to {} (TwoMonthAgo, Pro, more 8).csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сигнатурки для Игроков включая KDA (Позже добавить HD, TD, LVL... когда noxvil добавит в таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 1h 42min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Вытащить данные по героям для игроков (elo, gpm, xpm, kda). Передается DF в который добаляются все данные по одному матчу\n",
    "def get_players_heroes(df_heroe_match, radiant_or_dire, index):\n",
    "    for i in range(1, 6):\n",
    "        # вытащить id героя\n",
    "        id_hero = main[radiant_or_dire + '_H' + str(i)][index]\n",
    "        # вытащить id игрока\n",
    "        id_player = main[radiant_or_dire + '_P' + str(i)][index]\n",
    "        \n",
    "        # создать ДФ c avgElo для игрока по ДАТЕ ИГРЫ\n",
    "        df_player = get_df_AvgElo_heroes_player(int(id_player), index)\n",
    "\n",
    "        try:\n",
    "            total = df_player['total'][df_player['hero'] == id_hero].values[0]\n",
    "            winrate = df_player['winrate'][df_player['hero'] == id_hero].values[0]\n",
    "            kills = df_player['kills'][df_player['hero'] == id_hero].values[0]\n",
    "            deaths = df_player['deaths'][df_player['hero'] == id_hero].values[0]\n",
    "            assists = df_player['assists'][df_player['hero'] == id_hero].values[0]\n",
    "            elo = df_player['eloShift'][df_player['hero'] == id_hero].values[0]\n",
    "            gpm = df_player['gpm'][df_player['hero'] == id_hero].values[0]\n",
    "            xpm = df_player['xpm'][df_player['hero'] == id_hero].values[0]\n",
    "            kda = df_player['kda'][df_player['hero'] == id_hero].values[0] \n",
    "            lastHits = df_player['lastHits'][df_player['hero'] == id_hero].values[0] \n",
    "            denies = df_player['denies'][df_player['hero'] == id_hero].values[0] \n",
    "\n",
    "        except:\n",
    "            total=0; winrate=0; kills=0; deaths=0; assists=0; elo=0; gpm=0;  xpm=0; kda=0; lastHits=0; denies=0;          \n",
    "        \n",
    "        # ДФ для героя игрока по матчу\n",
    "        df_heroe = pd.DataFrame([[total, winrate, kills, deaths, assists, elo, gpm, xpm, kda, lastHits, denies]], columns=[\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_totalGames',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_winrate',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_kills',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_deaths',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_assists',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_eloShift',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_gpm',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_xpm',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_kda',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_lastHits',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_denies'])\n",
    "        df_heroe_match = pd.merge(df_heroe_match, df_heroe, left_index=True, right_index=True, how='outer')\n",
    "    return df_heroe_match\n",
    "\n",
    "# создать основной ДФ, где будут записаны все матчи (id матча и rda героя)\n",
    "df_heroes_players_elo_gpm_xpm_kda = pd.DataFrame()\n",
    "\n",
    "# создать список названий колонок  героев radiant\n",
    "all_her_rad = main.loc[:,'radiant_H1':'radiant_H5'].columns\n",
    "# создать список названий колонок  героев radiant\n",
    "all_her_dir = main.loc[:,'dire_H1':'dire_H5'].columns\n",
    "# создать список названий колонок  игроков radiant\n",
    "all_play_rad = main.loc[:,'radiant_P1':'radiant_P5'].columns\n",
    "# создать список названий колонок  игроков radiant\n",
    "all_play_dir = main.loc[:,'dire_P1':'dire_P5'].columns\n",
    "\n",
    "for index in main.index:\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "        \n",
    "    # ДФ для соединения всех герове radiant & dire матча в один ДФ \n",
    "    df_heroe_match = pd.DataFrame()\n",
    "    \n",
    "    df_heroe_match = get_players_heroes(df_heroe_match, 'radiant', index)\n",
    "    df_heroe_match = get_players_heroes(df_heroe_match, 'dire', index)\n",
    "    df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "    \n",
    "    df_heroes_players_elo_gpm_xpm_kda = pd.concat([df_heroes_players_elo_gpm_xpm_kda, df_heroe_match])   \n",
    "df_heroes_players_elo_gpm_xpm_kda = df_heroes_players_elo_gpm_xpm_kda.reset_index().drop('index', axis=1)\n",
    "# df_heroes_players_elo_gpm_xpm_kda['match_id'] = main['match_id']        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_heroes_players_elo_gpm_xpm_kda.to_csv('../tabel/table from Datdota/KDA/Players/'+\n",
    "                          'KDA Players on hero {} to {} (All time, All, more 5).csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Каждый герой матча как фича"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 2.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Прочитать файл с героями\n",
    "heroes = pd.read_csv('../All_heroes.csv').drop(['id.1'], axis=1)\n",
    "\n",
    "# Создвание списка имен героев и списка имен команд и объединение его\n",
    "name_heroes = heroes['localized_name'].values\n",
    "\n",
    "# основной df c которым потом работать, в нем так же будут записаны килы и радинт_вин  \n",
    "df_features_name = pd.DataFrame(columns=name_heroes)\n",
    "\n",
    "# Собрать все команды и героев\n",
    "for index in main.index:\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "    # radiant\n",
    "    for i in range(1,6):\n",
    "        id_her = main['radiant_H' + str(i)].loc[index]\n",
    "        name_her = heroes['localized_name'][heroes['id'] == id_her].item()\n",
    "        df_features_name.loc[index, name_her] = 1\n",
    "    # dire\n",
    "    for i in range(1,6):\n",
    "        id_her = main['dire_H' + str(i)].loc[index]\n",
    "        name_her = heroes['localized_name'][heroes['id'] == id_her].item()\n",
    "        df_features_name.loc[index, name_her] = -1     \n",
    "df_features_name['match_id'] = main['match_id']\n",
    "\n",
    "df_features_name = df_features_name.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_features_name.to_csv('../tabel/table from Datdota/Features Heroes/' +\n",
    "                        'PREMIUM on {} to {}.csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДФ с данными по предсказаниями по рейтингу команд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n",
      "325\n",
      "Index(['radiant_win', 'radiant_mu_glicko', 'radiant_rating_glicko',\n",
      "       'radiant_ratingSevenDaysAgo_glicko', 'radiant_mu_glicko2',\n",
      "       'dire_mu_glicko', 'dire_rating_glicko',\n",
      "       'dire_ratingSevenDaysAgo_glicko', 'dire_sigma_glicko',\n",
      "       'dire_mu_glicko2', 'dire_ratingSevenDaysAgo_glicko2', 'mu_glicko',\n",
      "       'rating_glicko', 'ratingSevenDaysAgo_glicko', 'mu_glicko2',\n",
      "       'phi_glicko2'],\n",
      "      dtype='object')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   dire_win       0.66      0.61      0.64       148\n",
      "radiant_win       0.70      0.73      0.71       177\n",
      "\n",
      "avg / total       0.68      0.68      0.68       325\n",
      "\n",
      "AUC для градиентного бустинга - 0.713\n"
     ]
    }
   ],
   "source": [
    "# Общая функция для удобного обучения и предсказания на контрольных данных\n",
    "def get_main_df_for_predict(df_rating_teams_Premium):\n",
    "# -------- Создание основного ДФ -----------------------------------------------\n",
    "    # Соединение всех данных в один ДФ\n",
    "    main = df_rating_teams_Premium\n",
    "\n",
    "    # удаление не нужных колонок для обучения\n",
    "    main = main.drop(['match_id', 'start_time', 'radiant_team_id', 'radiant_score', 'dire_team_id',\n",
    "               'dire_score', 'radiant_name', 'dire_name','league_name'], axis=1)\n",
    "    main = main.drop(main.loc[:, 'radiant_H1' : 'dire_P5'], axis=1)\n",
    "\n",
    "    # # Оставляю только важные фичи, убираю из рейтинга команд ело32 и ело64\n",
    "    main = main.drop(main.loc[:, 'radiant_current_elo32':'radiant_thirtyDayAvg_elo64'], axis=1)\n",
    "    main = main.drop(main.loc[:, 'dire_current_elo32':'dire_thirtyDayAvg_elo64'], axis=1)\n",
    "    print (len(main))\n",
    "# -------- Заполнить или удалить NaN и добаить коллонку с предсказаниями, обучеными ранее -----------------------------------------------       \n",
    "    # убрать пустые ячейки\n",
    "    main = main.dropna()\n",
    "    print(len(main))\n",
    "#---------- Для рейтинга команд -----------------------------------------------------------\n",
    "    main['mu_glicko'] = main['radiant_mu_glicko'] -  main['dire_mu_glicko']\n",
    "    main['rating_glicko'] = main['radiant_rating_glicko'] -  main['dire_rating_glicko']\n",
    "    main['ratingSevenDaysAgo_glicko'] = main['radiant_ratingSevenDaysAgo_glicko'] -  main['dire_ratingSevenDaysAgo_glicko']\n",
    "    main['mu_glicko2'] = main['radiant_mu_glicko2'] -  main['dire_mu_glicko2']\n",
    "    main['phi_glicko2'] = main['radiant_phi_glicko2'] -  main['dire_phi_glicko2'] \n",
    "# -------- Убрать лишние колонки -----------------------------------------------  \n",
    "#     main = main.drop(['radiant_sigma_glicko', \n",
    "#                        'radiant_phi_glicko2', 'dire_phi_glicko2',\n",
    "#                        'radiant_rating_glicko2', 'dire_rating_glicko2', \n",
    "#                        'radiant_ratingSevenDaysAgo_glicko2',\n",
    "#                       # иногда почему-то надо удалять\n",
    "#                      'dire_thirtyDayAgo_elo64', 'radiant_thirtyDayAgo_elo64', \n",
    "#                       'dire_sevenDayAgo_elo64', 'radiant_sevenDayAgo_elo64'\n",
    "                      \n",
    "#                      ], axis=1)\n",
    "    # Почему-то изменился порядок колоно из исходных данных и поэтому нужно создать правильный порядок\n",
    "    main = main[['radiant_win', 'radiant_mu_glicko', 'radiant_rating_glicko', 'radiant_ratingSevenDaysAgo_glicko', 'radiant_mu_glicko2', \n",
    " 'dire_mu_glicko', 'dire_rating_glicko', 'dire_ratingSevenDaysAgo_glicko', 'dire_sigma_glicko', 'dire_mu_glicko2', \n",
    " 'dire_ratingSevenDaysAgo_glicko2', 'mu_glicko', 'rating_glicko', 'ratingSevenDaysAgo_glicko', 'mu_glicko2',\n",
    " 'phi_glicko2']]\n",
    "    \n",
    "    print(main.columns)\n",
    "    return main\n",
    "\n",
    "XGB = pickle.load(open('../Work/Xgboost_model_predict_rating_teams_without_elo.sav', 'rb'))\n",
    "\n",
    "# дф с матчами и рейтингом каждой команды с \n",
    "df_rating_teams_Premium_contr = pd.read_csv('../tabel/table from Datdota/Rating teams/'+\n",
    "                                      'PREMIUM on {} to {} (PreDay).csv'.format(day_one, day_end), index_col=0)\n",
    "\n",
    "contr = get_main_df_for_predict(df_rating_teams_Premium_contr)\n",
    "# Создание контрольной выборки\n",
    "# Cделать обучающие данные и ответы\n",
    "X_contr = contr.drop(['radiant_win'], axis=1)\n",
    "y_contr = contr['radiant_win']\n",
    "\n",
    "# СДЕЛАТЬ 1 или 0 вместо true false\n",
    "y_contr = y_contr.astype(int)\n",
    "print(classification_report(y_contr, XGB.predict(X_contr), target_names=['dire_win', 'radiant_win']))\n",
    "gb_auc = metrics.roc_auc_score(y_contr, XGB.predict_proba(X_contr)[:,1])\n",
    "print('AUC для градиентного бустинга - {:.3f}'.format(gb_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создать и сохранить фичу с предсказаниями по алгоритму, обученому на рейтинге команд\n",
    "df_pedict_for_rating_teams = pd.DataFrame(XGB.predict_proba(X_contr)[:,1:], columns=['Predict'])\n",
    "df_pedict_for_rating_teams['match_id'] = df_rating_teams_Premium_contr['match_id'].reset_index().drop('index', axis=1)\n",
    "df_pedict_for_rating_teams.to_csv('../tabel/table from Datdota/Rating teams/'+\n",
    "                           'Predict for rating teams on {} to {}.csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тип атаки и тип героев (Пока не используется)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 19.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Прочитать файл с героями\n",
    "heroes = pd.read_csv('../All_heroes.csv').drop(['id.1'], axis=1)\n",
    "# Создвание списка имен героев и списка имен команд и объединение его\n",
    "name_heroes = heroes['localized_name'].values\n",
    "columns = ['attac_type1','Disabler1','Nuker1','Carry1','Initiator1','Escape1','Durable1','Support1','Pusher1','Jungler1',\n",
    "           'attac_type2','Disabler2','Nuker2','Carry2','Initiator2','Escape2','Durable2','Support2','Pusher2','Jungler2',\n",
    "           'attac_type3','Disabler3','Nuker3','Carry3','Initiator3','Escape3','Durable3','Support3','Pusher3','Jungler3',\n",
    "           'attac_type4','Disabler4','Nuker4','Carry4','Initiator4','Escape4','Durable4','Support4','Pusher4','Jungler4',\n",
    "           'attac_type5','Disabler5','Nuker5','Carry5','Initiator5','Escape5','Durable5','Support5','Pusher5','Jungler5',\n",
    "           'attac_type6','Disabler6','Nuker6','Carry6','Initiator6','Escape6','Durable6','Support6','Pusher6','Jungler6',\n",
    "           'attac_type7','Disabler7','Nuker7','Carry7','Initiator7','Escape7','Durable7','Support7','Pusher7','Jungler7',\n",
    "           'attac_type8','Disabler8','Nuker8','Carry8','Initiator8','Escape8','Durable8','Support8','Pusher8','Jungler8',\n",
    "           'attac_type9','Disabler9','Nuker9','Carry9','Initiator9','Escape9','Durable9','Support9','Pusher9','Jungler9',\n",
    "     'attac_type10','Disabler10','Nuker10','Carry10','Initiator10','Escape10','Durable10','Support10','Pusher10','Jungler10']\n",
    "\n",
    "list_scripts = ['Disabler', 'Nuker', 'Carry', 'Initiator', 'Escape', 'Durable',\n",
    "                'Support', 'Pusher', 'Jungler']\n",
    "\n",
    "# функция для перевода в бинарное состояние типа атаки\n",
    "def atac(type_at):\n",
    "    if type_at == 'Melee':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "# df в который записыватеся пик команда с росписью кажого героя    \n",
    "df_script_her = pd.DataFrame(columns=columns)\n",
    "\n",
    "for index in main.index:\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "    # для radiant\n",
    "    for i in range(1,6):\n",
    "        id_her = main['radiant_H' + str(i)].loc[index]\n",
    "        df_script_her.loc[index, ('attac_type' + str(i))] = atac(heroes['attack_type'][heroes['id'] == id_her].item())\n",
    "        for col in list_scripts:\n",
    "            sc = heroes[col][(heroes['id'] == id_her)].item()\n",
    "            df_script_her.loc[index, (col + str(i))] = sc\n",
    "    # для dire\n",
    "    for i in range(1,6):\n",
    "        id_her = main['dire_H' + str(i)].loc[index]\n",
    "        df_script_her.loc[index, ('attac_type' + str(i+5))] = atac(heroes['attack_type'][heroes['id'] == id_her].item())\n",
    "        for col in list_scripts:\n",
    "            sc = heroes[col][(heroes['id'] == id_her)].item()\n",
    "            df_script_her.loc[index, (col + str(i+5))] = sc      \n",
    "df_script_her['match_id'] = main['match_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_script_her.to_csv('../tabel/table from Datdota/Features carry, support, necker/'+\n",
    "                     'PREMIUM on {} to {}.csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Содать данные elo героев за 7 дней (Meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# создать основной ДФ, где будут записаны все матчи (id матча и rda героя)\n",
    "df_AvgElo_heroes_7day_ago = pd.DataFrame()\n",
    "\n",
    "# создать список названий колонок всех героев\n",
    "all_her = main.loc[:,'radiant_H1':'dire_H5'].columns\n",
    "for index in main.index:\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "    # ДФ для соединения всех герове матча в один ДФ \n",
    "    df_heroe_match = pd.DataFrame()\n",
    "    # дата матча\n",
    "    date_match = date.fromtimestamp(main['start_time'][index])\n",
    "    # предыдущий день\n",
    "    date_match =  date_match - timedelta(1)\n",
    "    # создать дату два месяца назад от даты матча\n",
    "    seven_day_ago = date_match - timedelta(7)\n",
    "    # создать ссылку с данными по Avg.Elo для двух предыдущих месяцев игры\n",
    "    url = ('http://www.datdota.com/api/heroes/elo?tier=1&tier=2&tier=3&valve-event=does-not-matter&threshold=10' +\n",
    "        PATCH + \n",
    "        '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03&patch=7.02' + \n",
    "        '&patch=7.01&patch=7.00&patch=6.88&patch=6.87&patch=6.86&patch=6.85'+\n",
    "        '&patch=6.84&patch=6.83&patch=6.82&patch=6.81&patch=6.80&patch=6.79&patch=6.78&patch=6.77'+\n",
    "        '&patch=6.76&patch=6.75&patch=6.74'+\n",
    "        '&winner=either'+\n",
    "        '&after={}%2F{}%2F{}'.format(seven_day_ago.day, seven_day_ago.month, seven_day_ago.year) + \n",
    "        '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year) + \n",
    "        '&duration=0%3B200&duration-value-from=0&duration-value-to=200')\n",
    "    # выгрузить все с сайта и создать ДФ\n",
    "    dat = get_json_from_url(url)\n",
    "    df_url = pd.DataFrame(dat.get('data'))\n",
    "    try:\n",
    "        # создать ДФ для одного героя за 7 предыдущих дней\n",
    "        df_data_tabel_for_heroes = get_df_avgElo_heroes(date_match, df_url)\n",
    "\n",
    "        for her in all_her:\n",
    "            # вытащить id героя\n",
    "            id_hero = main[her][index]\n",
    "\n",
    "            # вытащить avg elo для данного героя\n",
    "            avgElo_hero = df_data_tabel_for_heroes.loc[(index for index, x in enumerate(\n",
    "                                                df_data_tabel_for_heroes['heroes']) if x == [id_hero]),'eloShift']\n",
    "\n",
    "            # проверить есть ли герой\n",
    "            try:\n",
    "                avgElo_hero = float(avgElo_hero)\n",
    "            except:\n",
    "                avgElo_hero = 0\n",
    "            # ДФ для avgELo героя по матчу\n",
    "            df_heroe = pd.DataFrame([avgElo_hero], columns=[her + '_AvgElo_7day_ago'])\n",
    "            df_heroe_match = pd.merge(df_heroe_match, df_heroe, left_index=True, right_index=True, how='outer')\n",
    "            df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "    except:\n",
    "        for her in all_her:\n",
    "            avgElo_hero = 0\n",
    "            # ДФ для avgELo героя по матчу\n",
    "            df_heroe = pd.DataFrame([avgElo_hero], columns=[her + '_AvgElo_7day_ago'])\n",
    "            df_heroe_match = pd.merge(df_heroe_match, df_heroe, left_index=True, right_index=True, how='outer')\n",
    "            df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "    df_AvgElo_heroes_7day_ago = pd.concat([df_AvgElo_heroes_7day_ago, df_heroe_match])\n",
    "    \n",
    "df_AvgElo_heroes_7day_ago = df_AvgElo_heroes_7day_ago.reset_index().drop('index', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_AvgElo_heroes_7day_ago = df_AvgElo_heroes_7day_ago.fillna(0)\n",
    "df_AvgElo_heroes_7day_ago.to_csv('../tabel/table from Datdota/AvgElo Meta and Signatures Heroes/'+\n",
    "                        'Meta on {} to {} (7DayAgo, All, more 10).csv'.format(day_one, day_end))\n",
    "# df_AvgElo_heroes_7day_ago.to_csv('../tabel/table from Datdota/AvgElo Meta and Signatures Heroes/'+\n",
    "#                         'Meta on {} to {} (7DayAgo, Pro, more 5).csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Как игрок отыграл за последние 7 дней (KDA, EloShift, different_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# вытащить таблицу с elo героев  по каждому игроку\n",
    "def get_df_player_7day_ago(player, index):\n",
    "    # дата матча\n",
    "    date_match = date.fromtimestamp(main['start_time'][index])\n",
    "    \n",
    "    date_match = date_match - timedelta(1)\n",
    "    seven_day_ago = date_match - timedelta(7)\n",
    "    # создать ДФ для соло героев за все время игр игрока (сигнатурки)\n",
    "    url = ('http://www.datdota.com/api/players/hero-combos?players={}'.format(player) +\n",
    "    PATCH +\n",
    "    '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03&patch=7.02'+\n",
    "    '&patch=7.01&patch=7.00&patch=6.88&patch=6.87&patch=6.86&patch=6.85&patch=6.84&patch=6.83&patch=6.82&patch=6.81'+\n",
    "    '&patch=6.80&patch=6.79&patch=6.78&patch=6.77&patch=6.76&patch=6.75&patch=6.74&winner=either'+\n",
    "    '&after={}%2F{}%2F{}'.format(seven_day_ago.day, seven_day_ago.month, seven_day_ago.year)+\n",
    "    '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year)+\n",
    "    '&duration=0%3B200&duration-value-from=0&duration-value-to=200&tier=1&tier=2&tier=3'+\n",
    "    '&valve-event=does-not-matter&threshold=1')\n",
    "    # выгрузить все с сайта и создать ДФ\n",
    "    try:\n",
    "        dat = get_json_from_url(url)\n",
    "    except:\n",
    "        dat = {'data':[]}\n",
    "    df_url = pd.DataFrame(dat.get('data'))\n",
    "    \n",
    "    return df_url\n",
    "\n",
    "def get_elo_players_heroes_7day_ago(df_heroe_match, radiant_or_dire, index):\n",
    "    for i in range(1, 6):\n",
    "        # вытащить id игрока\n",
    "        id_player = main[radiant_or_dire + '_P' + str(i)][index]\n",
    "        \n",
    "        # создать ДФ c avgElo для игрока по ДАТЕ ИГРЫ\n",
    "        df_player = get_df_player_7day_ago(int(id_player), index)\n",
    "        df_player = df_player.dropna()\n",
    "        try:\n",
    "            # diffferent_H - на скольких разных героях отыграл этот игрок за 7 дней\n",
    "            different_H = len(df_player)\n",
    "            winrate = df_player['winrate'].mean()\n",
    "            kills = df_player['kills'].mean()\n",
    "            deaths = df_player['deaths'].mean()\n",
    "            assists = df_player['assists'].mean()\n",
    "            elo = df_player['eloShift'].mean()\n",
    "            gpm = df_player['gpm'].mean()\n",
    "            xpm = df_player['xpm'].mean()\n",
    "            kda = df_player['kda'].mean()\n",
    "            lastHits = df_player['lastHits'].mean()\n",
    "            denies = df_player['denies'].mean()\n",
    "        except:\n",
    "            different_H=0; winrate=0; kills=0; deaths=0; assists=0; elo=0; gpm=0;  xpm=0; kda=0; lastHits=0; denies=0;            \n",
    "        # ДФ для героя игрока по матчу\n",
    "        df_heroe = pd.DataFrame([[different_H, winrate, kills, deaths, assists, elo, gpm, xpm, kda, lastHits, denies\n",
    "                                 ]], columns=[radiant_or_dire + '_P' + str(i) + '_different_H_7day_ago',\n",
    "                                                radiant_or_dire + '_P' + str(i) + '_winrate_7day_ago',\n",
    "                                                radiant_or_dire + '_P' + str(i) + '_kills_7day_ago',\n",
    "                                                radiant_or_dire + '_P' + str(i) + '_deaths_7day_ago',\n",
    "                                                radiant_or_dire + '_P' + str(i) + '_assists_7day_ago',\n",
    "                                                radiant_or_dire + '_P' + str(i) + '_eloShift_7day_ago',\n",
    "                                                radiant_or_dire + '_P' + str(i) + '_gpm_7day_ago',\n",
    "                                                radiant_or_dire + '_P' + str(i) + '_xpm_7day_ago',\n",
    "                                                radiant_or_dire + '_P' + str(i) + '_kda_7day_ago',\n",
    "                                                radiant_or_dire + '_P' + str(i) + '_lastHits_7day_ago',\n",
    "                                                radiant_or_dire + '_P' + str(i) + '_denies_7day_ago',])\n",
    "\n",
    "        df_heroe_match = pd.merge(df_heroe_match, df_heroe, left_index=True, right_index=True, how='outer')\n",
    "    return df_heroe_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 19min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Вытащить elo игорока за последние 7 дней. Передается DF в который добаляются все данные по одному матчу\n",
    "# создать основной ДФ, где будут записаны все матчи (id матча и rda героя)\n",
    "df_heroes_players_elo_7day_ago = pd.DataFrame()\n",
    "\n",
    "for index in main.index:\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "        \n",
    "    # ДФ для соединения всех герове radiant & dire матча в один ДФ \n",
    "    df_heroe_match = pd.DataFrame()\n",
    "    \n",
    "    df_heroe_match = get_elo_players_heroes_7day_ago(df_heroe_match, 'radiant', index)\n",
    "    df_heroe_match = get_elo_players_heroes_7day_ago(df_heroe_match, 'dire', index)\n",
    "    df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "    \n",
    "    df_heroes_players_elo_7day_ago = pd.concat([df_heroes_players_elo_7day_ago, df_heroe_match])   \n",
    "df_heroes_players_elo_7day_ago = df_heroes_players_elo_7day_ago.reset_index().drop('index', axis=1)\n",
    "# df_heroes_players_elo_gpm_xpm_kda['match_id'] = main['match_id']        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_heroes_players_elo_7day_ago = df_heroes_players_elo_7day_ago.fillna(0)\n",
    "df_heroes_players_elo_7day_ago.to_csv('../tabel/table from Datdota/KDA/Players/7day_ago/'+\n",
    "                          'KDA, EloShift Players on {} to {} (7day_ago, All, more 1).csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HD, TD, LVL, HH, GS у игроков на героях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 1h 45min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Вытащить данные по героям для игроков (elo, gpm, xpm, kda). Передается DF в который добаляются все данные по одному матчу\n",
    "def get_players_heroes_HD_TD(df_heroe_match, radiant_or_dire, index):\n",
    "    for i in range(1, 6):\n",
    "        # вытащить id героя\n",
    "        id_hero = main[radiant_or_dire + '_H' + str(i)][index]\n",
    "        # вытащить id игрока\n",
    "        id_player = main[radiant_or_dire + '_P' + str(i)][index]\n",
    "        \n",
    "        # дата матча\n",
    "        date_match = date.fromtimestamp(main['start_time'][index])\n",
    "        date_match = date_match - timedelta(1)\n",
    "\n",
    "        # создать ДФ для соло героев за все время игр игрока (сигнатурки)\n",
    "        url = ('http://www.datdota.com/api/heroes/performances?players={}'.format(int(id_player)) +\n",
    "        PATCH +\n",
    "        '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03&patch=7.02'+\n",
    "        '&patch=7.01&patch=7.00&patch=6.88&patch=6.87&patch=6.86&patch=6.85&patch=6.84&patch=6.83&patch=6.82&patch=6.81'+\n",
    "        '&patch=6.80&patch=6.79&patch=6.78&patch=6.77&patch=6.76&patch=6.75&patch=6.74&winner=either'+\n",
    "        '&after=01%2F01%2F2011&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year)+\n",
    "        '&duration=0%3B200&duration-value-from=0&duration-value-to=200&tier=1&tier=2&tier=3'+\n",
    "        '&valve-event=does-not-matter&threshold=5')\n",
    "\n",
    "        # выгрузить все с сайта и создать ДФ\n",
    "        try:\n",
    "            dat = get_json_from_url(url)\n",
    "        except:\n",
    "            dat = {'data':[]}\n",
    "        df_player = pd.DataFrame(dat.get('data'))\n",
    "\n",
    "        try: \n",
    "            HD = df_player['heroDamage'][df_player['hero'] == id_hero].values[0]\n",
    "            TD = df_player['towerDamage'][df_player['hero'] == id_hero].values[0]\n",
    "            LVL = df_player['level'][df_player['hero'] == id_hero].values[0]\n",
    "            HH = df_player['heroHealing'][df_player['hero'] == id_hero].values[0]\n",
    "            GS = df_player['goldSpent'][df_player['hero'] == id_hero].values[0]\n",
    "        except:\n",
    "            HD=0; TD=0; LVL=0; HH=0; GS=0;         \n",
    "        \n",
    "        # ДФ для героя игрока по матчу\n",
    "        df_heroe = pd.DataFrame([[HD, TD, LVL, HH, GS]], columns=[\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_heroDamage',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_towerDamage',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_level',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_heroHealing',\n",
    "                                                                radiant_or_dire + '_P' + str(i) + '_goldSpent'])\n",
    "        df_heroe_match = pd.merge(df_heroe_match, df_heroe, left_index=True, right_index=True, how='outer')\n",
    "    return df_heroe_match\n",
    "\n",
    "# создать основной ДФ, где будут записаны все матчи (id матча и rda героя)\n",
    "df_heroes_players_HD_TD_LVL_HH_GS = pd.DataFrame()\n",
    "\n",
    "# создать список названий колонок  героев radiant\n",
    "all_her_rad = main.loc[:,'radiant_H1':'radiant_H5'].columns\n",
    "# создать список названий колонок  героев radiant\n",
    "all_her_dir = main.loc[:,'dire_H1':'dire_H5'].columns\n",
    "# создать список названий колонок  игроков radiant\n",
    "all_play_rad = main.loc[:,'radiant_P1':'radiant_P5'].columns\n",
    "# создать список названий колонок  игроков radiant\n",
    "all_play_dir = main.loc[:,'dire_P1':'dire_P5'].columns\n",
    "\n",
    "for index in main.index:\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "        \n",
    "    # ДФ для соединения всех герове radiant & dire матча в один ДФ \n",
    "    df_heroe_match = pd.DataFrame()\n",
    "    \n",
    "    df_heroe_match = get_players_heroes_HD_TD(df_heroe_match, 'radiant', index)\n",
    "    df_heroe_match = get_players_heroes_HD_TD(df_heroe_match, 'dire', index)\n",
    "    df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "    \n",
    "    df_heroes_players_HD_TD_LVL_HH_GS = pd.concat([df_heroes_players_HD_TD_LVL_HH_GS, df_heroe_match])   \n",
    "df_heroes_players_HD_TD_LVL_HH_GS = df_heroes_players_HD_TD_LVL_HH_GS.reset_index().drop('index', axis=1)\n",
    "# df_heroes_players_HD_TD_LVL_HH_GS['match_id'] = main['match_id']        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_heroes_players_HD_TD_LVL_HH_GS.to_csv('../tabel/table from Datdota/KDA/Players/'+\n",
    "                          'HD,TD,LVL,HH,GS Players on hero {} to {} (All time, All, more 5).csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDA и HD, TD... Для героев за последние 30 дней или за последний год, если не сыграно более 5 игр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Создание данных за последний год для героев до определенного дня и запись их  в один файл\n",
    "\n",
    "# date1 = datetime(2016, 12, 1)\n",
    "# date2 = datetime(2018, 6, 18)\n",
    "max_day = (day_end - day_one).days\n",
    "all_data = {}\n",
    "match_date = day_one \n",
    "for day in range(max_day):\n",
    "\n",
    "    date_year_ago = match_date - timedelta(365)\n",
    "    url_heroes =('http://www.datdota.com/api/heroes/performances?' + PATCH +\n",
    "            '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03' +\n",
    "            '&patch=7.02&patch=7.01&patch=7.00&patch=6.88&patch=6.87&patch=6.86&patch=6.85&patch=6.84&patch=6.83' +\n",
    "            '&patch=6.82&patch=6.81&patch=6.80&patch=6.79&patch=6.78&patch=6.77&patch=6.76&patch=6.75&patch=6.74' +\n",
    "            '&winner=either&after={}%2F{}%2F{}'.format(date_year_ago.day, date_year_ago.month, date_year_ago.year) + \n",
    "            '&before={}%2F{}%2F{}'.format(match_date.day, match_date.month, match_date.year) + \n",
    "            '&duration=0%3B200&duration-value-from=0&duration-value-to=200&tier=1' + \n",
    "            '&valve-event=does-not-matter&threshold=10') \n",
    "    \n",
    "    dat = get_json_from_url(url_heroes).get('data')\n",
    "    all_data[str(match_date)] = dat\n",
    "    match_date = match_date + timedelta(1)\n",
    "len(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_file = 'data_KDA_HD_TD_for_all_Heroes_on({})_to({}) (1Year_ago, Pro, more 10).txt'.format(\n",
    "                                                        day_one, day_end)\n",
    "with open(name_file, 'w') as outfile:\n",
    "    json.dump(all_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name_file = 'data_KDA_HD_TD_for_all_Heroes_on({})_to({}) (1Year_ago, Pro, more 10).txt'.format(day_one, day_end)\n",
    "\n",
    "with open(name_file, 'r') as outfile:\n",
    "    file_with_data_for_H_1Year_ago = json.load(outfile)\n",
    "\n",
    "# создать основной массив, где будут записаны все матчи (id матча и rda героя)\n",
    "df_basick_peromances_heroes_30Day_ago = pd.DataFrame()\n",
    "\n",
    "# создать список названий колонок всех героев\n",
    "all_her = main.loc[:,'radiant_H1':'dire_H5'].columns\n",
    "for index in main.index:\n",
    "    if index%100 == 0:\n",
    "        print (index)\n",
    "    # ДФ для соединения всех герове матча в один ДФ \n",
    "    df_heroe_match = pd.DataFrame()\n",
    "    # дата матча\n",
    "    date_match = date.fromtimestamp(main['start_time'][index])\n",
    "    # предыдущий день\n",
    "    date_match =  date_match - timedelta(1)\n",
    "    thirtieth_day_ago = date_match - timedelta(30)\n",
    "    url_heroes =('http://www.datdota.com/api/heroes/performances?' + PATCH +\n",
    "        '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03' +\n",
    "        '&patch=7.02&patch=7.01&patch=7.00&patch=6.88&patch=6.87' +\n",
    "        '&winner=either&after={}%2F{}%2F{}'.format(thirtieth_day_ago.day, thirtieth_day_ago.month, \n",
    "                                                   thirtieth_day_ago.year) + \n",
    "        '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year) + \n",
    "        '&duration=0%3B200&duration-value-from=0&duration-value-to=200&tier=1' + \n",
    "        '&valve-event=does-not-matter&threshold=5') \n",
    "#     print(url_heroes)\n",
    "    # выгрзить json с предыдущей ссылки\n",
    "    dat = get_json_from_url(url_heroes).get('data')\n",
    "\n",
    "    df_data_tabel_for_heroes = pd.DataFrame(dat)\n",
    "    # создание ДФ с данными за последний год до дня матча, из файла\n",
    "    df_data_tabel_for_heroes_1Year_ago = pd.DataFrame(file_with_data_for_H_1Year_ago.get(str(date_match)))\n",
    "#     print(dat)\n",
    "    for her in all_her:\n",
    "        # вытащить id героя\n",
    "        id_heroe = main[her][index]\n",
    "        try:\n",
    "            # создать массив с данными \n",
    "            array = df_data_tabel_for_heroes[df_data_tabel_for_heroes['hero'] == id_heroe].values\n",
    "            # Если нет данных по герою то взять данные по герою за последний год из файла\n",
    "            if len(array) == 0:\n",
    "                array = df_data_tabel_for_heroes_1Year_ago[df_data_tabel_for_heroes_1Year_ago['hero'] == id_heroe].values\n",
    "\n",
    "        except: # Если абсолютно новый герой то тогда поставить все 0\n",
    "            array = [[z*0 for z in range(21)]]\n",
    "        # создать название колонок для определнного героя\n",
    "        col = [her + '_' + c for c  in df_data_tabel_for_heroes_1Year_ago.columns + '_30day_ago']\n",
    "        # ДФ для героя по матчу\n",
    "        df_heroe = pd.DataFrame(array, columns=col)\n",
    "        df_heroe_match = pd.merge(df_heroe_match, df_heroe, \n",
    "                                               left_index=True, right_index=True, how='outer')\n",
    "        df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "    df_basick_peromances_heroes_30Day_ago = pd.concat([df_basick_peromances_heroes_30Day_ago, df_heroe_match])\n",
    "df_basick_peromances_heroes_30Day_ago = df_basick_peromances_heroes_30Day_ago.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_basick_peromances_heroes_30Day_ago.to_csv('../tabel/table from Datdota/KDA/Heroes/30day_ago/'+\n",
    "                          'KDA, HD, TD... heroes on {} to {} (30day_ago, Pro, more 5).csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пробные работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_df_avgElo_heroes(day_match, df):\n",
    "    # создать ДФ для одного героя, пары и тройки\n",
    "    df_one = df.loc[(index for index, x in enumerate(df['heroes']) if len(x) == 1), :]  \n",
    "    df_one = df_one.reset_index().drop('index', axis=1)\n",
    "    df_double = df.loc[(index for index, x in enumerate(df['heroes']) if len(x) == 2), :]  \n",
    "    df_double = df_double.reset_index().drop('index', axis=1)\n",
    "#     df_triple = df.loc[(index for index, x in enumerate(df['heroes']) if len(x) == 3), :]  \n",
    "    return df_one, df_double#, df_triple\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метовые герои AvgELo (TwoMonthAgo, Pro, more 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# создать основной ДФ, где будут записаны все матчи (id матча и rda героя)\n",
    "df_AvgElo_heroes = pd.DataFrame()\n",
    "df_AvgElo_for_two_heroes_in_two_teams = pd.DataFrame()\n",
    "# создать список названий колонок всех героев\n",
    "all_her = main.loc[:,'radiant_H1':'dire_H5'].columns\n",
    "for index in main.index:\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "    # ДФ для соединения всех герове матча в один ДФ \n",
    "    df_heroe_match = pd.DataFrame()\n",
    "    # дата матча\n",
    "    date_match = date.fromtimestamp(main['start_time'][index])\n",
    "    # предыдущий день\n",
    "    date_match =  date_match - timedelta(1)\n",
    "    # создать дату два месяца назад от даты матча\n",
    "    two_month_ago = date_match - timedelta(60)\n",
    "    # создать ссылку с данными по Avg.Elo для двух предыдущих месяцев игры\n",
    "    url = ('http://www.datdota.com/api/heroes/elo?tier=1&valve-event=does-not-matter&threshold=8' +\n",
    "        PATCH + \n",
    "        '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03&patch=7.02' + \n",
    "        '&patch=7.01&patch=7.00&patch=6.88&patch=6.87&patch=6.86&patch=6.85'+\n",
    "        '&patch=6.84&patch=6.83&patch=6.82&patch=6.81&patch=6.80&patch=6.79&patch=6.78&patch=6.77'+\n",
    "        '&patch=6.76&patch=6.75&patch=6.74'+\n",
    "        '&winner=either'+\n",
    "        '&after={}%2F{}%2F{}'.format(two_month_ago.day, two_month_ago.month, two_month_ago.year) + \n",
    "        '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year) + \n",
    "        '&duration=0%3B200&duration-value-from=0&duration-value-to=200')\n",
    "    # выгрузить все с сайта и создать ДФ\n",
    "    dat = get_json_from_url(url)\n",
    "    df_url = pd.DataFrame(dat.get('data'))\n",
    "    # создать ДФ для одного героя за 2 предыдущих месяца\n",
    "    df_data_tabel_for_heroes, df_data_tabel_for_Twoheroes = get_df_avgElo_heroes(date_match, df_url)\n",
    "    \n",
    "    # Массив героев в матче \n",
    "    arr_heroes_in_match = main.loc[index,'radiant_H1':'dire_H5'].values\n",
    "    \n",
    "    # Создать два ДФ для редиант и даер по парным связкам AvgElo\n",
    "    rad = get_df_AvgElo_for_two_heroes_in_teams(arr_heroes_in_match, df_data_tabel_for_Twoheroes, 'radiant')\n",
    "    di =  get_df_AvgElo_for_two_heroes_in_teams(arr_heroes_in_match, df_data_tabel_for_Twoheroes, 'dire')\n",
    "    df_AvgElo_for_two_heroes_in_match = pd.merge(rad, di, \n",
    "                                                   left_index=True, right_index=True, how='outer')\n",
    "    df_AvgElo_for_two_heroes_in_match['match_id'] = main.loc[index, 'match_id'] \n",
    "    df_AvgElo_for_two_heroes_in_two_teams = pd.concat([\n",
    "                                df_AvgElo_for_two_heroes_in_two_teams, df_AvgElo_for_two_heroes_in_match ])\n",
    "\n",
    "df_AvgElo_for_two_heroes_in_two_teams = df_AvgElo_for_two_heroes_in_two_teams.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_AvgElo_for_two_heroes_in_two_teams.to_csv('../tabel/table from Datdota/'+\n",
    "                        'AvgElo Meta and Signatures Heroes/Meta AvgElo Couples/'+\n",
    "                        'Meta couples heroes on {} to {} (TwoMonthAgo, Pro, more 8).csv'.format(day_one, day_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
