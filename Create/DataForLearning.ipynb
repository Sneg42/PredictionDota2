{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\User\\\\1_MY_WORK\\\\1_Data_Scientist_and_ML_Project\\\\PredictionDota2\\\\HelpModules')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib, json\n",
    "from datetime import date, timedelta, datetime\n",
    "import re, requests, pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from connection_to_internet import Connection_to_internet\n",
    "\n",
    "class DataForLearing:\n",
    "    def __init__(self, date_first, date_end, PATCH):\n",
    "        self.date_first = date_first\n",
    "        self.date_end = date_end\n",
    "        self.day_first_for_saving_in_file = date_first.date()\n",
    "        self.day_end_for_saving_in_file = date_end.date()\n",
    "        OLD_PATCH_FROM688 = ('&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05' +\n",
    "            '&patch=7.04&patch=7.03&patch=7.02&patch=7.01&patch=7.00&patch=6.88')\n",
    "        self.PATCH = PATCH + OLD_PATCH_FROM688\n",
    "        \n",
    "        connect = Connection_to_internet()\n",
    "        self.__get_url_from_proxy = connect.get_url_from_proxy\n",
    "        self.__get_json_from_url = connect.get_json_from_url\n",
    "    \n",
    "    # ------- For SQL request to  Opendota  ----------------------------------------------------------------\n",
    "    def __query_data_matches(self):\n",
    "        sql = '''SELECT\n",
    "        \n",
    "        matches.match_id ,\n",
    "        matches.start_time,\n",
    "        matches.radiant_team_id,\n",
    "        matches.radiant_score,\n",
    "        matches.dire_team_id,\n",
    "        matches.dire_score,\n",
    "        matches.radiant_win\n",
    "        FROM matches\n",
    "        JOIN match_patch using(match_id)\n",
    "        JOIN leagues using(leagueid)\n",
    "        JOIN player_matches using(match_id)\n",
    "        JOIN heroes on heroes.id = player_matches.hero_id\n",
    "        LEFT JOIN notable_players ON notable_players.account_id = player_matches.account_id AND notable_players.locked_until = (SELECT MAX(locked_until) FROM notable_players)\n",
    "        LEFT JOIN teams using(team_id)\n",
    "        WHERE TRUE\n",
    "        AND matches.start_time >= extract(epoch from timestamp '{}')\n",
    "        AND matches.start_time <= extract(epoch from timestamp '{}')\n",
    "        AND leagues.tier = 'professional'\n",
    "        AND match_patch.patch >= '7.01'\n",
    "        GROUP BY matches.match_id\n",
    "        HAVING count(distinct matches.match_id) >= 1\n",
    "        LIMIT 2000000'''.format(self.date_first.isoformat() , self.date_end.isoformat()) \n",
    "        return  self.__query_opendota(sql)\n",
    "\n",
    "    def __query_teams_heroes_mathes(self):\n",
    "        sql = '''SELECT\n",
    "        \n",
    "        matches.match_id,\n",
    "        matches.start_time,\n",
    "        ((player_matches.player_slot < 128) = matches.radiant_win) win,\n",
    "        player_matches.hero_id,\n",
    "        player_matches.account_id,\n",
    "        leagues.name leaguename\n",
    "        FROM matches\n",
    "        JOIN match_patch using(match_id)\n",
    "        JOIN leagues using(leagueid)\n",
    "        JOIN player_matches using(match_id)\n",
    "        JOIN heroes on heroes.id = player_matches.hero_id\n",
    "        LEFT JOIN notable_players ON notable_players.account_id = player_matches.account_id AND notable_players.locked_until = (SELECT MAX(locked_until) FROM notable_players)\n",
    "        LEFT JOIN teams using(team_id)\n",
    "        WHERE TRUE\n",
    "        AND matches.start_time >= extract(epoch from timestamp '{}')\n",
    "        AND matches.start_time <= extract(epoch from timestamp '{}')\n",
    "        AND leagues.tier = 'professional'\n",
    "        AND match_patch.patch >= '7.01'\n",
    "        ORDER BY matches.match_id DESC NULLS LAST\n",
    "        LIMIT 2000000'''.format(self.date_first.isoformat() , self.date_end.isoformat()) \n",
    "        return self.__query_opendota(sql)\n",
    "    \n",
    "    def __query_opendota(self, sql):\n",
    "        resp = self.__get_url_from_proxy('https://api.opendota.com/api/explorer',({'sql': sql}))\n",
    "        data = resp.json()\n",
    "        return pd.DataFrame.from_records(data['rows'])\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def createAndSaveMainDf(self):\n",
    "        # создать главный ДФ, в который и будет все добавляться\n",
    "        main = pd.DataFrame(self.__query_data_matches())\n",
    "        # присвоить ДФ для обработки из нужного файла с героями и игроками\n",
    "        df_her_play = pd.DataFrame(self.__query_teams_heroes_mathes())\n",
    "        # собрать все матчи из ДФ с героями и игроками\n",
    "        matches = np.unique(df_her_play['match_id'])\n",
    "        for id_match in matches:\n",
    "            # номер индекса в галвном ДФ\n",
    "            main_index = main[main['match_id'] == id_match].index[0]\n",
    "            # создать два датафрейма по героям и игрокам (разделенных на выйгрывших и проигравших)\n",
    "            her_false = pd.DataFrame(df_her_play['hero_id'][df_her_play['match_id'] == id_match][\n",
    "                                                                                        df_her_play['win'] == False])\n",
    "            her_true = pd.DataFrame(df_her_play['hero_id'][df_her_play['match_id'] == id_match][\n",
    "                                                                                        df_her_play['win'] == True])\n",
    "            heroes = pd.concat([her_false, her_true]).reset_index().T.drop('index')\n",
    "            play_false = pd.DataFrame(df_her_play['account_id'][df_her_play['match_id'] == id_match][\n",
    "                                                                                        df_her_play['win'] == False])\n",
    "            play_true = pd.DataFrame(df_her_play['account_id'][df_her_play['match_id'] == id_match][\n",
    "                                                                                        df_her_play['win'] == True])\n",
    "            players = pd.concat([play_false, play_true]).reset_index().T.drop('index')\n",
    "\n",
    "            # соединение и присваивание нормальных имен столбцам в дф с героями и игроками\n",
    "            col_her = {0: 'lose_H1', 1: 'lose_H2', 2: 'lose_H3', 3: 'lose_H4', 4: 'lose_H5', \n",
    "                         5: 'win_H1', 6: 'win_H2', 7: 'win_H3', 8: 'win_H4', 9: 'win_H5'}\n",
    "            col_play = {0: 'lose_P1', 1: 'lose_P2', 2: 'lose_P3', 3: 'lose_P4', 4: 'lose_P5', \n",
    "                         5: 'win_P1', 6: 'win_P2', 7: 'win_P3', 8: 'win_P4', 9: 'win_P5'}\n",
    "            heroes = heroes.rename(columns=col_her,).rename( {'hero_id': 0})\n",
    "            players = players.rename(columns=col_play).rename( {'account_id': 0})\n",
    "\n",
    "            match = pd.merge(heroes, players,  left_index=True, right_index=True)\n",
    "            match['match_id'] = id_match\n",
    "\n",
    "            #ЗАменить название столбцов win or lose на радиант и даер\n",
    "            if main[main['match_id'] == id_match]['radiant_win'].bool() == False:\n",
    "                for i in range(1,6):\n",
    "                    main.loc[main_index, 'radiant_H' + str(i)] = match['lose_H' + str(i)][0]\n",
    "                for i in range(1,6):\n",
    "                    main.loc[main_index, 'dire_H' + str(i)] = match['win_H' + str(i)][0]\n",
    "                for i in range(1,6):\n",
    "                    main.loc[main_index, 'radiant_P' + str(i)] = match['lose_P' + str(i)][0]\n",
    "                for i in range(1,6):\n",
    "                    main.loc[main_index, 'dire_P' + str(i)] = match['win_P' + str(i)][0]\n",
    "\n",
    "            elif main[main['match_id'] == id_match]['radiant_win'].bool() == True:\n",
    "                for i in range(1,6):\n",
    "                    main.loc[main_index, 'radiant_H' + str(i)] = match['win_H' + str(i)][0]\n",
    "                for i in range(1,6):\n",
    "                    main.loc[main_index, 'dire_H' + str(i)] = match['lose_H' + str(i)][0]\n",
    "                for i in range(1,6):\n",
    "                    main.loc[main_index, 'radiant_P' + str(i)] = match['win_P' + str(i)][0]\n",
    "                for i in range(1,6):\n",
    "                    main.loc[main_index, 'dire_P' + str(i)] = match['lose_P' + str(i)][0]\n",
    "        # добавить лигу\n",
    "        for id_match in matches:\n",
    "            # номер индекса в галвном ДФ\n",
    "            main_index = main[main['match_id'] == id_match].index[0]\n",
    "            df_her_play_index = df_her_play[df_her_play['match_id'] == id_match].index[0]\n",
    "\n",
    "            main.loc[main_index, 'league_name'] = df_her_play.loc[df_her_play_index,'leaguename']\n",
    "        main.to_csv('../tabel/MAIN TABEL PREMIUM on {} to {}.csv'.format(self.day_first_for_saving_in_file, \n",
    "                                                                         self.day_end_for_saving_in_file))\n",
    "        print('MAIN - ', len(main))\n",
    "        return main\n",
    "    \n",
    "    def createColumnWithTeamName(self, main):\n",
    "        # создать дф из json по всем командам с OPENDOTA https://api.opendota.com/api/teams\n",
    "        url_teams_name = \"https://api.opendota.com/api/teams\"\n",
    "        dat = self.__get_json_from_url(url_teams_name)\n",
    "        # дф с именем команды и ее id\n",
    "        df_team_id = pd.DataFrame(dat).loc[:,['name', 'team_id']]\n",
    "\n",
    "        # создать столбцы с именами команд с opendota\n",
    "        for index in main.index:\n",
    "            try:\n",
    "                main.loc[index, 'radiant_name'] = (\n",
    "                    df_team_id.loc[df_team_id['team_id'] == main.loc[index, 'radiant_team_id'], 'name'].get_values()[0])\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                main.loc[index, 'dire_name'] = (\n",
    "                    df_team_id.loc[df_team_id['team_id'] == main.loc[index, 'dire_team_id'], 'name'].get_values()[0])\n",
    "            except:\n",
    "                continue\n",
    "#         print(main.columns)\n",
    "        main = main.dropna()\n",
    "        main['radiant_name'] = main['radiant_name'].apply(self.__reg)\n",
    "        main['dire_name'] = main['dire_name'].apply(self.__reg)\n",
    "        main = main.reset_index().drop('index', axis=1)\n",
    "        return main\n",
    "    # для преобразования имен команд (убрать лишние символы)\n",
    "    def __reg(self, x): \n",
    "        reg = re.compile('[^-a-zA-Z0-9_. 、]')\n",
    "        return reg.sub('', x)\n",
    "    \n",
    "    def delRepeatedTeamsInMain(self, main):\n",
    "        # на Opendota в рейтинге команд есть повторяющиеся команды но с разными ID_team\n",
    "        main = main[main['dire_team_id'] != 5065748]\n",
    "        main = main[main['radiant_team_id'] != 5065748]\n",
    "        main = main[main['dire_team_id'] != 2672298]\n",
    "        main = main[main['radiant_team_id'] != 2672298]\n",
    "        main = main[main['dire_team_id'] != 5196328]\n",
    "        main = main[main['radiant_team_id'] != 5196328]\n",
    "        main = main[main['dire_team_id'] != 2512249]\n",
    "        main = main[main['radiant_team_id'] != 2512249]\n",
    "        main = main[main['dire_team_id'] != 2790766]\n",
    "        main = main[main['radiant_team_id'] != 2790766]\n",
    "        main = main[main['dire_team_id'] != 5197722]\n",
    "        main = main[main['radiant_team_id'] != 5197722]\n",
    "        return main\n",
    "   # ------- Рейтинг команд по таблице рейтинга -------------------------------------------------------------- \n",
    "    def createAndSaveRatingTeamsOnTabelRating(self, main):\n",
    "        print('Рейтинг команд по таблице рейтинга')\n",
    "        # вытащить таблицу рейтинга на предыдущий день матча\n",
    "        def get_rating_table(time_match):\n",
    "            # работа с датами\n",
    "            date = time_match - timedelta(1)\n",
    "            # Открыть json с сайта и выгрузить данные\n",
    "            url = \"https://www.datdota.com/api/ratings?date={}-{}-{}\".format(date.day, date.month, date.year)\n",
    "            dat = self.__get_json_from_url(url)\n",
    "            data = dat.get('data')\n",
    "            # создать DF для сохранения\n",
    "            rating_team_date = pd.DataFrame() \n",
    "            # вытащить все команды и сохранить их данные в all_teams\n",
    "            for i in data:   \n",
    "                team = get_data_team(i) \n",
    "                rating_team_date = pd.concat([rating_team_date, team], ignore_index=True)    \n",
    "            # очистить имена команд\n",
    "            rating_team_date['team_Name'] = rating_team_date['team_Name'].apply(self.__reg)\n",
    "            return rating_team_date\n",
    "        # создать данные рейтинга команды по мнимальному рейтингу на день соревнований\n",
    "        def get_min_team_rating(team_name, dire_or_radiant, rating_team_date):\n",
    "            #взять минимальную команду в рейтинге\n",
    "            test_min_team_rating = rating_team_date[rating_team_date['current_elo32'] == min(rating_team_date['current_elo32'])]\n",
    "            test_min_team_rating = test_min_team_rating.drop(['phi_glicko', 'sigma_glicko2'],  axis=1)\n",
    "            # сменить имя в минимальном рейтиенге\n",
    "            test_min_team_rating['team_Name'] = team_name\n",
    "            test_min_team_rating.columns = [dire_or_radiant + '_' + str(col) for col in test_min_team_rating.columns]\n",
    "            return test_min_team_rating\n",
    "        # создать мапу с старыми и новыми именами колонок для рейтинга команд\n",
    "        def name_columns(z1, elo):\n",
    "            mapa = {}\n",
    "            for index, key in enumerate(z1.keys()):\n",
    "                mapa[key] = key + elo\n",
    "            return mapa\n",
    "        # вытащить все данные по рейтингу (elo32, elo64, glicko, glicko2) одной команды\n",
    "        def get_data_team(data):\n",
    "            ratings = ['elo32', 'elo64', 'glicko', 'glicko2']\n",
    "            #Создать колонку с именем команды\n",
    "            team = pd.DataFrame(columns=['team_Name'])\n",
    "            team['team_Name'] = [data.get('teamName')]\n",
    "\n",
    "            for rat in ratings:\n",
    "                current_rating = data.get(rat)\n",
    "                columns = name_columns(current_rating, '_' + rat)\n",
    "                df = pd.DataFrame(data.get(rat), index=range(0,1))     \n",
    "                df.rename(columns=columns, inplace=True)\n",
    "                team = pd.DataFrame.merge(team, df, left_index=True, right_index=True)\n",
    "            return team\n",
    "\n",
    "        df_rating_teams_on_tabel_rating = pd.DataFrame()\n",
    "        for index in  main.index:\n",
    "            if index%100 == 0:\n",
    "                print (index) \n",
    "            # вытащить одну строчку (для того чтобы потом добавить в основную таблицу. Пока оставить так, но в принципе можно \n",
    "            # уброть переменную one_match)\n",
    "            one_match = main.loc[[index]]\n",
    "            # достать дату матча\n",
    "            date_match =  date.fromtimestamp(one_match['start_time'][index])\n",
    "            # вытащить таблицу с рейтингами на предыдущий день матча\n",
    "            rating_team_date = get_rating_table(date_match)\n",
    "\n",
    "            # имена команд в матче\n",
    "            radiant_name = one_match['radiant_name'][index]\n",
    "            dire_name = one_match['dire_name'][index]\n",
    "\n",
    "            # вытащить команду radiant из рейтинга команд на предыдущий день соревнований\n",
    "            rating_radiant = rating_team_date[rating_team_date['team_Name'] == radiant_name]\n",
    "            if rating_radiant.empty == True:\n",
    "                # если команды нету в списке рейтинга взять данные по команде с минимальным рейтинго elo32\n",
    "                rating_radiant = get_min_team_rating(radiant_name, 'radiant', rating_team_date)\n",
    "            else:\n",
    "                rating_radiant = rating_radiant.drop(['phi_glicko', 'sigma_glicko2'],  axis=1)\n",
    "                # добавить к названиям столбцов 'radiant'\n",
    "                rating_radiant.columns = ['radiant_' + str(col) for col in rating_radiant.columns]\n",
    "\n",
    "            # вытащить команду dire из рейтинга команд на предыдущий денб соревнований\n",
    "            rating_dire = rating_team_date[rating_team_date['team_Name'] == dire_name]\n",
    "            if rating_dire.empty == True:\n",
    "                # если команды нету в списке рейтинга взять данные по команде с минимальным рейтинго elo32\n",
    "                rating_dire = get_min_team_rating(dire_name, 'dire', rating_team_date)\n",
    "            else:\n",
    "                rating_dire = rating_dire.drop(['phi_glicko', 'sigma_glicko2'],  axis=1)\n",
    "                # добавить к названиям столбцов 'dire'\n",
    "                rating_dire.columns = ['dire_' + str(col) for col in rating_dire.columns]\n",
    "\n",
    "            #соединить в одну строчку данные матча и данные с рейтинга каждой команды если присутсвуют данные по команде\n",
    "            rating_teams = pd.merge(one_match, rating_radiant,  left_on='radiant_name', right_on='radiant_team_Name')\n",
    "            rating_teams = pd.merge(rating_teams, rating_dire, left_on='dire_name', right_on='dire_team_Name')\n",
    "            rating_teams = rating_teams.drop(['dire_team_Name', 'radiant_team_Name'], axis=1)\n",
    "            # Если повторяющиеся команды  то длина будет два. НЕ ДОБАВЛЯТЬ ПОВТОРЯЮЩИЕСЯ КОМАНДЫ\n",
    "            if len(rating_teams) == 1:\n",
    "                df_rating_teams_on_tabel_rating = pd.concat([df_rating_teams_on_tabel_rating, rating_teams])\n",
    "        # match_rating_teams = match_rating_teams.reset_index().drop('index', axis=1)\n",
    "        df_rating_teams_on_tabel_rating.to_csv('../tabel/table from Datdota/Rating teams/' +\n",
    "                                    'PREMIUM on {} to {} (PreDay).csv'.format(self.day_first_for_saving_in_file, \n",
    "                                                                              self.day_end_for_saving_in_file))\n",
    "    # ------- Рейтинг команд по ссылке на данные команды ----------------------------------------------------------\n",
    "    def createAndSaveGlickoRatingTeamsOnLinkTeam(self, main):\n",
    "        print('Рейтинг команд по ссылке на данные команды')\n",
    "        def get_current_rating_teams(date_match, team_id, radiant_or_dire):\n",
    "            date_rating = date_match\n",
    "            date_rating_7day_ago = date_rating - timedelta(7)\n",
    "            # Достать данные по рейтингу для редиант на текущий день и семь дней назад\n",
    "            url = 'http://www.datdota.com/api/teams/{}/ratings?date={}-{}-{}'.format(\n",
    "                                        team_id, date_rating.year, date_rating.month, date_rating.day )\n",
    "            # выгрзить json с предыдущей ссылки и создать ДФ\n",
    "            dat = self.__get_json_from_url(url)\n",
    "            data = pd.DataFrame(dat.get('data'))\n",
    "\n",
    "            url_7day_ago = 'http://www.datdota.com/api/teams/{}/ratings?date={}-{}-{}'.format(\n",
    "                    team_id, date_rating_7day_ago.year, date_rating_7day_ago.month, date_rating_7day_ago.day )\n",
    "            # выгрзить json с предыдущей ссылки и создать ДФ\n",
    "            dat_7day_ago = self.__get_json_from_url(url_7day_ago)\n",
    "            data_7day_ago = pd.DataFrame(dat_7day_ago.get('data'))\n",
    "            # если нету данных 7 дней назад\n",
    "            try:\n",
    "                # бывает что не посчитан рейтинг для текущей недели и тогда взять 14 дней назад\n",
    "                if data_7day_ago.loc['startPeriod', 'GLICKO_1'] == data.loc['startPeriod', 'GLICKO_1']:\n",
    "                    date_rating_7day_ago = date_rating - timedelta(14)\n",
    "                    url_7day_ago = 'http://www.datdota.com/api/teams/{}/ratings?date={}-{}-{}'.format(\n",
    "                            team_id, date_rating_7day_ago.year, date_rating_7day_ago.month, date_rating_7day_ago.day )\n",
    "                    # выгрзить json с предыдущей ссылки и создать ДФ\n",
    "                    dat_7day_ago = self.__get_json_from_url(url_7day_ago)\n",
    "                    data_7day_ago = pd.DataFrame(dat_7day_ago.get('data'))\n",
    "            except:\n",
    "                data_7day_ago = pd.DataFrame([[0,0]], columns=['GLICKO_1', 'GLICKO_2'], index=['rating'])\n",
    "            try:\n",
    "                team_ratin_df_allData = pd.DataFrame()\n",
    "                team_ratin_df_allData.loc[0, radiant_or_dire + '_mu_glicko'] = data.loc['mu', 'GLICKO_1']\n",
    "                team_ratin_df_allData.loc[0, radiant_or_dire + '_rating_glicko'] = data.loc['rating', 'GLICKO_1']\n",
    "                team_ratin_df_allData.loc[0, radiant_or_dire + '_ratingSevenDaysAgo_glicko'] = data_7day_ago.loc['rating', 'GLICKO_1']\n",
    "                team_ratin_df_allData.loc[0, radiant_or_dire + '_sigma_glicko'] = data.loc['sigma', 'GLICKO_1']\n",
    "\n",
    "                team_ratin_df_allData.loc[0, radiant_or_dire + '_mu_glicko2'] = data.loc['mu', 'GLICKO_2']\n",
    "                team_ratin_df_allData.loc[0, radiant_or_dire + '_phi_glicko2'] = data.loc['phi', 'GLICKO_2']\n",
    "                team_ratin_df_allData.loc[0, radiant_or_dire + '_rating_glicko2'] = data.loc['rating', 'GLICKO_2']\n",
    "                team_ratin_df_allData.loc[0, radiant_or_dire + '_ratingSevenDaysAgo_glicko2'] = data_7day_ago.loc['rating', 'GLICKO_2']    \n",
    "            except:\n",
    "                team_ratin_df_allData = pd.DataFrame([[0,0,0,0,0,0,0,0]], \n",
    "                        columns=[radiant_or_dire + x for x in ['_mu_glicko', '_rating_glicko', \n",
    "                                                '_ratingSevenDaysAgo_glicko', '_sigma_glicko', \n",
    "                                    '_mu_glicko2', '_phi_glicko2', '_rating_glicko2', '_ratingSevenDaysAgo_glicko2', ]])\n",
    "            return(team_ratin_df_allData)\n",
    "\n",
    "        df_glicko_rating_teams_on_links = pd.DataFrame()\n",
    "        for index in  main.index:\n",
    "            if index%100 == 0:\n",
    "                print (index) \n",
    "            # вытащить одну строчку (для того чтобы потом добавить в основную таблицу. Пока оставить так, но в принципе можно \n",
    "            # уброть переменную one_match)\n",
    "            one_match = main.loc[[index]]\n",
    "            # достать дату матча\n",
    "            date_match =  date.fromtimestamp(one_match['start_time'][index]) - timedelta(1)\n",
    "\n",
    "            # id команд в матче, иногда бывает что нет id \n",
    "            try:\n",
    "                radiant_id = int(one_match['radiant_team_id'][index])\n",
    "            except:\n",
    "                radiant_id = 0\n",
    "            try:\n",
    "                dire_id = int(one_match['dire_team_id'][index])\n",
    "            except:\n",
    "                dire_id = 0\n",
    "\n",
    "            rating_radiant = get_current_rating_teams(date_match, radiant_id, 'radiant')\n",
    "            rating_dire = get_current_rating_teams(date_match, dire_id, 'dire')\n",
    "            #соединить в одну строчку данные матча и данные с рейтинга каждой команды если присутсвуют данные по команде\n",
    "            rating_teams = pd.merge(rating_radiant, rating_dire, left_index=True, right_index=True)\n",
    "            rating_teams['match_id'] = one_match['match_id'].values[0]\n",
    "            # Если повторяющиеся команды  то длина будет два. НЕ ДОБАВЛЯТЬ ПОВТОРЯЮЩИЕСЯ КОМАНДЫ\n",
    "            if len(rating_teams) == 1:\n",
    "                df_glicko_rating_teams_on_links = pd.concat([df_glicko_rating_teams_on_links, rating_teams])\n",
    "            df_glicko_rating_teams_on_links = df_glicko_rating_teams_on_links.reset_index().drop('index', axis=1)\n",
    "            df_glicko_rating_teams_on_links.to_csv('../tabel/table from Datdota/Rating teams/' + \n",
    "                        'Rating Glicko on {} to {} (PreDay).csv'.format(self.day_first_for_saving_in_file, \n",
    "                                                                        self.day_end_for_saving_in_file))\n",
    "    # ------- KDA для героев в матче ----------------------------------------------------------\n",
    "    def createAndSaveKdaHeroes(self, main, days_ago=0, pro_or_all_teams='All', threshold='20'):\n",
    "        print('KDA и все другие данные для героев в матче')\n",
    "        columns = ['hero', 'kills', 'deaths', 'assists', 'kda', 'avgKal', 'gpm', 'xpm', 'lastHits', 'denies', 'level',\n",
    "                   'heroDamage', 'towerDamage', 'heroHealing', 'goldSpent']\n",
    "        # создать основной массив, где будут записаны все матчи (id матча и rda героя)\n",
    "        df_basick_peromances_heroes = pd.DataFrame()\n",
    "\n",
    "        # создать список названий колонок всех героев\n",
    "        all_her = main.loc[:,'radiant_H1':'dire_H5'].columns\n",
    "        \n",
    "        tier = self.__checkTierTeams(pro_or_all_teams)\n",
    "        \n",
    "        for index in main.index:\n",
    "            if index%100 == 0:\n",
    "                print (index)\n",
    "            # ДФ для соединения всех герове матча в один ДФ \n",
    "            df_heroe_match = pd.DataFrame()\n",
    "            # дата матча\n",
    "            date_match = date.fromtimestamp(main['start_time'][index])\n",
    "            # предыдущий день\n",
    "            date_match =  date_match - timedelta(1)\n",
    "            if days_ago == 0:\n",
    "                url_heroes =('http://www.datdota.com/api/heroes/performances?' + self.PATCH +\n",
    "                    '&winner=either&after=01%2F01%2F2011' + \n",
    "                    '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year) + \n",
    "                    '&duration=0%3B200&duration-value-from=0&duration-value-to=200&{}'.format(tier) + \n",
    "                    '&valve-event=does-not-matter&threshold={}'.format(threshold))\n",
    "            else:\n",
    "                several_day_ago = date_match - timedelta(days_ago)\n",
    "                url_heroes =('http://www.datdota.com/api/heroes/performances?' + self.PATCH +\n",
    "                    '&winner=either&after={}%2F{}%2F{}'.format(several_day_ago.day, several_day_ago.month, several_day_ago.year) + \n",
    "                    '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year) + \n",
    "                    '&duration=0%3B200&duration-value-from=0&duration-value-to=200&{}'.format(tier) + \n",
    "                    '&valve-event=does-not-matter&threshold={}'.format(threshold))\n",
    "            # выгрзить json с предыдущей ссылки\n",
    "            dat = self.__get_json_from_url(url_heroes).get('data')\n",
    "            df_data_tabel_for_heroes = pd.DataFrame(dat)#, columns=columns)\n",
    "            for her in all_her:\n",
    "                # вытащить id героя\n",
    "                id_heroe = main[her][index]\n",
    "\n",
    "                # создать массив с данными \n",
    "                array = df_data_tabel_for_heroes[df_data_tabel_for_heroes['hero'] == id_heroe].values\n",
    "                # создать название колонок для определнного героя\n",
    "                col = [her + '_' + c for c  in df_data_tabel_for_heroes.columns]\n",
    "                # ДФ для героя по матчу\n",
    "                df_heroe = pd.DataFrame(array, columns=col)\n",
    "                df_heroe_match = pd.merge(df_heroe_match, df_heroe, \n",
    "                                                       left_index=True, right_index=True, how='outer')\n",
    "                df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "            df_basick_peromances_heroes = pd.concat([df_basick_peromances_heroes, df_heroe_match])\n",
    "        df_basick_peromances_heroes = df_basick_peromances_heroes.reset_index().drop('index', axis=1)\n",
    "        df_basick_peromances_heroes = df_basick_peromances_heroes.fillna(0)\n",
    "        if days_ago == 0:\n",
    "            df_basick_peromances_heroes.to_csv('../tabel/table from Datdota/KDA/Heroes/'+\n",
    "                        'KDA heroes on {} to {} (6.88+, {}, more {}).csv'.format(self.day_first_for_saving_in_file, \n",
    "                                                                            self.day_end_for_saving_in_file,\n",
    "                                                                                pro_or_all_teams, threshold))\n",
    "        else:\n",
    "            df_basick_peromances_heroes.to_csv('../tabel/table from Datdota/KDA/Heroes/{}day_ago/'.format(days_ago)+\n",
    "                        'KDA heroes on {} to {} ({}day_ago, {}, more {}).csv'.format(self.day_first_for_saving_in_file, \n",
    "                                                                                self.day_end_for_saving_in_file, \n",
    "                                                                                str(days_ago), \n",
    "                                                                                pro_or_all_teams, threshold))\n",
    "            \n",
    "    # ------- Head-to-Head ----------------------------------------------------------\n",
    "    def createAndSaveHeadToHead(self, main, pro_or_all_teams='All', threshold='20'):\n",
    "        \"\"\"Contrpick Heroes\"\"\"\n",
    "        print('Head-to-Head')\n",
    "        def elo_heroes_vs_enemies(main, index, columns_heroes, columns_enemies, df_elo_herVsEne, df_head_to_head_elo_heroes):\n",
    "            \"\"\"Добавить в df_head_to_head_elo_heroes суммарный показатель elo для героя vs всх врагов\"\"\"\n",
    "            # две переменные для записи суммарного elo каждой команды\n",
    "            for her in columns_heroes:\n",
    "                hero_elo = 0\n",
    "                # вытащить id героя\n",
    "                id_heroe = main[her][index]\n",
    "                # суммировать elo героя против героев противника\n",
    "                for her_enemy in columns_enemies:\n",
    "                    id_heroe_enemy = main[her_enemy][index]\n",
    "                    try:\n",
    "                        elo =  df_elo_herVsEne['shift'][df_elo_herVsEne['hero'] == \n",
    "                                                      id_heroe][df_elo_herVsEne['againstHero'] == id_heroe_enemy].item()\n",
    "                    except:\n",
    "                        elo=0\n",
    "                    hero_elo += elo\n",
    "                # записать в основной ДФ elo по каждому герою\n",
    "                df_head_to_head_elo_heroes.loc[index, her + '_elo_vs_enemies'] =  hero_elo \n",
    "\n",
    "        # создать основной массив, где будут записаны суммарное elo каждого егроя относительно всех героев противника\n",
    "        df_head_to_head_elo_heroes = pd.DataFrame()#main['match_id']\n",
    "        # создать список названий колонок  героев radiant\n",
    "        all_her_rad = main.loc[:,'radiant_H1':'radiant_H5'].columns\n",
    "        # создать список названий колонок  героев radiant\n",
    "        all_her_dir = main.loc[:,'dire_H1':'dire_H5'].columns\n",
    "        \n",
    "        tier = self.__checkTierTeams(pro_or_all_teams)\n",
    "        \n",
    "        for index in main.index:\n",
    "            if index % 100 == 0:\n",
    "                print (index)\n",
    "            # достать дату матча и отнять один день\n",
    "            date_match = date.fromtimestamp(main['start_time'][index])\n",
    "            date_match = date_match - timedelta(1)    \n",
    "            # создать cылку для предыдущего дня по контрпикам  за все время существования DatDota\n",
    "            url_heroes_team = ('http://www.datdota.com/api/heroes/head-to-head-elo?{}'.format(tier) +\n",
    "                               '&valve-event=does-not-matter&threshold={}'.format(threshold) + self.PATCH +\n",
    "                               '&patch=6.87&patch=6.86&patch=6.85&patch=6.84&patch=6.83&patch=6.82&patch=6.81' +\n",
    "                               '&patch=6.80&patch=6.79&patch=6.78&patch=6.77&patch=6.76&patch=6.75&patch=6.74'+\n",
    "                               '&winner=either&after=01%2F01%2F2011' +\n",
    "                        '&before={}%2F{}%2F{}&duration=0%3B200&'.format(date_match.day, date_match.month, date_match.year) +\n",
    "                        'duration-value-from=0&duration-value-to=200') \n",
    "            # выгрзить json с предыдущей ссылки и создать ДФ\n",
    "            dat = self.__get_json_from_url(url_heroes_team)\n",
    "            df_elo_herVsEne = pd.DataFrame(dat.get('data'))\n",
    "\n",
    "            # добавить в мейн таблицу данные сначала по ело героям рединт против дире, а затем наоборот\n",
    "            elo_heroes_vs_enemies(main, index, all_her_rad, all_her_dir, df_elo_herVsEne, df_head_to_head_elo_heroes)\n",
    "            elo_heroes_vs_enemies(main, index, all_her_dir, all_her_rad, df_elo_herVsEne, df_head_to_head_elo_heroes)\n",
    "        df_head_to_head_elo_heroes['match_id'] = main['match_id']  \n",
    "        \n",
    "        self.df_head_to_head_elo_heroes = df_head_to_head_elo_heroes\n",
    "        df_head_to_head_elo_heroes.to_csv('../tabel/table from Datdota/Heah-to-head Contrpicks/'+\n",
    "                               'data from 6.74-last. on {} to {} (All time, {}, more {}).csv'.format(\n",
    "                                   self.day_first_for_saving_in_file, self.day_end_for_saving_in_file,\n",
    "                                   pro_or_all_teams, threshold))\n",
    "        \n",
    "    def __checkTierTeams(self, pro_or_all_teams):\n",
    "        if pro_or_all_teams == 'All':\n",
    "            tier = 'tier=1&tier=2&tier=3'            \n",
    "        elif pro_or_all_teams == 'Pro':\n",
    "            tier = 'tier=1'\n",
    "        return tier\n",
    "    # ------- Метовые герои AvgELo для одного и для пары героев ---------------------------------------------\n",
    "    def createAndSaveAvgeloForOneHero(self, main, days_ago=60, pro_or_all_teams='All', threshold='20'):\n",
    "        \"\"\"Meta за последние время, какие показатели у одного героя. По умолчанию за 2 месяца (60 дней)\"\"\"\n",
    "        print('AvgElo (Meta) for one heroes')\n",
    "        # создать основной ДФ, где будут записаны все матчи (id матча и rda героя)\n",
    "        df_AvgElo_heroes = pd.DataFrame()\n",
    "        df_AvgElo_for_two_heroes_in_two_teams = pd.DataFrame()\n",
    "\n",
    "        # создать список названий колонок всех героев\n",
    "        all_her = main.loc[:,'radiant_H1':'dire_H5'].columns\n",
    "       \n",
    "        tier = self.__checkTierTeams(pro_or_all_teams)\n",
    "        \n",
    "        for index in main.index:\n",
    "            if index % 100 == 0:\n",
    "                print (index)\n",
    "            # ДФ для соединения всех герове матча в один ДФ \n",
    "            df_heroe_match = pd.DataFrame()\n",
    "            date_match = date.fromtimestamp(main['start_time'][index])\n",
    "            date_match =  date_match - timedelta(1)\n",
    "            # создать дату столько то дней назад назад от даты матча\n",
    "            several_day_ago = date_match - timedelta(days_ago)\n",
    "            # создать ссылку с данными по Avg.Elo для двух предыдущих месяцев игры\n",
    "            url = ('http://www.datdota.com/api/heroes/elo?{}'.format(tier) +\n",
    "                '&valve-event=does-not-matter&threshold={}'.format(threshold) + self.PATCH + \n",
    "                '&patch=6.87&patch=6.86&patch=6.85&patch=6.84&patch=6.83&patch=6.82&patch=6.81&patch=6.80' + \n",
    "                '&patch=6.79&patch=6.78&patch=6.77&patch=6.76&patch=6.75&patch=6.74'+\n",
    "                '&winner=either'+\n",
    "                '&after={}%2F{}%2F{}'.format(several_day_ago.day, several_day_ago.month, several_day_ago.year) + \n",
    "                '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year) + \n",
    "                '&duration=0%3B200&duration-value-from=0&duration-value-to=200')\n",
    "            # выгрузить все с сайта и создать ДФ\n",
    "            dat = self.__get_json_from_url(url)\n",
    "            df_url = pd.DataFrame(dat.get('data'))\n",
    "            # создать ДФ для одного и пары героев за 2 предыдущих месяца\n",
    "            df_data_tabel_for_heroes, df_data_tabel_for_two_heroes = self.__get_df_avgElo_heroes(date_match, df_url)\n",
    "\n",
    "            for her in all_her:\n",
    "                # вытащить id героя\n",
    "                id_hero = main[her][index]\n",
    "\n",
    "                # вытащить avg elo для данного героя\n",
    "                avgElo_hero = df_data_tabel_for_heroes.loc[(index for index, x in enumerate(\n",
    "                                                    df_data_tabel_for_heroes['heroes']) if x == [id_hero]),'eloShift']\n",
    "\n",
    "                # проверить есть ли герой\n",
    "                try:\n",
    "                    avgElo_hero = float(avgElo_hero)\n",
    "                except:\n",
    "                    avgElo_hero = 0\n",
    "                # ДФ для avgELo героя по матчу\n",
    "                df_heroe = pd.DataFrame([avgElo_hero], columns=[her + '_AvgElo'])\n",
    "                df_heroe_match = pd.merge(df_heroe_match, df_heroe, left_index=True, right_index=True, how='outer')\n",
    "                df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "            df_AvgElo_heroes = pd.concat([df_AvgElo_heroes, df_heroe_match])\n",
    "\n",
    "        # df_AvgElo_heroes['mathc_id'] = main['match_id']\n",
    "        df_AvgElo_heroes = df_AvgElo_heroes.reset_index().drop('index', axis=1)\n",
    "        df_AvgElo_heroes.to_csv('../tabel/table from Datdota/AvgElo Meta and Signatures Heroes/'+\n",
    "                            'Meta on {} to {} ({}day_ago, {}, more {}).csv'.format(self.day_first_for_saving_in_file, \n",
    "                                                                                    self.day_end_for_saving_in_file, \n",
    "                                                                                    str(days_ago), \n",
    "                                                                                    pro_or_all_teams, threshold))\n",
    "    # вытащить ДФы для одного, пары, тройки героев из сайта по дате\n",
    "    def __get_df_avgElo_heroes(self, day_match, df):\n",
    "        # создать ДФ для одного героя, пары и тройки\n",
    "        df_one = df.loc[(index for index, x in enumerate(df['heroes']) if len(x) == 1), :]  \n",
    "        df_one = df_one.reset_index().drop('index', axis=1)\n",
    "        df_double = df.loc[(index for index, x in enumerate(df['heroes']) if len(x) == 2), :]  \n",
    "        df_double = df_double.reset_index().drop('index', axis=1)\n",
    "    #     df_triple = df.loc[(index for index, x in enumerate(df['heroes']) if len(x) == 3), :]  \n",
    "        return df_one, df_double#, df_triple\n",
    "\n",
    "    def createAndSaveAvgeloForTwoHeroes(self, main, days_ago=60, pro_or_all_teams='Pro', threshold='8'):\n",
    "        \"\"\"Meta за последние время, какие показатели у ПАРЫ героев. По умолчанию за 2 месяца (60 дней)\"\"\"\n",
    "        print('AvgElo (Meta) for two heroes')\n",
    "        # вытащить avgElo для двух героев, по их номеру\n",
    "        def AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_two_heroes, what_team, first_H, second_H):\n",
    "            a = what_team + first_H\n",
    "            b = what_team + second_H\n",
    "            # Если нету связки то поставить 0\n",
    "            try:\n",
    "                avgElo = df_data_tabel_for_two_heroes.loc[(ind for ind, x in enumerate(df_data_tabel_for_two_heroes['heroes'])\n",
    "                        if (arr_heroes[a] in x and arr_heroes[b] in x)),'eloShift'].values[0]\n",
    "            except:\n",
    "                avgElo = 0\n",
    "            return (avgElo)\n",
    "\n",
    "        # создать ДФ с avgElo по парам героев\n",
    "        def get_df_AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_two_heroes, dire_or_radiant):\n",
    "            if dire_or_radiant == 'dire':\n",
    "                what_team = 5\n",
    "            else:\n",
    "                what_team = 0\n",
    "             # вытащить avgElo для связки героя с другими по команде\n",
    "            avgElo_hero1_2 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_two_heroes, what_team, 0, 1)\n",
    "            avgElo_hero1_3 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_two_heroes, what_team, 0, 2)\n",
    "            avgElo_hero1_4 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_two_heroes, what_team, 0, 3)\n",
    "            avgElo_hero1_5 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_two_heroes, what_team, 0, 4)\n",
    "            avgElo_hero2_3 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_two_heroes, what_team, 1, 2)\n",
    "            avgElo_hero2_4 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_two_heroes, what_team, 1, 3)\n",
    "            avgElo_hero2_5 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_two_heroes, what_team, 1, 4)\n",
    "            avgElo_hero3_4 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_two_heroes, what_team, 2, 3)\n",
    "            avgElo_hero3_5 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_two_heroes, what_team, 2, 4)\n",
    "            avgElo_hero4_5 = AvgElo_for_two_heroes_in_teams(arr_heroes, df_data_tabel_for_two_heroes, what_team, 3, 4)\n",
    "            arr = []\n",
    "            arr.append(avgElo_hero1_2); arr.append(avgElo_hero1_3); arr.append(avgElo_hero1_4); arr.append(avgElo_hero1_5);\n",
    "            arr.append(avgElo_hero2_3); arr.append(avgElo_hero2_4); arr.append(avgElo_hero2_5);\n",
    "            arr.append(avgElo_hero3_4); arr.append(avgElo_hero3_5);\n",
    "            arr.append(avgElo_hero4_5);\n",
    "            # Создать ДФ с данными для пар героев в команде\n",
    "            df_avgElo_for_two_heroes = pd.DataFrame([arr], columns=[dire_or_radiant + '_' + c for c in [\n",
    "                                                                                            '1_2','1_3','1_4','1_5',\n",
    "                                                                                            '2_3','2_4','2_5',\n",
    "                                                                                            '3_4','3_5',\n",
    "                                                                                            '4_5']])\n",
    "            return df_avgElo_for_two_heroes\n",
    "\n",
    "        # создать основной ДФ, где будут записаны все матчи (id матча и rda героя)\n",
    "        df_AvgElo_heroes = pd.DataFrame()\n",
    "        df_AvgElo_for_two_heroes_in_two_teams = pd.DataFrame()\n",
    "        # создать список названий колонок всех героев\n",
    "        all_her = main.loc[:,'radiant_H1':'dire_H5'].columns\n",
    "        \n",
    "        tier = self.__checkTierTeams(pro_or_all_teams)\n",
    "        \n",
    "        for index in main.index:\n",
    "            if index % 100 == 0:\n",
    "                print (index)\n",
    "            # ДФ для соединения всех герове матча в один ДФ \n",
    "            df_heroe_match = pd.DataFrame()\n",
    "            # дата матча\n",
    "            date_match = date.fromtimestamp(main['start_time'][index])\n",
    "            # предыдущий день\n",
    "            date_match =  date_match - timedelta(1)\n",
    "            # создать дату два месяца назад от даты матча\n",
    "            several_day_ago = date_match - timedelta(days_ago)\n",
    "            # создать ссылку с данными по Avg.Elo для двух предыдущих месяцев игры\n",
    "            url = ('http://www.datdota.com/api/heroes/elo?{}'.format(tier) +\n",
    "                '&valve-event=does-not-matter&threshold={}'.format(threshold) + self.PATCH + \n",
    "                '&patch=6.87&patch=6.86&patch=6.85&patch=6.84&patch=6.83&patch=6.82&patch=6.81&patch=6.80' + \n",
    "                '&patch=6.79&patch=6.78&patch=6.77&patch=6.76&patch=6.75&patch=6.74'+\n",
    "                '&winner=either'+\n",
    "                '&after={}%2F{}%2F{}'.format(several_day_ago.day, several_day_ago.month, several_day_ago.year) + \n",
    "                '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year) + \n",
    "                '&duration=0%3B200&duration-value-from=0&duration-value-to=200')\n",
    "            # выгрузить все с сайта и создать ДФ\n",
    "            dat = self.__get_json_from_url(url)\n",
    "            df_url = pd.DataFrame(dat.get('data'))\n",
    "            # создать ДФ для одного и пары героев за 2 предыдущих месяца\n",
    "            df_data_tabel_for_heroes, df_data_tabel_for_two_heroes = self.__get_df_avgElo_heroes(date_match, df_url)\n",
    "            # Массив героев в матче \n",
    "            arr_heroes_in_match = main.loc[index,'radiant_H1':'dire_H5'].values\n",
    "            # Создать два ДФ для редиант и даер по парным связкам AvgElo\n",
    "            rad = get_df_AvgElo_for_two_heroes_in_teams(arr_heroes_in_match, df_data_tabel_for_two_heroes, 'radiant')\n",
    "            di =  get_df_AvgElo_for_two_heroes_in_teams(arr_heroes_in_match, df_data_tabel_for_two_heroes, 'dire')\n",
    "            df_AvgElo_for_two_heroes_in_match = pd.merge(rad, di, \n",
    "                                                           left_index=True, right_index=True, how='outer')\n",
    "            df_AvgElo_for_two_heroes_in_match['match_id'] = main.loc[index, 'match_id'] \n",
    "            df_AvgElo_for_two_heroes_in_two_teams = pd.concat([\n",
    "                                        df_AvgElo_for_two_heroes_in_two_teams, df_AvgElo_for_two_heroes_in_match ])\n",
    "\n",
    "        df_AvgElo_for_two_heroes_in_two_teams = df_AvgElo_for_two_heroes_in_two_teams.reset_index().drop('index', axis=1)\n",
    "        df_AvgElo_for_two_heroes_in_two_teams.to_csv('../tabel/table from Datdota/'+\n",
    "            'AvgElo Meta and Signatures Heroes/Meta AvgElo Couples/'+\n",
    "            'Meta couples heroes on {} to {} ({}day_ago, {}, more {}).csv'.format(self.day_first_for_saving_in_file, \n",
    "                                                                    self.day_end_for_saving_in_file, \n",
    "                                                                    str(days_ago), \n",
    "                                                                    pro_or_all_teams, threshold))\n",
    "    # ------- Signatures & KDA для игрока ---------------------------------------------\n",
    "    def createAndSaveSignatureAndKdaForPlayers(self, main, pro_or_all_teams='All', threshold='5'):\n",
    "        print('Signatures and KDA for players')\n",
    "        def get_players_heroes(df_heroe_match, radiant_or_dire, index, pro_or_all_teams, threshold):\n",
    "            \"\"\"Вытащить данные по героям для игроков (elo, gpm, xpm, kda). \n",
    "               Передается DF в который добаляются все данные по одному матчу\"\"\"\n",
    "            def get_df_AvgElo_heroes_player(player, index, tier, threshold):\n",
    "                # дата матча\n",
    "                date_match = date.fromtimestamp(main['start_time'][index])\n",
    "                date_match = date_match - timedelta(1)\n",
    "                # создать ДФ для соло героев за все время игр игрока (сигнатурки)\n",
    "                url = ('http://www.datdota.com/api/players/hero-combos?players={}'.format(player) +\n",
    "                self.PATCH +\n",
    "                '&patch=6.87&patch=6.86&patch=6.85&patch=6.84&patch=6.83&patch=6.82&patch=6.81'+\n",
    "                '&patch=6.80&patch=6.79&patch=6.78&patch=6.77&patch=6.76&patch=6.75&patch=6.74&winner=either'+\n",
    "                '&after=01%2F01%2F2011&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year)+\n",
    "                '&duration=0%3B200&duration-value-from=0&duration-value-to=200&{}'.format(tier) +\n",
    "                '&valve-event=does-not-matter&threshold={}'.format(threshold))\n",
    "                # выгрузить все с сайта и создать ДФ\n",
    "                try:\n",
    "                    dat = self.__get_json_from_url(url)\n",
    "                except:\n",
    "                    dat = {'data':[]}\n",
    "                df_url = pd.DataFrame(dat.get('data'))\n",
    "                return df_url\n",
    "            \n",
    "            tier = self.__checkTierTeams(pro_or_all_teams)\n",
    "            \n",
    "            for i in range(1, 6):\n",
    "                # вытащить id героя\n",
    "                id_hero = main[radiant_or_dire + '_H' + str(i)][index]\n",
    "                # вытащить id игрока\n",
    "                id_player = main[radiant_or_dire + '_P' + str(i)][index]\n",
    "                # создать ДФ c avgElo для игрока по ДАТЕ ИГРЫ\n",
    "                df_player = get_df_AvgElo_heroes_player(int(id_player), index, pro_or_all_teams, threshold)\n",
    "                try:\n",
    "                    total = df_player['total'][df_player['hero'] == id_hero].values[0]\n",
    "                    winrate = df_player['winrate'][df_player['hero'] == id_hero].values[0]\n",
    "                    kills = df_player['kills'][df_player['hero'] == id_hero].values[0]\n",
    "                    deaths = df_player['deaths'][df_player['hero'] == id_hero].values[0]\n",
    "                    assists = df_player['assists'][df_player['hero'] == id_hero].values[0]\n",
    "                    elo = df_player['eloShift'][df_player['hero'] == id_hero].values[0]\n",
    "                    gpm = df_player['gpm'][df_player['hero'] == id_hero].values[0]\n",
    "                    xpm = df_player['xpm'][df_player['hero'] == id_hero].values[0]\n",
    "                    kda = df_player['kda'][df_player['hero'] == id_hero].values[0] \n",
    "                    lastHits = df_player['lastHits'][df_player['hero'] == id_hero].values[0] \n",
    "                    denies = df_player['denies'][df_player['hero'] == id_hero].values[0] \n",
    "                except:\n",
    "                    total=0; winrate=0; kills=0; deaths=0; assists=0; elo=0; gpm=0;  xpm=0; kda=0; lastHits=0; denies=0;\n",
    "                # ДФ для героя игрока по матчу\n",
    "                df_heroe = pd.DataFrame([[total, winrate, kills, deaths, assists, elo, gpm, xpm, kda, lastHits, denies]], \n",
    "                                    columns=[radiant_or_dire + '_P' + str(i) + '_totalGames',\n",
    "                                            radiant_or_dire + '_P' + str(i) + '_winrate',\n",
    "                                            radiant_or_dire + '_P' + str(i) + '_kills',\n",
    "                                            radiant_or_dire + '_P' + str(i) + '_deaths',\n",
    "                                            radiant_or_dire + '_P' + str(i) + '_assists',\n",
    "                                            radiant_or_dire + '_P' + str(i) + '_eloShift',\n",
    "                                            radiant_or_dire + '_P' + str(i) + '_gpm',\n",
    "                                            radiant_or_dire + '_P' + str(i) + '_xpm',\n",
    "                                            radiant_or_dire + '_P' + str(i) + '_kda',\n",
    "                                            radiant_or_dire + '_P' + str(i) + '_lastHits',\n",
    "                                            radiant_or_dire + '_P' + str(i) + '_denies'])\n",
    "                df_heroe_match = pd.merge(df_heroe_match, df_heroe, left_index=True, right_index=True, how='outer')\n",
    "            return df_heroe_match\n",
    "\n",
    "        # создать основной ДФ, где будут записаны все матчи (id матча и rda героя)\n",
    "        df_heroes_players_elo_gpm_xpm_kda = pd.DataFrame()\n",
    "        # создать список названий колонок  героев radiant\n",
    "        all_her_rad = main.loc[:,'radiant_H1':'radiant_H5'].columns\n",
    "        # создать список названий колонок  героев radiant\n",
    "        all_her_dir = main.loc[:,'dire_H1':'dire_H5'].columns\n",
    "        # создать список названий колонок  игроков radiant\n",
    "        all_play_rad = main.loc[:,'radiant_P1':'radiant_P5'].columns\n",
    "        # создать список названий колонок  игроков radiant\n",
    "        all_play_dir = main.loc[:,'dire_P1':'dire_P5'].columns\n",
    "        for index in main.index:\n",
    "            if index % 100 == 0:\n",
    "                print (index)\n",
    "            # ДФ для соединения всех герове radiant & dire матча в один ДФ \n",
    "            df_heroe_match = pd.DataFrame()\n",
    "            df_heroe_match = get_players_heroes(df_heroe_match, 'radiant', index, pro_or_all_teams, threshold)\n",
    "            df_heroe_match = get_players_heroes(df_heroe_match, 'dire', index, pro_or_all_teams, threshold)\n",
    "            df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "            df_heroes_players_elo_gpm_xpm_kda = pd.concat([df_heroes_players_elo_gpm_xpm_kda, df_heroe_match])   \n",
    "        df_heroes_players_elo_gpm_xpm_kda = df_heroes_players_elo_gpm_xpm_kda.reset_index().drop('index', axis=1)\n",
    "        df_heroes_players_elo_gpm_xpm_kda.to_csv('../tabel/table from Datdota/KDA/Players/'+\n",
    "                    'KDA Players on hero {} to {} (All time, {}, more {}).csv'.format(self.day_first_for_saving_in_file, \n",
    "                                                                                        self.day_end_for_saving_in_file,\n",
    "                                                                                        pro_or_all_teams, threshold))   \n",
    "    # ------- Predict on rating Teams ---------------------------------------------\n",
    "    def createAndSavePredictionForRatingTeams(self, main):\n",
    "        print(\"DF for Prediction on Rating Teams\")\n",
    "        # Общая функция для удобного обучения и предсказания на контрольных данных\n",
    "        def get_main_df_for_predict(df_rating_teams_Premium):\n",
    "            # Создание основного ДФ \n",
    "            # Соединение всех данных в один ДФ\n",
    "            main = df_rating_teams_Premium\n",
    "\n",
    "            # удаление не нужных колонок для обучения\n",
    "            main = main.drop(['match_id', 'start_time', 'radiant_team_id', 'radiant_score', 'dire_team_id',\n",
    "                       'dire_score', 'radiant_name', 'dire_name','league_name'], axis=1)\n",
    "            main = main.drop(main.loc[:, 'radiant_H1' : 'dire_P5'], axis=1)\n",
    "\n",
    "            # # Оставляю только важные фичи, убираю из рейтинга команд ело32 и ело64\n",
    "            main = main.drop(main.loc[:, 'radiant_current_elo32':'radiant_thirtyDayAvg_elo64'], axis=1)\n",
    "            main = main.drop(main.loc[:, 'dire_current_elo32':'dire_thirtyDayAvg_elo64'], axis=1)\n",
    "            print (len(main))\n",
    "            #  Заполнить или удалить NaN и добаить коллонку с предсказаниями, обучеными ранее        \n",
    "            # убрать пустые ячейки\n",
    "            print(main)\n",
    "            main = main.dropna()\n",
    "            print(len(main), \"After dropna\")\n",
    "            # Для рейтинга команд \n",
    "            print(main)\n",
    "            main['mu_glicko'] = main['radiant_mu_glicko'] -  main['dire_mu_glicko']\n",
    "            main['rating_glicko'] = main['radiant_rating_glicko'] -  main['dire_rating_glicko']\n",
    "            main['ratingSevenDaysAgo_glicko'] = main['radiant_ratingSevenDaysAgo_glicko'] -  main['dire_ratingSevenDaysAgo_glicko']\n",
    "            main['mu_glicko2'] = main['radiant_mu_glicko2'] -  main['dire_mu_glicko2']\n",
    "            main['phi_glicko2'] = main['radiant_phi_glicko2'] -  main['dire_phi_glicko2'] \n",
    "            # Почему-то иногда менятеся порядок колоно из исходных данных и поэтому нужно создать правильный порядок\n",
    "            main = main[['radiant_win', 'radiant_mu_glicko', 'radiant_rating_glicko', 'radiant_ratingSevenDaysAgo_glicko', \n",
    "                         'radiant_mu_glicko2', 'dire_mu_glicko', 'dire_rating_glicko', 'dire_ratingSevenDaysAgo_glicko', \n",
    "                         'dire_sigma_glicko', 'dire_mu_glicko2', 'dire_ratingSevenDaysAgo_glicko2', 'mu_glicko', \n",
    "                         'rating_glicko', 'ratingSevenDaysAgo_glicko', 'mu_glicko2', 'phi_glicko2']]\n",
    "            return main\n",
    "\n",
    "        XGB = pickle.load(open('../Work/Xgboost_model_predict_rating_teams_without_elo.sav', 'rb'))\n",
    "\n",
    "        # дф с матчами и рейтингом каждой команды с \n",
    "        df_rating_teams_Premium_contr = pd.read_csv('../tabel/table from Datdota/Rating teams/'+\n",
    "                                              'PREMIUM on {} to {} (PreDay).csv'.format(\n",
    "                                                                      self.day_first_for_saving_in_file, \n",
    "                                                                      self.day_end_for_saving_in_file,), index_col=0)\n",
    "\n",
    "        contr = get_main_df_for_predict(df_rating_teams_Premium_contr)\n",
    "        # Создание контрольной выборки\n",
    "        # Cделать обучающие данные и ответы\n",
    "        X_contr = contr.drop(['radiant_win'], axis=1)\n",
    "        y_contr = contr['radiant_win']\n",
    "\n",
    "        # СДЕЛАТЬ 1 или 0 вместо true false\n",
    "        y_contr = y_contr.astype(int)\n",
    "        print(classification_report(y_contr, XGB.predict(X_contr), target_names=['dire_win', 'radiant_win']))\n",
    "        gb_auc = metrics.roc_auc_score(y_contr, XGB.predict_proba(X_contr)[:,1])\n",
    "        print('AUC для градиентного бустинга - {:.3f}'.format(gb_auc))\n",
    "        # Создать и сохранить фичу с предсказаниями по алгоритму, обученому на рейтинге команд\n",
    "        df_pedict_for_rating_teams = pd.DataFrame(XGB.predict_proba(X_contr)[:,1:], columns=['Predict'])\n",
    "        df_pedict_for_rating_teams['match_id'] = df_rating_teams_Premium_contr['match_id'].reset_index().drop(\n",
    "                                                                                                        'index', axis=1)\n",
    "        df_pedict_for_rating_teams.to_csv('../tabel/table from Datdota/Rating teams/'+\n",
    "                                   'Predict for rating teams on {} to {}.csv'.format(self.day_first_for_saving_in_file, \n",
    "                                                                            self.day_end_for_saving_in_file,))\n",
    "    # ------- Тип Атаки и тиа героев в матче ---------------------------------------------\n",
    "    def createAndSaveTypeAtackOfHeroesAndTypeHeroes(self, main):\n",
    "        \"\"\"Пока не используется в предсказательных моделях, но необходимо собирать данные тоже, \n",
    "            так как может пригодиться в будущем.\"\"\"\n",
    "        print(\"Тип Атаки и тип героев\")\n",
    "        # Прочитать файл с героями\n",
    "        heroes = pd.read_csv('../All_heroes.csv').drop(['id.1'], axis=1)\n",
    "        # Создвание списка имен героев и списка имен команд и объединение его\n",
    "        name_heroes = heroes['localized_name'].values\n",
    "        columns = ['attac_type1','Disabler1','Nuker1','Carry1','Initiator1','Escape1','Durable1','Support1','Pusher1','Jungler1',\n",
    "                   'attac_type2','Disabler2','Nuker2','Carry2','Initiator2','Escape2','Durable2','Support2','Pusher2','Jungler2',\n",
    "                   'attac_type3','Disabler3','Nuker3','Carry3','Initiator3','Escape3','Durable3','Support3','Pusher3','Jungler3',\n",
    "                   'attac_type4','Disabler4','Nuker4','Carry4','Initiator4','Escape4','Durable4','Support4','Pusher4','Jungler4',\n",
    "                   'attac_type5','Disabler5','Nuker5','Carry5','Initiator5','Escape5','Durable5','Support5','Pusher5','Jungler5',\n",
    "                   'attac_type6','Disabler6','Nuker6','Carry6','Initiator6','Escape6','Durable6','Support6','Pusher6','Jungler6',\n",
    "                   'attac_type7','Disabler7','Nuker7','Carry7','Initiator7','Escape7','Durable7','Support7','Pusher7','Jungler7',\n",
    "                   'attac_type8','Disabler8','Nuker8','Carry8','Initiator8','Escape8','Durable8','Support8','Pusher8','Jungler8',\n",
    "                   'attac_type9','Disabler9','Nuker9','Carry9','Initiator9','Escape9','Durable9','Support9','Pusher9','Jungler9',\n",
    "             'attac_type10','Disabler10','Nuker10','Carry10','Initiator10','Escape10','Durable10','Support10','Pusher10','Jungler10']\n",
    "\n",
    "        list_scripts = ['Disabler', 'Nuker', 'Carry', 'Initiator', 'Escape', 'Durable',\n",
    "                        'Support', 'Pusher', 'Jungler']\n",
    "\n",
    "        # функция для перевода в бинарное состояние типа атаки\n",
    "        def atac(type_at):\n",
    "            if type_at == 'Melee':\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "        # df в который записыватеся пик команда с росписью кажого героя    \n",
    "        df_script_her = pd.DataFrame(columns=columns)\n",
    "\n",
    "        for index in main.index:\n",
    "            if index % 100 == 0:\n",
    "                print (index)\n",
    "            # для radiant\n",
    "            for i in range(1,6):\n",
    "                id_her = main['radiant_H' + str(i)].loc[index]\n",
    "                df_script_her.loc[index, ('attac_type' + str(i))] = atac(heroes['attack_type'][heroes['id'] == id_her].item())\n",
    "                for col in list_scripts:\n",
    "                    sc = heroes[col][(heroes['id'] == id_her)].item()\n",
    "                    df_script_her.loc[index, (col + str(i))] = sc\n",
    "            # для dire\n",
    "            for i in range(1,6):\n",
    "                id_her = main['dire_H' + str(i)].loc[index]\n",
    "                df_script_her.loc[index, ('attac_type' + str(i+5))] = atac(heroes['attack_type'][heroes['id'] == id_her].item())\n",
    "                for col in list_scripts:\n",
    "                    sc = heroes[col][(heroes['id'] == id_her)].item()\n",
    "                    df_script_her.loc[index, (col + str(i+5))] = sc      \n",
    "        df_script_her['match_id'] = main['match_id']\n",
    "        df_script_her.to_csv('../tabel/table from Datdota/Features carry, support, necker/'+\n",
    "                         'PREMIUM on {} to {}.csv'.format(self.day_first_for_saving_in_file, \n",
    "                                                                    self.day_end_for_saving_in_file))\n",
    "   # ------- KDA и Elo у игрока за послдние несколько дней (Его форма и подготовка) ------------------------------\n",
    "    def createAndSaveKdaAndEloshiftPlayersForLastDays(self, main, days_ago=7, pro_or_all_teams='All', threshold='1'):\n",
    "        \"\"\"Как игрок играет в псоледнее время (Его нынешняя форма)\"\"\"\n",
    "        # вытащить таблицу с elo героев  по каждому игроку\n",
    "        def getDfPlayerDaysAgo(player, index, days_ago, threshold):\n",
    "            date_match = date.fromtimestamp(main['start_time'][index])\n",
    "            date_match = date_match - timedelta(1)\n",
    "            several_days_ago = date_match - timedelta(days_ago)\n",
    "            url = ('http://www.datdota.com/api/players/hero-combos?players={}'.format(player) +\n",
    "            self.PATCH +\n",
    "            '&patch=6.87&patch=6.86&patch=6.85&patch=6.84&patch=6.83&patch=6.82&patch=6.81'+\n",
    "            '&patch=6.80&patch=6.79&patch=6.78&patch=6.77&patch=6.76&patch=6.75&patch=6.74&winner=either'+\n",
    "            '&after={}%2F{}%2F{}'.format(several_days_ago.day, several_days_ago.month, several_days_ago.year)+\n",
    "            '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year)+\n",
    "            '&duration=0%3B200&duration-value-from=0&duration-value-to=200&tier=1&tier=2&tier=3'+\n",
    "            '&valve-event=does-not-matter&threshold={}'.format(threshold))\n",
    "            # выгрузить все с сайта и создать ДФ\n",
    "            try:\n",
    "                dat = self.__get_json_from_url(url)\n",
    "            except:\n",
    "                dat = {'data':[]}\n",
    "            df_url = pd.DataFrame(dat.get('data'))\n",
    "            return df_url\n",
    "\n",
    "        def getKdaAndEloshiftPlayersFromTeam(df_heroe_match, radiant_or_dire, index, days_ago, threshold):\n",
    "            def createColumnName(radiant_or_dire, i, different_part, days_ago):\n",
    "                column_name = '{}_P{}_{}_{}days_ago'.format(radiant_or_dire, str(i), different_part, days_ago)\n",
    "                return column_name\n",
    "\n",
    "            for i in range(1, 6):\n",
    "                # вытащить id игрока\n",
    "                id_player = main[radiant_or_dire + '_P' + str(i)][index]\n",
    "                # создать ДФ c avgElo для игрока по ДАТЕ ИГРЫ\n",
    "                df_player = getDfPlayerDaysAgo(int(id_player), index, days_ago, threshold)\n",
    "                df_player = df_player.dropna()\n",
    "                try:\n",
    "                    # diffferent_H - на скольких разных героях отыграл этот игрок за 7 дней\n",
    "                    different_H = len(df_player)\n",
    "                    winrate = df_player['winrate'].mean()\n",
    "                    kills = df_player['kills'].mean()\n",
    "                    deaths = df_player['deaths'].mean()\n",
    "                    assists = df_player['assists'].mean()\n",
    "                    elo = df_player['eloShift'].mean()\n",
    "                    gpm = df_player['gpm'].mean()\n",
    "                    xpm = df_player['xpm'].mean()\n",
    "                    kda = df_player['kda'].mean()\n",
    "                    lastHits = df_player['lastHits'].mean()\n",
    "                    denies = df_player['denies'].mean()\n",
    "                except:\n",
    "                    different_H=0; winrate=0; kills=0; deaths=0; assists=0; elo=0; gpm=0;  xpm=0; kda=0; lastHits=0; denies=0;            \n",
    "                # ДФ для героя игрока по матчу\n",
    "                df_heroe = pd.DataFrame([[different_H, winrate, kills, deaths, assists, elo, gpm, \n",
    "                                              xpm, kda, lastHits, denies]], columns=[\n",
    "                                                        createColumnName(radiant_or_dire, i, 'different_H', days_ago),\n",
    "                                                        createColumnName(radiant_or_dire, i, 'winrate', days_ago),\n",
    "                                                        createColumnName(radiant_or_dire, i, 'kills', days_ago),\n",
    "                                                        createColumnName(radiant_or_dire, i, 'deaths', days_ago),\n",
    "                                                        createColumnName(radiant_or_dire, i, 'assists', days_ago),\n",
    "                                                        createColumnName(radiant_or_dire, i, 'eloShift', days_ago),\n",
    "                                                        createColumnName(radiant_or_dire, i, 'gpm', days_ago),\n",
    "                                                        createColumnName(radiant_or_dire, i, 'xpm', days_ago),\n",
    "                                                        createColumnName(radiant_or_dire, i, 'kda', days_ago),\n",
    "                                                        createColumnName(radiant_or_dire, i, 'lastHits', days_ago),\n",
    "                                                        createColumnName(radiant_or_dire, i, 'denies', days_ago)])\n",
    "                df_heroe_match = pd.merge(df_heroe_match, df_heroe, left_index=True, right_index=True, how='outer')\n",
    "            return df_heroe_match\n",
    "\n",
    "        # создать основной ДФ, где будут записаны все матчи (id матча и rda героя)\n",
    "        df_heroes_players_KDA_elo_days_ago = pd.DataFrame()\n",
    "\n",
    "        for index in main.index:\n",
    "            if index % 100 == 0:\n",
    "                print (index)\n",
    "            # ДФ для соединения всех герове radiant & dire матча в один ДФ \n",
    "            df_heroe_match = pd.DataFrame()\n",
    "            df_heroe_match = getKdaAndEloshiftPlayersFromTeam(df_heroe_match, 'radiant', index, days_ago, threshold)\n",
    "            df_heroe_match = getKdaAndEloshiftPlayersFromTeam(df_heroe_match, 'dire', index, days_ago, threshold)\n",
    "            df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "            df_heroes_players_KDA_elo_days_ago = pd.concat([df_heroes_players_KDA_elo_days_ago, df_heroe_match])   \n",
    "\n",
    "        df_heroes_players_KDA_elo_days_ago = df_heroes_players_KDA_elo_days_ago.reset_index().drop('index', axis=1)       \n",
    "        df_heroes_players_KDA_elo_days_ago = df_heroes_players_KDA_elo_days_ago.fillna(0)\n",
    "        df_heroes_players_KDA_elo_days_ago.to_csv('../tabel/table from Datdota/KDA/Players/{}day_ago/'.format(days_ago) +\n",
    "                                  'KDA, EloShift Players on {} to {} ({}day_ago, {}, more {}).csv'.format(\n",
    "                                                                                    self.day_first_for_saving_in_file, \n",
    "                                                                                    self.day_end_for_saving_in_file, \n",
    "                                                                                    str(days_ago), \n",
    "                                                                                    pro_or_all_teams, threshold))\n",
    "    # ------- HD, TD, LVL, HH, GS у Игрока на героях за все время ------------------------------\n",
    "    def createAndSaveHdTdLvlHhGsForPlayersOnHeroes(self, main, threshold=5):\n",
    "        print(\"HD, TD, LVL ... у игроков на героях за все время\")\n",
    "        # Вытащить данные по героям для игроков (elo, gpm, xpm, kda). Передается DF в который добаляются все данные по одному матчу\n",
    "        def get_players_heroes_HD_TD(df_heroe_match, radiant_or_dire, index):\n",
    "            for i in range(1, 6):\n",
    "                # вытащить id героя\n",
    "                id_hero = main[radiant_or_dire + '_H' + str(i)][index]\n",
    "                # вытащить id игрока\n",
    "                id_player = main[radiant_or_dire + '_P' + str(i)][index]\n",
    "\n",
    "                date_match = date.fromtimestamp(main['start_time'][index])\n",
    "                date_match = date_match - timedelta(1)\n",
    "\n",
    "                url = ('http://www.datdota.com/api/heroes/performances?players={}'.format(int(id_player)) +\n",
    "                self.PATCH +\n",
    "                '&patch=7.11&patch=7.10&patch=7.09&patch=7.08&patch=7.07&patch=7.06&patch=7.05&patch=7.04&patch=7.03&patch=7.02'+\n",
    "                '&patch=7.01&patch=7.00&patch=6.88&patch=6.87&patch=6.86&patch=6.85&patch=6.84&patch=6.83&patch=6.82&patch=6.81'+\n",
    "                '&patch=6.80&patch=6.79&patch=6.78&patch=6.77&patch=6.76&patch=6.75&patch=6.74&winner=either'+\n",
    "                '&after=01%2F01%2F2011&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year)+\n",
    "                '&duration=0%3B200&duration-value-from=0&duration-value-to=200&tier=1&tier=2&tier=3'+\n",
    "                '&valve-event=does-not-matter&threshold={}'.format(threshold))\n",
    "\n",
    "                # выгрузить все с сайта и создать ДФ\n",
    "                try:\n",
    "                    dat = self.__get_json_from_url(url)\n",
    "                except:\n",
    "                    dat = {'data':[]}\n",
    "                df_player = pd.DataFrame(dat.get('data'))\n",
    "\n",
    "                try: \n",
    "                    HD = df_player['heroDamage'][df_player['hero'] == id_hero].values[0]\n",
    "                    TD = df_player['towerDamage'][df_player['hero'] == id_hero].values[0]\n",
    "                    LVL = df_player['level'][df_player['hero'] == id_hero].values[0]\n",
    "                    HH = df_player['heroHealing'][df_player['hero'] == id_hero].values[0]\n",
    "                    GS = df_player['goldSpent'][df_player['hero'] == id_hero].values[0]\n",
    "                except:\n",
    "                    HD=0; TD=0; LVL=0; HH=0; GS=0;         \n",
    "\n",
    "                # ДФ для героя игрока по матчу\n",
    "                df_heroe = pd.DataFrame([[HD, TD, LVL, HH, GS]], columns=[\n",
    "                                                                    radiant_or_dire + '_P' + str(i) + '_heroDamage',\n",
    "                                                                    radiant_or_dire + '_P' + str(i) + '_towerDamage',\n",
    "                                                                    radiant_or_dire + '_P' + str(i) + '_level',\n",
    "                                                                    radiant_or_dire + '_P' + str(i) + '_heroHealing',\n",
    "                                                                    radiant_or_dire + '_P' + str(i) + '_goldSpent'])\n",
    "                df_heroe_match = pd.merge(df_heroe_match, df_heroe, left_index=True, right_index=True, how='outer')\n",
    "            return df_heroe_match\n",
    "\n",
    "        # создать основной ДФ, где будут записаны все матчи (id матча и rda героя)\n",
    "        df_heroes_players_HD_TD_LVL_HH_GS = pd.DataFrame()\n",
    "\n",
    "        # создать список названий колонок  героев radiant\n",
    "        all_her_rad = main.loc[:,'radiant_H1':'radiant_H5'].columns\n",
    "        # создать список названий колонок  героев radiant\n",
    "        all_her_dir = main.loc[:,'dire_H1':'dire_H5'].columns\n",
    "        # создать список названий колонок  игроков radiant\n",
    "        all_play_rad = main.loc[:,'radiant_P1':'radiant_P5'].columns\n",
    "        # создать список названий колонок  игроков radiant\n",
    "        all_play_dir = main.loc[:,'dire_P1':'dire_P5'].columns\n",
    "\n",
    "        for index in main.index:\n",
    "            if index % 100 == 0:\n",
    "                print (index)\n",
    "\n",
    "            # ДФ для соединения всех герове radiant & dire матча в один ДФ \n",
    "            df_heroe_match = pd.DataFrame()\n",
    "\n",
    "            df_heroe_match = get_players_heroes_HD_TD(df_heroe_match, 'radiant', index)\n",
    "            df_heroe_match = get_players_heroes_HD_TD(df_heroe_match, 'dire', index)\n",
    "            df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "\n",
    "            df_heroes_players_HD_TD_LVL_HH_GS = pd.concat([df_heroes_players_HD_TD_LVL_HH_GS, df_heroe_match])   \n",
    "        df_heroes_players_HD_TD_LVL_HH_GS = df_heroes_players_HD_TD_LVL_HH_GS.reset_index().drop('index', axis=1)\n",
    "\n",
    "        df_heroes_players_HD_TD_LVL_HH_GS.to_csv('../tabel/table from Datdota/KDA/Players/'+\n",
    "                              'HD,TD,LVL,HH,GS Players on hero {} to {} (All time, All, more {}).csv'.format(\n",
    "                                                                                        self.day_first_for_saving_in_file, \n",
    "                                                                                        self.day_end_for_saving_in_file, \n",
    "                                                                                        threshold))\n",
    "    # ------- HD, TD, LVL, HH, GS для героев за последние несколько дней или год если отсутсвуют данные -------------\n",
    "    def createSaveReturnDataForFillEmptyData(self, main, days_ago=365, pro_or_all_teams='Pro', threshold='10'):\n",
    "        max_day = (self.day_end_for_saving_in_file - self.day_first_for_saving_in_file).days\n",
    "        all_data = {}\n",
    "        match_date = self.day_first_for_saving_in_file - timedelta(1)\n",
    "        tier = self.__checkTierTeams(pro_or_all_teams)\n",
    "                    \n",
    "        for day in range(max_day + 1):\n",
    "            date_ago = match_date - timedelta(days_ago)\n",
    "            url_heroes =('http://www.datdota.com/api/heroes/performances?' + self.PATCH +\n",
    "                '&patch=6.87&patch=6.86&patch=6.85&patch=6.84&patch=6.83&patch=6.82&patch=6.81&patch=6.80'+ \n",
    "                '&patch=6.79&patch=6.78&patch=6.77&patch=6.76&patch=6.75&patch=6.74' +\n",
    "                '&winner=either&after={}%2F{}%2F{}'.format(date_ago.day, date_ago.month, date_ago.year) + \n",
    "                '&before={}%2F{}%2F{}'.format(match_date.day, match_date.month, match_date.year) + \n",
    "                '&duration=0%3B200&duration-value-from=0&duration-value-to=200&{}'.format(tier) + \n",
    "                '&valve-event=does-not-matter&threshold={}'.format(threshold)) \n",
    "\n",
    "            dat = self.__get_json_from_url(url_heroes).get('data')\n",
    "            all_data[str(match_date)] = dat\n",
    "            match_date = match_date + timedelta(1)\n",
    "\n",
    "        name_file = 'DataForFillEmptyData/data_KDA_HD_TD_for_all_Heroes_on({})_to({}) ({}day_ago, {}, more {}).txt'.format(\n",
    "                                                    self.day_first_for_saving_in_file, self.day_end_for_saving_in_file, \n",
    "                                                    str(days_ago), pro_or_all_teams, threshold)\n",
    "        with open(name_file, 'w') as outfile:\n",
    "            json.dump(all_data, outfile)\n",
    "        return all_data\n",
    "    def createAndSaveHdTdLvlHhGsForHeroesLastDaysWithFillEmptyData(self, main, file_with_data_for_empty_data, \n",
    "                                                                   days_ago=30, pro_or_all_teams='Pro', threshold='5'):\n",
    "        \"\"\"В отличие от функции createAndSaveKdaHeroes эта отсуствующих данных вставляет данные из\n",
    "        подгруженного файла. Чтобы создать этот файл, используйте фун-ию createSaveReturnDataForFillEmptyData.\"\"\"\n",
    "        print('HD, TD, LVL, HH, GS для героев за последние несколько дней с заполненеим отсуствующих данных')\n",
    "\n",
    "        # создать основной массив, где будут записаны все матчи (id матча и rda героя)\n",
    "        df_HD_TD_LVL_HH_GS_heroes_last_days = pd.DataFrame()\n",
    "        # создать список названий колонок всех героев\n",
    "        all_her = main.loc[:,'radiant_H1':'dire_H5'].columns\n",
    "        tier = self.__checkTierTeams(pro_or_all_teams)\n",
    "        for index in main.index:\n",
    "            if index%100 == 0:\n",
    "                print (index)\n",
    "            # ДФ для соединения всех герове матча в один ДФ \n",
    "            df_heroe_match = pd.DataFrame()\n",
    "            # дата матча\n",
    "            date_match = date.fromtimestamp(main['start_time'][index])\n",
    "            # предыдущий день\n",
    "            date_match =  date_match - timedelta(1)\n",
    "            several_days_ago = date_match - timedelta(days_ago)\n",
    "            url_heroes =('http://www.datdota.com/api/heroes/performances?' + self.PATCH +\n",
    "                '&winner=either&after={}%2F{}%2F{}'.format(several_days_ago.day, several_days_ago.month, \n",
    "                                                           several_days_ago.year) + \n",
    "                '&before={}%2F{}%2F{}'.format(date_match.day, date_match.month, date_match.year) + \n",
    "                '&duration=0%3B200&duration-value-from=0&duration-value-to=200&{}'.format(tier) + \n",
    "                '&valve-event=does-not-matter&threshold={}'.format(threshold)) \n",
    "\n",
    "            # выгрзить json с предыдущей ссылки\n",
    "            dat = self.__get_json_from_url(url_heroes).get('data')\n",
    "            df_data_tabel_for_heroes = pd.DataFrame(dat)\n",
    "            # создание ДФ с данными за последний год до дня матча, из файла\n",
    "            df_data_tabel_for_heroes_1Year_ago = pd.DataFrame(file_with_data_for_empty_data.get(str(date_match)))\n",
    "            for her in all_her:\n",
    "                # вытащить id героя\n",
    "                id_heroe = main[her][index]\n",
    "                try:\n",
    "                    # создать массив с данными \n",
    "                    array = df_data_tabel_for_heroes[df_data_tabel_for_heroes['hero'] == id_heroe].values\n",
    "                    # Если нет данных по герою то взять данные по герою за последний год из файла\n",
    "                    if len(array) == 0:\n",
    "                        array = df_data_tabel_for_heroes_1Year_ago[df_data_tabel_for_heroes_1Year_ago['hero'] == \n",
    "                                                                   id_heroe].values\n",
    "                except: # Если абсолютно новый герой то тогда поставить все 0\n",
    "                    array = [[z*0 for z in range(21)]]\n",
    "                # создать название колонок для определнного героя\n",
    "                col = [her + '_' + c for c  in df_data_tabel_for_heroes_1Year_ago.columns + '_{}day_ago'.format(\n",
    "                                                                                                            days_ago)]\n",
    "                # ДФ для героя по матчу\n",
    "                df_heroe = pd.DataFrame(array, columns=col)\n",
    "                df_heroe_match = pd.merge(df_heroe_match, df_heroe, \n",
    "                                                       left_index=True, right_index=True, how='outer')\n",
    "                df_heroe_match['match_id'] = main.loc[index, 'match_id']\n",
    "            df_HD_TD_LVL_HH_GS_heroes_last_days = pd.concat([df_HD_TD_LVL_HH_GS_heroes_last_days, df_heroe_match])\n",
    "        df_HD_TD_LVL_HH_GS_heroes_last_days = df_HD_TD_LVL_HH_GS_heroes_last_days.reset_index().drop('index', axis=1)\n",
    "        df_HD_TD_LVL_HH_GS_heroes_last_days.to_csv('../tabel/table from Datdota/KDA/Heroes/DaysAgoWithFillEmptyData/' +\n",
    "                              'KDA, HD, TD... heroes on {} to {} ({}day_ago, {}, more {}).csv'.format(\n",
    "                                                                                    self.day_first_for_saving_in_file, \n",
    "                                                                                    self.day_end_for_saving_in_file, \n",
    "                                                                                    str(days_ago), \n",
    "                                                                                    pro_or_all_teams, threshold))\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
